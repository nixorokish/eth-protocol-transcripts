WEBVTT

1
00:08:58.800 --> 00:09:00.040
lightclient: Hello!

2
00:09:04.070 --> 00:09:04.760
Kim: 8.

3
00:09:06.580 --> 00:09:12.159
lightclient: I think we'll start in a couple of minutes after a few more people have time to come in.

4
00:09:17.380 --> 00:09:18.850
Marius: I'm fine with them.

5
00:09:19.300 --> 00:09:22.329
Marius: The links over just equal.

6
00:10:13.833 --> 00:10:17.839
lightclient: I'm just waiting, maybe one more minute or so to get started.

7
00:11:09.240 --> 00:11:12.569
lightclient: Okay, I think most people are here

8
00:11:13.030 --> 00:11:21.359
lightclient: and just get started. I guess from my side. Basically.

9
00:11:22.060 --> 00:11:28.619
lightclient: we're we've been trying to think about what what to do going forward for Portal, because.

10
00:11:29.140 --> 00:11:36.960
lightclient: as most of you know, a large portion of the portal team was laid off by the ethereum foundation a couple weeks ago.

11
00:11:37.490 --> 00:11:48.530
lightclient: and we continue to need a mechanism for decentral like robust, decentral, decentralized

12
00:11:48.890 --> 00:11:53.249
lightclient: history, retrieval mechanism and portal has been

13
00:11:53.350 --> 00:12:09.530
lightclient: the thing that we've expected to service those needs, and in some ways, like Portal exists today and is servicing those needs, but we still are trying to get the integration into the execution clients and

14
00:12:09.900 --> 00:12:15.109
lightclient: performing the integration is not, is not trivial and

15
00:12:15.510 --> 00:12:38.380
lightclient: handling. The infrastructure that exists around this project. Glados, the testing the standalone clients. This is all a lot of this is a lot of work that a team used to maintain that, you know, no longer exists at the Ef. And we are trying to think about how we can move forward. Given these constraints and

16
00:12:39.610 --> 00:12:49.679
lightclient: the kind of the way that I have been thinking about this problem is trying to deliver the minimal

17
00:12:49.890 --> 00:12:55.879
lightclient: portions of portal and integrating them more deeply into the execution clients because

18
00:12:56.460 --> 00:13:14.719
lightclient: Portal started 4 or 5 years ago. And even today it does not really exist in an execution client. It's always thought to be this standalone mechanism that connects to an execution client that could provide the history. But we've just realized that this

19
00:13:16.580 --> 00:13:23.450
lightclient: this isn't. This is not like brought in all of the people, from the execution clients that need to be brought into

20
00:13:24.320 --> 00:13:25.220
lightclient: help.

21
00:13:25.400 --> 00:13:36.670
lightclient: the integration, and to really like create a row, you know, bring it to the level of robustness that we feel comfortable, enabling by default into our clients.

22
00:13:37.160 --> 00:13:49.489
lightclient: So the thing we've been talking about over the past few weeks is just this idea like, how do we integrate with execution clients better? How do we get more of the execution client developers that exist today working on the portal network.

23
00:13:50.970 --> 00:13:58.990
lightclient: and the thing that we've kind of come up with, which Miles can talk about a bit more in a few minutes. But this kind of idea that we've come up with is

24
00:13:59.370 --> 00:14:05.800
lightclient: we want to not necessarily change the long term vision about what Portal is trying to achieve.

25
00:14:06.290 --> 00:14:09.580
lightclient: We just want to make sure that we are

26
00:14:10.750 --> 00:14:16.690
lightclient: intensely focused on specific milestones that deliver a lot of value to

27
00:14:17.320 --> 00:14:26.079
lightclient: the ethereum protocol and execution clients immediately like this idea of the standalone portal clients is kind of going away for now.

28
00:14:26.600 --> 00:14:51.859
lightclient: because we've sort of seen it play out the last few years, and the centralized Json. Rpc idea. It's a good idea. And 3 or 4 years ago it was something that felt very important. But in the last few years it seems like there's been like this divergence where ethereum has gone in a bit of a different path, and most users continue to just use centralized Json, Rpc. Providers.

29
00:14:52.184 --> 00:15:02.240
lightclient: and then execution clients have these needs like, they need to be able to access the data for 4 4, so that we can do rolling history expiry like we've planned.

30
00:15:04.360 --> 00:15:05.470
lightclient: And

31
00:15:07.320 --> 00:15:13.189
lightclient: for yeah, so for these reasons, we kind of feel that the best way forward is to make sure that

32
00:15:13.300 --> 00:15:18.160
lightclient: each step of the way. This portal protocol is.

33
00:15:18.320 --> 00:15:27.339
lightclient: you know, immediately giving value to the execution layer, and the way that we think is the best to to achieve this is to

34
00:15:27.500 --> 00:15:30.899
lightclient: kind of drop a lot of the

35
00:15:31.810 --> 00:15:46.370
lightclient: portal sub protocols that that exist around the beacon chain and the State and the ephemeral headers, and focus like refocus a bit on just the history portion of the protocol, making the history portion of the protocol

36
00:15:46.760 --> 00:16:14.310
lightclient: baked directly into the execution client not treat it as a totally separate module. It will be separate in many ways, but it has the expectation that it's running with an execution client, so it doesn't need to Bootstrap itself as a light client from a beacon light client bootstrapping endpoint. It doesn't need to keep up to date with the head of the chain in this way, and we can kind of get away

37
00:16:14.310 --> 00:16:22.359
lightclient: from using these bridge nodes to seed the network. Because fundamentally, you as an execution plan, are already downloading

38
00:16:22.710 --> 00:16:37.310
lightclient: this data so you can when it meets the criteria for your node to store. You can kind of just, you know, store it off in your own client. So this is kind of like the way that we're thinking about the portal network.

39
00:16:37.990 --> 00:16:41.099
lightclient: you know, to to like really

40
00:16:41.250 --> 00:16:45.170
lightclient: make it useful in the execution clients as soon as possible.

41
00:16:47.090 --> 00:17:08.000
lightclient: and in a longer term we like hope that people will still be able to. We don't want to make decisions today that will not allow the other sub protocols that have kind of been implemented and formulated in people's minds to exist. We want the Beacon protocol to exist. We would like the State. The State protocols to exist. But just like the reality is is that we don't have the

42
00:17:08.109 --> 00:17:13.580
lightclient: capacity to like develop all of these things to the same standards

43
00:17:14.050 --> 00:17:16.109
lightclient: in, you know, in this time.

44
00:17:18.280 --> 00:17:19.369
lightclient: So

45
00:17:19.700 --> 00:17:38.940
lightclient: that's kind of like where we're we're coming from for this for the the future of the portal portal protocol, and you know Milosh and Felix and I have been talking about this amongst ourselves a fair bit for the past couple of weeks, and this is kind of like how we think we can be most productive. Moving forward.

46
00:17:39.250 --> 00:17:47.860
lightclient: Obviously, portal is a project that exists with many different contributors. Many people within execution clients, many Grant teams

47
00:17:48.420 --> 00:17:53.349
lightclient: and people. Everybody is kind of expecting the Portal protocol to provide different things.

48
00:17:54.320 --> 00:18:19.300
lightclient: depending on the exact use case that they want, and I don't think that we can make the portal protocol like, you know, Mila, Felix and I like. We don't have the ability to develop all of the different aspects of the portal protocol right now, and I don't want to stop people from who, you know, people who want to continue developing those features. But we also need to figure out how to streamline the like most critical things to the execution layer.

49
00:18:19.300 --> 00:18:24.690
lightclient: First, st because that's kind of like where we're coming from at this point is that the execution layer needs this.

50
00:18:24.690 --> 00:18:31.719
lightclient: It's needed this for many years, and we have to accelerate the timeframe in which execution clients integrate this stuff.

51
00:18:32.180 --> 00:18:47.780
lightclient: and this is kind of like the way that we see it best. But I want to like open up to other clients or people who have been implementing, you know, implementing portal protocol projects to hear like how this kind of rough

52
00:18:48.030 --> 00:18:57.029
lightclient: execution layer focus plan how they see it, impacting their projects and the way that they anticipate using the quarter protocol.

53
00:18:57.220 --> 00:19:08.609
lightclient: And then, after that, Milash can probably jump in a bit deeper and talk a little bit about the exact changes that we're imagining to the history portion of the portal protocol.

54
00:19:09.460 --> 00:19:10.730
lightclient: Does that sound good?

55
00:19:16.910 --> 00:19:21.649
lightclient: So any questions or thoughts on this, so far.

56
00:19:26.200 --> 00:19:32.333
Justin Florentine (Besu): Hey, this is Justin, the basic team. And just just a quick thought. I kind of love what I'm hearing.

57
00:19:32.840 --> 00:19:57.820
Justin Florentine (Besu): one of the things that sticks out to me. And just tell me if I'm understanding your point correctly is that there's currently kind of a gap where making the execution clients able to leverage portal is not really a thing. So, for instance, if you look at what was designed with Eth, a, there's some discovery aspects of like. Okay, if an execution client needs this history, how does it find

58
00:19:57.820 --> 00:20:04.239
Justin Florentine (Besu): it? Recover it and get it from the portal network, and maybe then make it available to the rest of the network.

59
00:20:04.240 --> 00:20:06.700
Justin Florentine (Besu): Do you think that that's kind of

60
00:20:06.710 --> 00:20:27.640
Justin Florentine (Besu): the area of focus that we need to hone in on here like? So, for instance, how does dev. P. 2, PE. Wireline Protocols, snap protocols? What do all of those things do when the client also has a view of the portal network, and maybe a limited source of data locally.

61
00:20:27.950 --> 00:20:28.470
Felix: I mean.

62
00:20:28.470 --> 00:20:42.320
Felix: we will. I can answer this. So the way I see it is that now, with this refocusing also, we are more trying to basically say that the the portal history protocol is one possible

63
00:20:43.340 --> 00:20:50.700
Felix: future for execution, layer, peer to peer in general, and especially for the shrinking part. So

64
00:20:51.290 --> 00:20:59.769
Felix: we have to see what that looks like. But for, for just, for example, acquiring the block bodies and receipts

65
00:21:00.525 --> 00:21:09.240
Felix: we can easily say that if portal is sufficiently adopted in the execution layer client space, then we can remove

66
00:21:09.420 --> 00:21:19.290
Felix: the the capability for retrieving these things from the eth protocol completely, because we will be able to always get them via the portal.

67
00:21:19.510 --> 00:21:25.460
Justin Florentine (Besu): Okay, so good. Good. Thank you. That's different. That's more of a sister protocol as opposed to an integration with existing ones. Thank you.

68
00:21:25.460 --> 00:21:47.441
Felix: Yeah, so this is not about implementing portal as a part of the like existing capabilities. Portal network cannot fundamentally be implemented on Tcp, the way the eth protocol is it has to be done differently because of the dht approach and so we have to see

69
00:21:48.210 --> 00:21:51.573
Felix: How this I mean.

70
00:21:52.590 --> 00:22:01.639
Felix: it is a different kind of thing, basically from the current from the existing protocols. But we do see that in the long term it can replace the existing protocols. Yeah.

71
00:22:03.520 --> 00:22:04.870
Justin Florentine (Besu): That's helpful. Thank you.

72
00:22:13.570 --> 00:22:16.009
lightclient: Other questions, feedback.

73
00:22:19.880 --> 00:22:31.510
FLCL: Yeah, so consider it. Do you think it is possible to replace in the future, replace squaring

74
00:22:32.787 --> 00:22:40.582
FLCL: receipts and stuff in old way with portal fully without changes in portal protocol.

75
00:22:41.400 --> 00:22:47.590
FLCL: I heard concerns about ranges, for example, and

76
00:22:47.770 --> 00:22:53.490
FLCL: probably about that turing stuff that is a level

77
00:22:54.413 --> 00:22:59.029
FLCL: like encapsulated on the level more than required. Yeah.

78
00:23:01.810 --> 00:23:08.510
Felix: So we are aware that at the moment the ported protocol does not fully support

79
00:23:08.890 --> 00:23:30.199
Felix: like it doesn't support querying, for example, ranges of block bodies. Milos has created a document outlining some changes to the history protocol that would enable this. So basically, we can tweak the locality assign, like the assignment of content to nodes in such a way that

80
00:23:30.380 --> 00:23:35.160
Felix: ranges of block bodies will always be stored in certain nodes.

81
00:23:35.910 --> 00:23:52.350
Felix: or at least the likelihood of like ranges being available from a single node will be higher. So this would then allow us to serve range queries in some way, but it's also fundamentally important to understand that the network protocol is very different from the

82
00:23:52.700 --> 00:24:10.750
Felix: from how it works in the Dev. P. 2, p. Because the porter network doesn't have an inherent limit on the number of peers. So in the Dev. P. 2, p. Protocol, the node is only connected to a certain number of peers, and these connections are meant to be kind of long lived and actually establishing peer connections takes some time

83
00:24:10.750 --> 00:24:31.479
Felix: with the portal network. You can basically walk the entire network at the same time. So it means you can query a lot of nodes concurrently for the blocks, and even with the existing assignment of content you can probably get quite the sufficient speed of syncing by just querying many nodes and waiting for their responses concurrently.

84
00:24:31.480 --> 00:24:34.160
Felix: If you want to sync the whole chain, for example.

85
00:24:35.290 --> 00:24:37.369
Felix: At same time, we think that

86
00:24:38.010 --> 00:24:46.460
Felix: syncing a full chain is less of a problem if you can get it at any time. So basically, it's then the question of

87
00:24:46.570 --> 00:25:04.530
Felix: what are the performance requirements like? Basically, it has to be fast enough to be able to import the blocks like download the blocks faster than you can process them, I guess. And then if you want to create an archive, then yeah, we may want to have a fast download speed, but I don't see it as

88
00:25:04.950 --> 00:25:10.929
Felix: our big priority right now for this protocol to

89
00:25:11.180 --> 00:25:24.679
Felix: have the maximum download speed for syncing the full chain. So at the moment. It's more about integrating it as a sort of alternative to the existing protocols and then replacing, for example, eth protocol. With this.

90
00:25:26.360 --> 00:25:28.810
Felix: maybe going to happen later.

91
00:25:33.662 --> 00:25:44.050
FLCL: Yeah, I I mean, I I still believe that without wearing those ranges, it is possible to still synchronize it in parallel.

92
00:25:45.670 --> 00:25:58.309
Felix: Yeah, it is possible. Yeah, I mean the ranges. We talk about it. And it is we are trying to come up with a design right now that facilitates this. But it's not implemented right now.

93
00:25:58.760 --> 00:26:01.530
Felix: whereas the other, like basically this, like

94
00:26:02.080 --> 00:26:08.169
Felix: single block storage, is implemented right now in in the in all the portal clients.

95
00:26:09.960 --> 00:26:18.689
FLCL: And all this think is quite complex to test and implement in clients.

96
00:26:18.830 --> 00:26:31.060
FLCL: But there is a proposal that way later and simpler. I guess it is about sharding blocks. So

97
00:26:31.220 --> 00:26:39.250
FLCL: I mean just hosting ranges of blocks and receipts using a bit field.

98
00:26:42.110 --> 00:26:46.729
FLCL: Why should we use portal?

99
00:26:47.710 --> 00:26:52.409
FLCL: Is it something critical and way better than

100
00:26:53.185 --> 00:26:57.070
FLCL: using that simple approach when you just

101
00:26:57.380 --> 00:26:59.519
FLCL: shared, according to a bit field.

102
00:26:59.520 --> 00:27:06.620
Felix: Yeah. So the the difference between this approach and this and this like charting approach, is that

103
00:27:06.620 --> 00:27:29.600
Felix: for Portal the node? Can any node can choose their contribution to the network in terms of number of bytes. So, for example, there is no protocol, wide assignment of like storage capacities to the nodes, but rather with portal. The big idea is that it is a dynamically sharded system. So each node brings a certain capacity to the network.

104
00:27:29.600 --> 00:27:38.180
Felix: and then the network will ensure that the content is distributed to the node according to is, according to its

105
00:27:40.650 --> 00:27:41.300
FLCL: Reduce.

106
00:27:41.770 --> 00:27:43.660
Felix: Radius of storage.

107
00:27:44.790 --> 00:27:53.360
FLCL: But what if I enable several bits in that bit field which means like I can

108
00:27:53.720 --> 00:27:59.039
FLCL: effect regulates how much content is hosted by.

109
00:27:59.910 --> 00:28:24.760
Felix: Yes, the difference with the bit field is that still? I mean, the question is, just how much does one bit cover? And then in the end it kind of resolves to. This same thing is that the bit field approach also is not structured. So there's no routing. So if you require a certain piece of content. You actually will have to somehow figure out where to like, how to find a peer that actually has this content.

110
00:28:24.930 --> 00:28:52.019
Felix: I mean if the network has a sufficient assignment of peers, and you know the ranges are sufficiently large, and everything is, you know, works out fine. Then there's no problem. But the thing with Portal is that it's explicitly designed in a way that assigns the content in a uniform way throughout the network, which means that you have much higher guarantees of availability of the content. So there's

111
00:28:52.180 --> 00:29:02.809
Felix: the chances of losing a part of the history, for example, are very low, whereas with this sharding thing where everyone just kind of like decides it. It's it's a bit different, I would say.

112
00:29:03.270 --> 00:29:09.179
Kim: And it's not only that part, it's also the actual like discovery part. You will have to add a lot of peer management

113
00:29:09.610 --> 00:29:11.380
Kim: in the sharding approach.

114
00:29:12.441 --> 00:29:15.839
Kim: And you will basically like, be reinventing portal. But in a worse way.

115
00:29:16.150 --> 00:29:22.489
Kim: and on Tcp connections where you would have to keep maybe a whole set of clients or peers

116
00:29:22.780 --> 00:29:26.800
Kim: within a specific sharding range continuously, like open.

117
00:29:27.880 --> 00:29:34.139
Kim: So yeah, I think it's presented as a easy solution. But in in reality. I think it's more complex than you might think.

118
00:29:34.370 --> 00:29:35.680
Kim: The sharding approach.

119
00:29:39.060 --> 00:29:39.969
FLCL: Yeah, I agree.

120
00:29:41.630 --> 00:29:57.062
FLCL: another question about like clients. So it will say that it they are not in kind of priority. Right? Will portal help with that? Or will it be modified to

121
00:29:58.571 --> 00:30:01.978
FLCL: support, like trustless, decentralized

122
00:30:03.410 --> 00:30:04.660
FLCL: Rpc.

123
00:30:08.700 --> 00:30:14.489
lightclient: I still see this as a long term goal for Portal. But to me one of the

124
00:30:14.780 --> 00:30:16.450
lightclient: one of the issues that

125
00:30:16.620 --> 00:30:24.020
lightclient: the portal project had? Was it tried to solve everything kind of at one time.

126
00:30:24.370 --> 00:30:40.920
lightclient: and you know they were so far ahead in terms of already trying to solve the state network trying to solve like centralized transaction propagation when you don't have necessarily have the state for all the transactions. There are all these ideas about

127
00:30:41.060 --> 00:30:54.340
lightclient: things that need to exist in the future. And I'm not necessarily saying that that is changing in terms of what the portal project might aim to achieve. I am just thinking it makes more sense to

128
00:30:54.340 --> 00:31:16.799
lightclient: change the ordering in which we focus on things. So to me, it's like, you know, instead of it being 10 or 20% focus on this history network. That's kind of implemented. But it's not really integrated into execution clients. And there's some stuff working on there and then, you know, 2530% working on a state network. And then you know another. You know, some amounts of percent like testing and doing other things. It's like 100%

129
00:31:16.800 --> 00:31:29.879
lightclient: effort and energy on the, you know, Portal related projects, or at least like, you know, the portal related projects that Gath is working on, for instance, will be focused on making sure that there is

130
00:31:29.990 --> 00:31:59.369
lightclient: a history sub protocol supported in execution clients, and once that is achieved. And once we are able to support rolling history, X-ray, we can start thinking about the next thing. And like, maybe the next thing is like, you know, just moving. You know, one meter in front of us and achieving like range queries like, I'm not even saying that we'll have range queries from like version 1.0 of whatever this history sub protocol is that kind of been working on, you know, we want to like what you know.

131
00:31:59.370 --> 00:32:26.419
lightclient: have small victories along the way where we are giving useful functionality. And and this is just kind of different from how things were thought before, where we wanted to do all of it. We wanted, like, we wanted to have product market fit for a standalone client. And so we're just changing this ordering of priorities to focus on the thing that is needed at this moment. And then, once that's done, we focus on the next thing, and the next thing.

132
00:32:28.565 --> 00:32:34.100
FLCL: Last quick question is about potential devnet testnet. How do you see this.

133
00:32:37.350 --> 00:32:47.339
lightclient: Right? I mean, this is kind of a question for people who plan to continue working on this during this period of time where

134
00:32:47.510 --> 00:32:49.000
lightclient: we're developing it.

135
00:32:49.360 --> 00:33:19.270
lightclient: Because, like, you know as well as anyone that it is not the easiest thing to continue specing things out, implementing them, testing them, finding integration integrations and then specing, implementing, testing integrations like this is a somewhat slow process. And like, as you add, more parties, you know, involved in this, then it's, you know, the complexity can kind of blow up. And so I am curious like which

136
00:33:19.430 --> 00:33:43.769
lightclient: you know what teams are interested in taking this journey and continuing on the implementation of portal, as things are in flux, because if there are teams who want to continue to do that, then we can try to find the best working path for working on this. But if a lot of clients don't have the resources or don't want to, you know

137
00:33:43.910 --> 00:33:51.120
lightclient: implement things while stuff is in flux. Then the plan that we've kind of been thinking about is that

138
00:33:51.840 --> 00:34:00.470
lightclient: you know we will try to publish some specs. We'll implement it in. Go ethereum and go ethereum will.

139
00:34:00.470 --> 00:34:25.420
lightclient: you know, sort of handle most of the testing and the test nets, and once we're comfortable with having it in the master branch as a non default. Like, we start doing this like we slowly like, build it up. And then eventually, you know, hopefully, in like 6 to 8 months. We have a backbone of the portal network, and the spec is written, and clients can kind of just implement the spec and connect to the network

140
00:34:25.420 --> 00:34:42.579
lightclient: and run this like testing infrastructure that exists. But if we if it's going to be a collaborative environment, then yeah, we will need to figure out what the best way for us to continue collaborating on this is. So I'm curious what what clients are thinking about in terms of that.

141
00:34:44.010 --> 00:34:50.780
FLCL: Oh, thanks I I will ask the team. But another mind has a portal

142
00:34:50.889 --> 00:34:55.858
FLCL: integration in progress. And we potentially can finish it and

143
00:34:57.020 --> 00:35:01.640
FLCL: participate in some network. Right now, if a portal

144
00:35:02.106 --> 00:35:06.480
FLCL: the testnets will be closed, it will be harder for us to develop

145
00:35:07.190 --> 00:35:09.949
FLCL: some. Yeah, at least some kind of

146
00:35:10.320 --> 00:35:13.329
FLCL: definite something like that would help.

147
00:35:14.010 --> 00:35:14.660
lightclient: Yeah.

148
00:35:14.660 --> 00:35:23.359
Kim: I, I can speak for members. So yeah, 1st of all, the nodes that we currently have running we will not take them down. So

149
00:35:23.844 --> 00:35:27.679
Kim: whatever development you want to test against those they will, they will stay up.

150
00:35:28.750 --> 00:35:35.869
Kim: And then Nimbus already has is already has already an integration with our portal client, so you can run the El

151
00:35:36.160 --> 00:35:39.769
Kim: with the port, the client in like Standalone over Json, Rpc.

152
00:35:39.950 --> 00:35:43.360
Kim: But probably in the future, we will just fully integrate it in a binary

153
00:35:44.303 --> 00:35:46.975
Kim: and yeah, so we are obviously up for

154
00:35:48.328 --> 00:35:50.959
Kim: Continuation of of the history network.

155
00:35:51.400 --> 00:36:04.279
Kim: Not sure about the other networks, because, yeah, that might be. I mean, it's unlikely that we have the resources for that but history or the adapted history network or slimmed down history network, which is receipts.

156
00:36:04.710 --> 00:36:05.950
Kim: embodies.

157
00:36:06.410 --> 00:36:10.099
Kim: We can definitely further work on that and and implement that

158
00:36:12.140 --> 00:36:16.620
Kim: we might even be still like, have some experimental network up

159
00:36:16.790 --> 00:36:25.719
Kim: which just serves the headers with their proofs. We're not sure yet about. This probably depends whether we still see use case within our el client itself for that or not.

160
00:36:27.800 --> 00:36:31.699
Kim: The thing is, most of the code is there, so it's it's probably a little

161
00:36:32.000 --> 00:36:43.970
Kim: less involved for us to keep to move that to another experimental network and and keep it running. But I can't fully confirm on this yet. I guess it will. We have to figure that out ourselves, if it's worth the effort or not.

162
00:36:44.200 --> 00:36:45.990
Kim: And if you see, use case for that.

163
00:36:47.620 --> 00:36:51.689
Kim: But yeah. And then I wanted to just also add on the range requesting,

164
00:36:52.290 --> 00:36:56.830
Kim: I do think it's a useful thing, especially with the only use case now being the Els

165
00:36:57.313 --> 00:37:01.990
Kim: but I just wanted to say that it's because maybe some people that don't have the full background on Portal

166
00:37:02.410 --> 00:37:07.170
Kim: that's better something to do immediately rather than later, because it does mean you have to like

167
00:37:07.900 --> 00:37:18.109
Kim: redistribute, redistribute the data over the network, because the content Id basically changes, at least for the proposed solution currently, which is also like

168
00:37:18.610 --> 00:37:20.649
Kim: kind of the only solution I see for this.

169
00:37:24.910 --> 00:37:37.219
Milos: I can talk a bit about the what we were seeing as a direction of going forward. If if that's okay for now and then we can maybe discuss that in in more details or something, or we can bring it to other topic. What do you guys think.

170
00:37:37.220 --> 00:37:39.860
lightclient: Yeah, yeah. Could. Could you do that?

171
00:37:40.150 --> 00:37:45.450
Milos: Yeah, let me share my screen.

172
00:37:52.270 --> 00:37:55.770
Milos: just a second in this one.

173
00:37:59.190 --> 00:38:00.939
Milos: I hope you see it. Well.

174
00:38:01.060 --> 00:38:09.340
Milos: I will probably transfer this into the East research post and share it either later today or early next week after I polish it a bit more.

175
00:38:10.273 --> 00:38:11.879
Milos: So basically.

176
00:38:11.880 --> 00:38:13.160
lightclient: Even slightly.

177
00:38:13.490 --> 00:38:14.200
Milos: Yep.

178
00:38:14.540 --> 00:38:15.250
lightclient: Thanks.

179
00:38:16.230 --> 00:38:33.209
Milos: So the working name of the thing is finalized. Change, history, port of sub network. So it would be a new subnetwork. Do not combine it with the previous history, or not, more like not modify the already existing history network, because we are introducing new content types and

180
00:38:33.350 --> 00:38:41.480
Milos: other than just keeping the name, there is no really benefit of combining them together. This is working name. We can iterate on it. And, as the name suggested.

181
00:38:41.730 --> 00:38:47.230
Milos: unlike the history sub network. This will only store the content that is finalized. So

182
00:38:47.570 --> 00:38:54.829
Milos: it means there is no handling of if a mirror quantity in any kind of way. And also

183
00:38:56.170 --> 00:39:08.909
Milos: it's as we will see later. It's for now only focus on the bodies and receipts without headers. In the future we can add headers there as well, and we can decide if we want to add them with or without proofs.

184
00:39:09.508 --> 00:39:20.130
Milos: But since main main users are the execution layer clients, there is really no need of storing the headers, because we assume that all execution clients

185
00:39:20.432 --> 00:39:32.230
Milos: already have all the headers. So there is no really point of doing that at the moment, and later we can decide. Maybe if your clients no longer want to store headers, that we add them either with or without proof or something like that.

186
00:39:32.270 --> 00:39:55.440
Milos: The big change is the quantitative deviation function is different. To support the range queries. I will go a bit into details about how it works. What is the idea behind it? And the code might not be obvious. Why, it works that way. I have a graphical visualization that will also help, and I will cover that a bit later. But let me go over the high level idea

187
00:39:55.650 --> 00:40:04.590
Milos: regarding the the. So basically, every message on a portal wire protocol goes over this 5 talk request

188
00:40:04.630 --> 00:40:26.579
Milos: message and to use the talk request message, we have to identify the protocol id. I basically use the idea that what we were doing on the on the portal, basically where every different testnet would use a different protocol. Id so, for example, I just put this where, for example, this test net

189
00:40:26.590 --> 00:40:48.470
Milos: code can be used for arbitrary, isolated devnets like, if you run something on network or hive test, or something like that, you would be always use this one in a sort of isolated net. But if you want to support a testnet or something like that you would use this. This means that if you want to support more testnets or L. 2 s. Or something like that, each of them would have to

190
00:40:49.070 --> 00:40:53.279
Milos: add another code somewhere in some standardized way.

191
00:40:53.500 --> 00:41:07.440
Milos: Now, this might become a problem. If we have so many use cases, there is a alternative idea that will require changing to the portal wire spec, where basically, we just use one protocol id. Let's say this one

192
00:41:07.650 --> 00:41:11.460
Milos: 0 x 5,000, and

193
00:41:12.010 --> 00:41:30.669
Milos: then you would negotiate with the peer. What? What? Basically ethereum network you are talking about, either through the handshake, using the ping extensions, or maybe as part of the enr records, or something like that can be basically then added as alternative way of

194
00:41:30.830 --> 00:41:31.340
Milos: no.

195
00:41:31.340 --> 00:41:37.049
Kim: Can. Can I make a smaller mark that neither those actually work

196
00:41:37.200 --> 00:41:39.450
Kim: unless you'd like? I mean, you couldn't do.

197
00:41:40.590 --> 00:41:48.950
Kim: Maybe it's too much in detail. But if you do like a find content, recursive, find content, request to look up data. You might reach notes that you've never contacted before.

198
00:41:49.478 --> 00:41:53.450
Kim: And thus you never think, and you cannot negotiate upfront, and that.

199
00:41:53.450 --> 00:41:53.850
Milos: Oh!

200
00:41:53.850 --> 00:41:54.380
Kim: Okay.

201
00:41:54.650 --> 00:41:58.399
Kim: that kind of like breaks the whole way. That portal works like you don't need to know every note.

202
00:41:59.410 --> 00:42:08.169
Milos: I mean, if it's part of the enr, then you can check from the enr because you you will have their enr records right.

203
00:42:09.120 --> 00:42:15.380
Kim: Yeah, Dnr would would. Yeah, okay, sure. The Nr is is a potential solution. I think.

204
00:42:15.830 --> 00:42:18.519
Felix: Just for identifying which network is it, or.

205
00:42:18.810 --> 00:42:19.220
Milos: Yeah.

206
00:42:19.630 --> 00:42:32.029
Felix: I mean, we have the existing records like this is a solved problem for the execution layer, because we actually have enr entries for execution layer nodes that directly specify the network that they are on

207
00:42:32.170 --> 00:42:43.699
Felix: so. But the fork id. So I think it's just something that has to be supported as well. And the portal network basically you have to. You can always determine if the node is a part of the network that you are looking for.

208
00:42:46.935 --> 00:43:03.474
Milos: I mean, it's something to be figured out. Details like the easiest one is to just use a different protocol id for different network. But if it might become problem if scaling, if if we have to do it, and this is something that we can potentially introduce later in the future and change how we do it.

209
00:43:04.320 --> 00:43:21.660
Milos: the message types is the same standard types as the other protocol requests no changing there. We use the basic radius and basic client info ping types. And the content types are basically block body and receipts. What is different compared to

210
00:43:22.520 --> 00:43:42.639
Milos: compared to portal history network as it exists today is that these are the content. Values are, are the Rrp encodings of the equivalent types on the Dev. P. 2, p. Spec. So basically, they are not the SSD. Containers of the transactions, withdrawals and

211
00:43:43.000 --> 00:44:05.630
Milos: ankle headers, etc. They are basically the same way that they are defining their peer to be spec. Because if the main use cases are user clients, we might as well use the same recording for the same types of of data. The only exception are the content key, which is basically just. In our case, the block number is used as the

212
00:44:05.820 --> 00:44:20.510
Milos: as the part of the content, key and selector to indicate that the different content key. And in this document there was a bit more explanation like, why are the differences between them? But I think we kind of covered them that

213
00:44:20.830 --> 00:44:28.380
Milos: already before. And here is a visualization of how the continuity function works like, what

214
00:44:28.530 --> 00:44:39.039
Milos: if you have an if you have a block number. How does it convert to a content? Id. And some explanation about it? But I think it would be easier now. I'm not sure if

215
00:44:39.450 --> 00:44:43.740
Milos: if you see the different screen that the

216
00:44:43.840 --> 00:44:46.570
Milos: the chart that I started drawing? Do you see that.

217
00:44:48.390 --> 00:44:48.960
Marius: Yes.

218
00:44:49.850 --> 00:44:52.152
Milos: Yeah, okay, so the idea is,

219
00:44:53.420 --> 00:45:13.299
Milos: the the entire block, all block numbers. I are basically split into cycles. And I picked a value of 2 to the 16, which is 65,000. It presents one cycle. And basically, what it means is that you will spread around the content. So here would be a block 0. Here will be a block one.

220
00:45:13.300 --> 00:45:23.469
Milos: He will be block 2, and you will go like that, and here would be a block. 65,000. I don't know something like that. Right?

221
00:45:24.307 --> 00:45:31.060
Milos: Whatever is 2 to the 16 minus one, and then you will start again from the beginning.

222
00:45:31.190 --> 00:45:54.500
Milos: but instead of overlapping all of them on top of each other, you would actually block 65,000, plus one, or whatever the 2 to the 16 would be here. Here in the middle would be 2 to the 16 plus one. Here will be 2 to the 16,

223
00:45:54.680 --> 00:46:02.660
Milos: plus 2 basically would interleave in the content space content like this. And here would be 2 to the

224
00:46:03.100 --> 00:46:20.160
Milos: 17 minus one, I believe, or something like that. No. 2 to the 32, I guess. And you would basically interleave the the next. The next time you circle, you would basically go here in between here

225
00:46:20.160 --> 00:46:36.910
Milos: here, etcetera, and the cycle. After that you would basically go here, here and there is an easy way how you can achieve that by using the bit manipulation of the original block number. That's what the function does. And that's what is explained here of how to actually

226
00:46:36.910 --> 00:46:52.160
Milos: do a bit manipulation, which is, basically, you just shift one bit from the front to the end of the 2 55 bit number. And then you basically do like reverse order of certain bits. And you basically get this property and split

227
00:46:52.290 --> 00:46:56.839
Milos: exactly like this. So what that actually means in practice is.

228
00:46:57.020 --> 00:47:09.529
Milos: if, for example, you know, they default somewhere here, and you are storing some content like this. You will be storing ranges from many different cycles that all fall within this range.

229
00:47:10.730 --> 00:47:11.840
Milos: And

230
00:47:12.550 --> 00:47:24.330
Milos: the the value of 2 to the 16 was big, that it's it presents some re-reasonable values that, for example, if- if you store only 0 point 4%

231
00:47:24.460 --> 00:47:45.479
Milos: or around that value. To be more precise, you store one over 256 of values. So that's your radius. If you store that, then you will be storing 256, content from each cycle, and that seems like a reasonable value to be retrieved in one request from one peer to another, you would basically request

232
00:47:45.830 --> 00:47:51.860
Milos: that. And if the peer stores at least 0 point 4%, then they will have a continuous

233
00:47:52.040 --> 00:47:56.230
Milos: cycle of that many content that they can give you in one request.

234
00:47:57.040 --> 00:48:03.960
Milos: And that's why I picked the value 2 to the 16 this can be, we can negotiate and pick something else

235
00:48:04.110 --> 00:48:11.529
Milos: but this basically. So this will allow us that peer store somewhat continuous chunks together.

236
00:48:11.978 --> 00:48:22.479
Milos: At the moment there will be no way of actually getting more than one at a time, because the protocol doesn't allow it. But if the peers are storing it, we can easily.

237
00:48:22.700 --> 00:48:30.189
Milos: Here, for example, either we can add here another another request that will be basically the

238
00:48:31.160 --> 00:48:53.909
Milos: batch find content or something like that. And then you would be able to fetch more at the same time, or we can add another another content key. That will basically be the same thing where there'll be a new selector, and you would indicate the block number and indicate how many peers you want, and the content value would be like combined assets from from that range.

239
00:48:54.340 --> 00:49:08.829
Milos: and it will only be used for for fetching, but never for like offering the quantity to the piece, or something like that. So there are ways how we can extend the protocol to later support batch queries or the range queries.

240
00:49:09.500 --> 00:49:13.060
Milos: Once the quantity is actually spread like this around the network.

241
00:49:18.280 --> 00:49:24.427
Milos: I think that high level pretty much the idea of how to do this.

242
00:49:25.290 --> 00:49:33.210
Milos: and I don't know if there's any any questions on this or on high level idea, or anything like that

243
00:49:44.202 --> 00:49:53.799
Milos: how to find a different name. I'm up for finding different name. I named it finalized chain history, portal sub network. But I'm completely fine with calling it

244
00:49:54.010 --> 00:49:57.629
Milos: history, expiry, sub network, or anything like that.

245
00:50:00.960 --> 00:50:04.800
Milos: The current spec basically doesn't say that

246
00:50:05.080 --> 00:50:11.669
Milos: this is only up to pre merge or up to finalize, or anything like that. I think the spec

247
00:50:11.880 --> 00:50:25.260
Milos: or it can be specified out of the spec. How like the the if nothing changes regarding the spec, what would be the range of the content that we store. So if we decide to only store pre merge, because this is currently being agreed with the execution of our clients.

248
00:50:25.310 --> 00:50:48.289
Milos: Then there would have to be some enforcement when checking whether the content is valid or not, or what to store it there. If we decide to store everything up, to finalize, then it's like that. But the idea is that we will use pretty much the same spec to store all finalized content on this at some point, or either or finalized, or all to some rolling window or whatever. But

249
00:50:48.420 --> 00:50:52.009
Milos: yeah, everything that is finalized can be stored using this protocol.

250
00:50:58.310 --> 00:51:04.458
Kim: Thank you, Milosh, that's pretty clear to me. I had another thing that popped my mind.

251
00:51:05.210 --> 00:51:10.719
Kim: that we probably have to add in the slim down or or newer version of the specs

252
00:51:11.392 --> 00:51:15.639
Kim: which is related to injection of new data

253
00:51:17.200 --> 00:51:23.330
Kim: like we will probably have. It's it's something fairly simple, I think, to solve. But we will probably have to define that only

254
00:51:23.540 --> 00:51:26.560
Kim: execution clients that's

255
00:51:27.140 --> 00:51:41.510
Kim: that. They only inject data which is like within their radius, or some other something similar, so that not every client is injecting every new finalized block, for example, which would probably, which is way too much and would overload the network.

256
00:51:42.960 --> 00:51:46.379
Kim: I mean just a small detail. That is, that I don't think we thought about yet.

257
00:51:48.070 --> 00:51:53.689
Milos: Yeah, it. It will depend if we know that there are no really

258
00:51:53.990 --> 00:51:57.479
Milos: so. 1 1 thing that I mentioned

259
00:51:57.760 --> 00:52:11.160
Milos: here in the comparison to the history porter network is, if we assume that all clients are execution clients, or that all clients in some way know about all block block hashes, they can figure out

260
00:52:11.840 --> 00:52:18.850
Milos: what are all the content that they need storing locally, and they can do that as a process of syncing

261
00:52:19.000 --> 00:52:38.479
Milos: when they initialize their own portal network or their portal storage, so they can sync their client completely. And, for example, if they are following the head of the chain in some format. If if they don't have the content, they can fetch it out from other clients, and if you assume that most of the clients on the network are execution clients.

262
00:52:38.650 --> 00:53:01.200
Milos: We don't really need any kind of bridging or any kind of needs to inject the content network, because all the clients on the network can just keep the headers or bodies or whatever they can just figure out. Okay, I'm now deleting from my permanent storage everything. And I'm just keeping 1% of the data or whatever, and they can figure out exactly what they need to keep.

263
00:53:01.580 --> 00:53:06.180
Milos: So if we assume that most clients are execution clients.

264
00:53:06.890 --> 00:53:17.979
Milos: Then there might not be no need to actually do a gossip, and if you assume that there are some clients that might not be execution clients that they might want to have a partial view of the network.

265
00:53:18.441 --> 00:53:27.670
Milos: I would say that gossip is probably not very likely going to work if they are very minority, because every execution clients, when they try to gossip.

266
00:53:27.870 --> 00:53:30.760
Milos: they they would have to iterate entire

267
00:53:31.060 --> 00:53:49.480
Milos: entire their routing table to find potential peers that want to accept it. If I only try. Like one or 2 peers, they might not find the peers without the content might not be fine that way. So it's kind of like the problem if majority of the clients have the content to begin with.

268
00:53:50.050 --> 00:54:02.150
Milos: compared to if and and only minority of them are like. This is some kind of standalone clients. So I think in this scenario it's much better for standalone clients if they already following the head of the chain.

269
00:54:02.400 --> 00:54:17.520
Milos: They can request from the peers the content that they are missing as they figure out. Okay, the the change progresses. I now need more content. I can fetch it from the other peers that should have it. So. It's something to be figured out. Maybe alternative

270
00:54:17.750 --> 00:54:28.250
Milos: bridging can be done so that you actually go and try to offer it to our peers. But maybe that can be on the execution layer plans, or they could be like a standalone bridges. That will do that.

271
00:54:28.800 --> 00:54:33.770
Milos: Yeah. But it's something, maybe also for the future, of how to how to do it.

272
00:54:34.900 --> 00:54:36.839
Kim: Yeah, a solution could simply be.

273
00:54:37.540 --> 00:54:44.190
Kim: remove remove offering data not not saying that it should be the solution. But it yeah, it would probably work that way also.

274
00:54:45.370 --> 00:55:08.799
Milos: Yeah, I think it's the easiest to start with that. If we assume that all clients are execution clients, if if there are some standalone clients. We can figure out how to do it better in that way. But I think it will. All depends on how many, what percentage of the clients or the peers of network are standalone, because it's like a very small chance of them actually being offered. The content is

275
00:55:08.820 --> 00:55:24.760
Milos: also very small. Somebody would actually have to go and iterate through entire network to do it. Maybe there is a way to I don't know. Either describe it in the enr, or describe it in some other way that nodes would actually like to participate in that, or in some other way, like there might be some ways to do it. But

276
00:55:24.790 --> 00:55:38.869
Milos: my 1st intuition is, if they are minority, it might be easier for them to, just because they will have to follow the head of the chain, anyway, in some format, so it might be easier for them to just ask for the content they are they are missing.

277
00:55:48.160 --> 00:56:17.830
Milos: The soar metric is still maintain. Yes, the soar metric is used for the distance and for node, id, and for retrieval, the content, and everything. So the soar distance is used for everything. The charge that I draw here is not fully accurate, that this range is not necessarily continuous range. It will be continuous range if your radius is the power of 2. Then there is a guarantee that this will be a continuous range.

278
00:56:17.940 --> 00:56:25.400
Milos: otherwise you don't have such guarantees. Otherwise you have guarantees that at least half of your radius will be continuous.

279
00:56:25.520 --> 00:56:45.949
Milos: But the idea is that you use the soar metric for for everything that was used right now, you don't use the actual like a number distance metric, because that can introduce other problems with the routing table and stuff like. So the Xor metric is used for everything, and how to do, how to choose the node. Id, I would say random, I think.

280
00:56:46.650 --> 00:56:47.670
Milos: yeah.

281
00:57:03.753 --> 00:57:14.390
Milos: The Json Rpc. Endpoints. I think they would be good to be left for the testing purposes. There was also a question about the 5 tests.

282
00:57:14.770 --> 00:57:17.599
Milos: Yeah, Felix, if you want to comment on that.

283
00:57:17.600 --> 00:57:24.770
Felix: Yeah, we need to figure out the plan for this. So this is actually one of these, like all of the differences

284
00:57:25.190 --> 00:57:40.099
Felix: that we are discussing with, like the new direction, just fall out of this basic idea, that for for from the Ef side there is no goal to continue the like standalone portal client, at least not

285
00:57:40.400 --> 00:57:44.920
Felix: with the capacity that we have here. And this will also mean that.

286
00:57:45.340 --> 00:57:51.600
Felix: for example, the portal network was kind of designed so that the clients would be able to serve

287
00:57:52.170 --> 00:58:06.579
Felix: more or less the ethereum Json, Rpc. By themselves, just by being connected to the network. And this is not really the realistic view. So I guess if we want to continue testing

288
00:58:06.770 --> 00:58:13.280
Felix: standalone portal clients in hive, then we will have to

289
00:58:14.310 --> 00:58:29.250
Felix: maintain some kind of Api that we can call. But I also think that the hive testing will kind of have to change a little bit, because if we move more to this world where we want to test the

290
00:58:29.510 --> 00:58:46.040
Felix: integration of portal into the execution layer clients, then it's totally different from how it is now, because now, the hive tests just run a mainnet sync. And so they basically connect to the Internet, join the existing portal network.

291
00:58:46.340 --> 00:59:07.359
Felix: And then basically, some tests are run against the client. So these are more. These like production integration tests. It's not possible to do these tests with the execution layer client included, because we would have to sync the whole execution layer client. So the testing that we want to set up in the future is more like to run a synthetic network.

292
00:59:07.940 --> 00:59:30.230
Felix: like we do for the other execution layer hive tests. Basically the client. The execution client will be initialized with a synthetic chain. And then we will perform some basic queries against them. How this will look this is not really figured out yet, but we will need these types of tests if we actually want to get serious about

293
00:59:30.540 --> 00:59:36.370
Felix: integration of portal in the execution layout, and then, I mean

294
00:59:37.270 --> 00:59:46.830
Felix: so the the like existing way of testing was only possible because of this like immediate sync of the standalone portal client.

295
00:59:46.980 --> 00:59:55.960
Felix: And yeah, unfortunately, that's not so easy to support now.

296
00:59:58.530 --> 01:00:04.870
Felix: like with the with. I mean, it would. We would always have hit this problem sooner or later.

297
01:00:05.280 --> 01:00:08.880
Felix: Once we started integrating portal into the execution clients.

298
01:00:09.880 --> 01:00:15.279
Felix: So I guess it was just a matter of time, and we will kind of have to hit it now.

299
01:00:15.830 --> 01:00:18.518
Felix: Yeah, in general.

300
01:00:20.290 --> 01:00:28.009
Felix: it would be good, maybe, to transition on the final minutes of this call more to this question of like

301
01:00:28.710 --> 01:00:32.860
Felix: which clients are intended

302
01:00:33.440 --> 01:00:56.180
Felix: intending to continue their development, and in which way, so the as far as I understand at the moment there is the Java client, the go client Shizui, and there is the nimbus client from status. There used to be also trend, but we will not have the capacity to further develop trin. So this means

303
01:00:56.910 --> 01:00:58.600
Felix: we are left with.

304
01:00:58.840 --> 01:01:03.850
Felix: where did I? 1st of all, did I forget a client? Yes, I did. There's also a Js based one.

305
01:01:04.480 --> 01:01:07.659
Felix: Correct? Is anyone here from that implementation.

306
01:01:08.380 --> 01:01:10.230
Paul Jickling: That was with the Ef. So.

307
01:01:10.540 --> 01:01:25.470
Felix: So the Js one was also an Ef, all right. So okay, so I guess we will also not continue the Js one, for now. So this leaves us with the 3 clients, and I think all of these 3 clients have a perspective for execution, layer integration.

308
01:01:27.530 --> 01:01:38.600
Felix: the one I mean. There's also one apparently under development in never mind. But I, as far as I know, this client was never a part of the current

309
01:01:39.490 --> 01:01:43.719
Felix: testing efforts, because it's just a prototype.

310
01:01:45.570 --> 01:01:49.502
Felix: Yeah, okay, I got the thumbs up there. So

311
01:01:51.270 --> 01:02:05.159
Felix: basically, we will have to figure out from the guest side. We will schedule meeting next week with

312
01:02:05.520 --> 01:02:26.870
Felix: Shizui. I hope you guys have time to discuss the ongoing integration plans and how we will do it within status. I guess it's pretty easy for you to figure out how to do this. The remaining question is about the Java client and its integration into, for example, bisu

313
01:02:27.458 --> 01:02:32.770
Felix: I have no idea of the status of that collaboration. And or the

314
01:02:34.750 --> 01:02:44.659
Felix: How should I say like the setup for this like, maybe you can give some quick notice about the

315
01:02:46.160 --> 01:02:57.880
Felix: kind of company situation that is there, because I know that, like it's not, an it's not a project from consensus. But bisu is a project at consensus. So we would have to figure out, where is the

316
01:02:58.510 --> 01:03:03.290
Felix: yeah, how does this get done?

317
01:03:04.830 --> 01:03:11.299
Simon | Besu: Yeah, that's something we need to figure out as well. So we we're gonna be talking about that in the coming days and weeks.

318
01:03:12.240 --> 01:03:22.230
Felix: Yeah. So I think that one thing that we have established is that if we reduce

319
01:03:22.470 --> 01:03:25.709
Felix: the scope of portal network for now

320
01:03:26.130 --> 01:03:30.969
Felix: it's good because it will accelerate the development toward a

321
01:03:31.600 --> 01:03:45.109
Felix: fully productionized network. And I think this is something that I'm not sure if this came across, I'm not sure if this came across earlier in what in Matt's speech. But

322
01:03:46.420 --> 01:03:55.969
Felix: we, what we want to achieve is basically like Portal was developed for quite a while with this basically very

323
01:03:56.430 --> 01:04:24.150
Felix: wide goal of creating an alternative client for ethereum that would be able to instantly do everything trustless. And so on. The portal network was operational, but at the same time the network was always very small and was kind of mainnet only, and I think all of the debugging kind of focused on bringing up like individual parts. At the same time the portal network rapidly added features such as state network, and so on, and try to do like all the directions at once.

324
01:04:24.150 --> 01:04:26.789
Felix: we hope that with this new focus

325
01:04:28.220 --> 01:04:58.069
Felix: we will be able to get to a situation where the history network is basically like as large as the current execution layer. P. 2, p. Network. So like several 1,000 nodes. And it will basically be run fully by the community. The previous portal network was not run by. The community was mostly just run by, I guess, like, you guys like the developers of Portal. So we want to get to a world where this is actually deployed in production. And this I think we can only achieve this by focusing on just the history.

326
01:04:58.400 --> 01:05:08.920
Felix: Once we have that working, we will see it will become a platform, and if the history part is very successful, and it, you know, serves as well

327
01:05:08.970 --> 01:05:29.820
Felix: we can totally continue it more, and also try, for example, integrating perhaps the beacon network again, like we can restart the beacon network for then, but at the moment. We just don't have time for it, and we feel somehow it's easiest to execute this within a limited scope of just a handful of execution layer clients.

328
01:05:31.270 --> 01:05:34.550
Felix: So yeah, I hope you guys can.

329
01:05:35.270 --> 01:05:37.379
Felix: I hope we can actually ship it.

330
01:05:52.440 --> 01:05:54.450
lightclient: We're kind of coming up on time.

331
01:05:55.180 --> 01:06:01.979
lightclient: Is there any other things we wanted to discuss during this call before we close.

332
01:06:11.130 --> 01:06:13.947
Kim: I just wanted to ask pragmatically,

333
01:06:15.110 --> 01:06:24.380
Kim: what is up next? Are these spec changes going to be pushed to the current spec repo. Are we gonna make a new spec repo? Is this still to be decided? And.

334
01:06:24.760 --> 01:06:48.406
Felix: We discussed this as well. For the moment I think we will keep iterating on the current specs. Report with these specs. The long term perspective is for the portal specs to move into the Fp repo. This is because, we see it that if it becomes a part of the execution layer, and then it should be there. We don't want

335
01:06:49.000 --> 01:06:54.800
Felix: It's a bit unfortunate because we lost all the people at the F. Who like were

336
01:06:54.930 --> 01:07:04.419
Felix: actually, you know, actively involved in in maintaining all of these ripples. So we will have to see like which of these ripples will be surviving, and how, and

337
01:07:04.530 --> 01:07:05.165
Felix: but

338
01:07:06.310 --> 01:07:28.160
Felix: definitely. What is to be expected is that the whole infrastructure around this will be downsized, and this includes also the calls. So we have to figure out on which cadence should we meet. I guess there's also a discord server for Portal. I am a member of that, so I will check in there regularly, but it should be mentioned that I have, like

339
01:07:28.500 --> 01:07:34.490
Felix: 10 other projects at the same time, and as the Shizui developers can attest, I may sometimes disappear for a month.

340
01:07:35.130 --> 01:07:38.080
Felix: so I am not going to be the leader of

341
01:07:38.930 --> 01:07:46.950
Felix: this effort by any means. But I absolutely do want this to continue. And we just have to kind of see

342
01:07:47.110 --> 01:07:49.830
Felix: where. Yeah.

343
01:07:51.210 --> 01:08:02.776
Felix: I guess, for now we can schedule focused meetings related with specific topics. And I think this will be more productive. For example, when it comes to this,

344
01:08:03.990 --> 01:08:12.670
Felix: content, id changes from Milos. We can just schedule another meeting about it and figure out the details in that meeting.

345
01:08:13.210 --> 01:08:21.470
Felix: but I don't think we will have this like weekly calls set up that used to be there before, because there just won't be as much to discuss.

346
01:08:23.550 --> 01:08:37.649
lightclient: Yeah, I think we'll just try to do things Async and Post in Portal Dev for the time being, and as the need comes up to have a synchronous call of this format. We can do it at a more ad hoc cadence.

347
01:08:42.520 --> 01:09:00.329
lightclient: but we'll also use the regular methods of client coordination, like all core devs. To discuss the things that like really need to get discussed to. This is like part of the process of bringing together the portal project and the execution clients.

348
01:09:07.859 --> 01:09:10.510
lightclient: Okay, we're at time.

349
01:09:11.399 --> 01:09:13.659
lightclient: I think this is a good time to close.

350
01:09:14.229 --> 01:09:20.270
lightclient: We'll we'll be available on Portal Dev or over DM. Feel free to message

351
01:09:20.880 --> 01:09:34.569
lightclient: myself, Felix, or Milos, or post on one of the channels, and we'll we'll try to answer any questions that you have, and we will continue posting our updates and progress and figure out a good way to work on

352
01:09:34.670 --> 01:09:37.600
lightclient: the changes to the protocol together.

353
01:09:40.680 --> 01:09:42.680
lightclient: Great thanks, everybody.

354
01:09:44.010 --> 01:09:45.409
Milos: Oh, my! Gosh!

