00:06:30	Ansgar Dietrichs:	gm gm
00:06:53	Tim Beiko:	g(acd)m
00:07:03	potuz:	GM
00:07:27	Barnabas:	could we have ansgar as perma host?
00:07:41	Parithosh Jayanthi:	Replying to "could we have ansgar..."

My body can only take so many EIPs
00:07:43	potuz:	Lol, poor Tim
00:07:58	Barnabas:	Reacted to "Lol, poor Tim" with 😂
00:08:01	Parithosh Jayanthi:	Reacted to "Lol, poor Tim" with 😂
00:08:10	Felix (geth):	Is it Tim again?
00:08:10	Tim Beiko:	Reacted to "could we have ansgar..." with 💔
00:08:14	Tim Beiko:	Reacted to "Is it Tim again?" with 🫡
00:08:22	Tim Beiko:	Replying to "Is it Tim again?"

Unfortunately, yes!
00:08:32	Parithosh Jayanthi:	Reacted to "could we have ansgar..." with 💔
00:08:34	Parithosh Jayanthi:	Reacted to "Is it Tim again?" with 🫡
00:08:34	Felix (geth):	Replying to "Is it Tim again?"

WDYM unfortunately
00:08:36	Parithosh Jayanthi:	Reacted to "Unfortunately, yes!" with ❤️
00:08:40	Felix (geth):	Replying to "Is it Tim again?"

we missed you
00:08:47	Trent:	Replying to "Is it Tim again?"

The goat has returned
00:08:52	Tim Beiko:	Replying to "Is it Tim again?"

Did u tho
00:08:57	Tim Beiko:	Replying to "Is it Tim again?"

😄
00:08:59	Gary Schulte:	Reacted to My body can only tak... with "😅"
00:09:00	Parithosh Jayanthi:	Reacted to "Screenshot 2025-07-03 at 7.02.01 AM.png" with 😂
00:09:06	felix (eest):	Reacted to "Screenshot 2025-07..." with 📸
00:09:08	felix (eest):	Reacted to "Screenshot 2025-07..." with 😂
00:09:20	Łukasz Rozmej:	Replying to "Is it Tim again?"

those are QA's, don't mind them
00:09:20	Barnabas:	Replying to "Is it Tim again?"

with one comment I managed to get Ansgar and Tim both be mad at me 😂
00:09:22	Ben Adams:	Replying to "Is it Tim again?"

Anyone tell Tim we completely changed what was in fork while he was away?
00:09:27	Tim Beiko:	Reacted to "with one comment I m..." with 🫡
00:09:30	Gabriel Trintinalia | Besu:	Reacted to "Anyone tell Tim we c..." with 😅
00:09:33	Parithosh Jayanthi:	Reacted to "those are QA's, don'..." with 😂
00:09:35	Barnabas:	Reacted to "Anyone tell Tim we c..." with 😅
00:09:36	Barnabas:	Reacted to "those are QA's, don'..." with 😂
00:09:38	Parithosh Jayanthi:	Reacted to "Anyone tell Tim we c..." with 😅
00:09:40	potuz:	Reacted to "with one comment I m..." with 😄
00:09:40	felix (eest):	Reacted to "Anyone tell Tim we..." with 😅
00:09:45	nixo:	Reacted to "Unfortunately, yes!" with 😂
00:09:46	potuz:	Reacted to "Anyone tell Tim we c..." with 😅
00:09:55	milen | Erigon:	Reacted to "Anyone tell Tim we c..." with 😅
00:11:01	Roman:	most likely also fork id related
00:11:29	Tim Beiko:	Replying to "Is it Tim again?"

On a more serious note, the changes should all be reflected here: https://eips.ethereum.org/EIPS/eip-7600
00:11:41	Barnabas:	Maybe easier to list those that did not have issues
00:11:56	Gabriel Trintinalia | Besu:	Besu was not calculating forkdId correctly. We fixed it
00:12:05	potuz:	Prysm issue was localized to the fork transition and it's resolved, added Spec tests for them. didn't affect anything after that fork, restarting the nodes fixed it too
00:13:06	Barnabas:	💯we should test this
00:13:32	spencer-tb:	Think this was Danno’s proposal: https://eips.ethereum.org/EIPS/eip-2364
00:13:45	Trent:	Carson please stay muted 🙏
00:13:57	Gabriel Trintinalia | Besu:	eth_config 🙂
00:14:09	Gabriel Trintinalia | Besu:	https://eips.ethereum.org/EIPS/eip-7910
00:14:27	spencer-tb:	Reacted to "https://eips.ethereu..." with ➕
00:14:35	Tim Beiko:	Reacted to "https://eips.ethereu..." with ➕
00:14:36	Barnabas:	Reacted to "https://eips.ethereu..." with ➕
00:14:43	spencer-tb:	Replying to "https://eips.ethereu..."

My bad! Yeah I sent wrong link! Thx
00:15:27	Luis Pinto | Besu:	There’s a PR for best AFAIK
00:15:41	Gabriel Trintinalia | Besu:	Reacted to "There’s a PR for bes..." with ➕
00:15:59	Ameziane Hamlat:	Replying to "There’s a PR for bes..."

https://github.com/hyperledger/besu/pull/8417
00:16:06	Ameziane Hamlat:	Reacted to "There’s a PR for bes..." with ➕
00:16:07	Gabriel Trintinalia | Besu:	strong support it as well
00:16:50	Barnabas:	anyone opposed adding this to devnet 3 scope?
00:17:05	Barnabas:	CLs already have this
00:17:08	Parithosh Jayanthi:	There’s already a cl config
00:17:12	Parithosh Jayanthi:	*cl api config
00:17:17	Łukasz Rozmej:	7910 is non-consensus, can be implemented in the background
00:17:41	Barnabas:	I can gatekeep ELs on this :D
00:18:02	Barnabas:	sgtm
00:18:21	Gabriel Trintinalia | Besu:	Reacted to "I can gatekeep ELs o..." with 🙌
00:18:41	Gabriel Trintinalia | Besu:	EIP-7907: In Besu, we have two databases: the state trie and the Flat Database. The Flat Database stores the codesize directly within the account, allowing it to be retrieved without requiring a second access.

We are fine with the proposed changes:
PR 9910 – Reduce the code size limit, increase the cost per word, and fix the EXTCODESIZE issue.
CODESIZE Warm Read Removal (Draft) – Remove the warm read cost for CODESIZE.
PR 9955 – Account for large contracts at transaction entry.
00:19:32	Tim Beiko:	Reacted to "EIP-7907: In Besu, w..." with 👍
00:19:53	Ansgar Dietrichs:	If we keep 7907 in Fusaka, can we please make an explicit decision on whether the code size index is optional or mandatory for Fusaka rollout?

If mandatory, we need to have agreement around timeline and testing of the index
00:20:32	Tim Beiko:	Reacted to "If we keep 7907 in F..." with 👍
00:20:35	Barnabas:	Reacted to "If we keep 7907 in F..." with 👍
00:20:54	lightclient:	nope!
00:21:18	draganrakita:	Reacted to "EIP-7907: In Besu, w..." with 👍
00:22:23	Ansgar Dietrichs:	optional means that clients need to be comfortable with worst case performance of 100M gas blocks without the index present. I don’t think we have the benchmarking basis for that tbh
00:23:16	Łukasz Rozmej:	potential bottlenecks on IO, jumpdest analysis, memory growth
00:23:56	Marius:	Reacted to potential bottleneck... with "👍"
00:24:01	Justin Florentine (Besu):	will you be able to leverage 48 before 256?
00:25:32	Marius:	Do you need 256 on mainnet?
00:25:49	Marius:	Replying to "Do you need 256 on m..." 

 Or only on arbitrum
00:26:01	Luis Pinto | Besu:	Reacted to "potential bottleneck..." with 👍
00:27:10	Allan | Offchain Labs:	Replying to "Do you need 256 on m..."

We’d prefer to mirror mainnet exactly, rather than deviate from the exact implementation
00:27:33	Ansgar Dietrichs:	wait this was not a decision on the index
00:27:38	Ansgar Dietrichs:	Replying to "wait this was not a ..."

so is it optional?
00:27:54	Justin Florentine (Besu):	client detail, no size in state
00:27:59	jochem-brouwer:	I'll prep the perf test
00:28:03	Gabriel Trintinalia | Besu:	@jochem-brouwer  were you doing that on devnet-2, no?
00:28:04	Tim Beiko:	Reacted to "I'll prep the perf t..." with 🔥
00:28:05	spencer-tb:	Reacted to "I'll prep the perf t..." with 🙏
00:28:06	jochem-brouwer:	Yes
00:28:08	Mario Vega:	Reacted to "I'll prep the perf t..." with 🔥
00:28:25	Gabriel Trintinalia | Besu:	Reacted to "I'll prep the perf t..." with 🔥
00:28:26	Gabriel Trintinalia | Besu:	Reacted to "I'll prep the perf t..." with 🙏
00:28:50	Allan | Offchain Labs:	Replying to "Do you need 256 on m..."

It’s certainly possible for us to try the larger limit ourselves, but best case scenario is mirroring mainnet exactly!
00:28:52	Justin Florentine (Besu):	so performance testing requirement
00:29:18	draganrakita:	Replying to "wait this was not a ..."

Nethermind/geth will have its own index
Reth/besu will add field to the account.
Erigon is going to add it to bytecode table  (they have ability to read only part of value)
00:29:26	iPhone:	@Allan | Offchain Labs do you have more details on the impact of going from 24 to 48 to 96 etc?
00:29:39	Parithosh Jayanthi:	Reacted to "I'll prep the perf t..." with 🙏
00:29:59	iPhone:	Replying to "@Allan | Offchain La…"
Is it the bigger the better and the impact starts to taper off at 256 or is it just the bigger the better?
00:30:35	Justin Florentine (Besu):	i think we can make the call, we do leave the door open for a client shipping late.
00:31:02	Ansgar Dietrichs:	well it’s the only EIP in Fusaka that is a plausible new DOS vector
00:31:09	Gabriel Trintinalia | Besu:	Replying to "i think we can make ..."

Shipping later before fusaka 🙂
00:31:32	Ansgar Dietrichs:	can we have an agreement for by when we need to see these benchmarks?
00:31:36	jochem-brouwer:	I'll add those perf tests to EEST as well as benchmark so every client can test it isolated (obv. on a super small state relative to mainnet)
00:32:00	Allan | Offchain Labs:	Replying to "@Allan | Offchain La..."

Bigger is generally better! i can pull more examples, but even a simple Poseidon hash crate blows past 24KB once optimized. More complex crates and precompiles need more headroom to work with
00:32:03	Gabriel Trintinalia | Besu:	Reacted to "I'll add those perf ..." with 🙌
00:32:08	Ansgar Dietrichs:	Reacted to "I'll add those perf ..." with 🙏
00:32:15	Parithosh Jayanthi:	Reacted to "I'll add those perf ..." with 🙏
00:32:18	jochem-brouwer:	Devnet-3 needs the big contracts (12k) in the prestate but I think we will get this in genesis
00:32:30	potuz:	Reacted to "Shipping later befor..." with 😁
00:32:38	Ansgar Dietrichs:	okay then let’s just make sure we communicate to community that there is still some risk 7907 doesn’t make it into Fusaka
00:32:44	iPhone:	Reacted to "Bigger is generally …" with 👍
00:32:45	Justin Florentine (Besu):	Replying to "@Allan | Offchain La..."

a distribution curve would be fun to see, an example of a sweet spot that opens up the most inclusion
00:32:48	Parithosh Jayanthi:	Reacted to "Devnet-3 needs the b..." with 👍🏽
00:32:59	iPhone:	Reacted to "a distribution curve…" with 👍
00:33:07	nixo:	Reacted to "okay then let’s just..." with 👍
00:33:14	Barnabas:	hopefully not
00:33:19	potuz:	hopefully not!
00:33:27	potuz:	Replying to "hopefully not"

jinx
00:33:34	potuz:	Replying to "hopefully not"

second week in a row that we agree
00:33:37	potuz:	Replying to "hopefully not"

there's something wrong
00:33:45	Allan | Offchain Labs:	Reacted to "there's something wr..." with 😂
00:33:45	jochem-brouwer:	Do 48. 256 KiB w/h mandatory code size index is a big nope. Can pull 3Gib+ from disk
00:33:47	Barnabas:	Reacted to "there's something wr..." with 😂
00:33:50	Justin Florentine (Besu):	yeah, we're already a week "behind"
00:33:58	Luis Pinto | Besu:	Reacted to "a distribution curve..." with 👍
00:34:01	Marius:	Reacted to Do 48. 256 KiB w/h m... with "👍"
00:34:04	Gabriel Trintinalia | Besu:	Reacted to "Do 48. 256 KiB w/h m..." with 👍
00:34:28	Ansgar Dietrichs:	Goal for Glamsterdam should definitely be to find a good way to raise the code size limit further (or at all, in case we need to pull 7907 from Fusaka)
00:34:28	draganrakita:	Replying to "Do 48. 256 KiB w/h m..."

Don’t having index does not mean that size is not going to be saved somewhere else.
00:34:36	Tim Beiko:	https://eips.ethereum.org/EIPS/eip-7892
00:34:38	draganrakita:	Replying to "Do 48. 256 KiB w/h m..."

Index as a separate table.
00:34:40	Łukasz Rozmej:	Reacted to "Do 48. 256 KiB w/h m..." with 👍
00:34:40	Gabriel Trintinalia | Besu:	EIP-7892 –maxBlobsPerTx ->  No strong preference, but the priorities are ranked as follows:
Keep in the BPO schedule and make maxBlobsPerTx mandatory.
Already implemented across clients.
No compelling reason to move it to the PeerDAS eip.
Move to PeerDAS EIP with a 9-blob limit. If moving is necessary, prefer maintaining the current Prague limit of 9 blobs per transaction, unless there’s a good argument to reduce it.
Move to PeerDAS EIP and limit it to 6-blob per transaction
00:34:41	Mercy Boma Naps-Nkari:	Reacted to "there's something wr..." with 😂
00:35:08	draganrakita:	Replying to "Do 48. 256 KiB w/h m..."

This is really a misconception here
00:35:14	Allan | Offchain Labs:	Reacted to "a distribution curve..." with 👍
00:35:19	Allan | Offchain Labs:	Replying to "@Allan | Offchain La..."

Let me see what I can do!
00:35:20	Łukasz Rozmej:	Replying to "Goal for Glamsterdam..."

First assess if it is really needed to rise further?
00:35:21	Ansgar Dietrichs:	I thought decision was last acde to set it to 6 and not touch in BPOs?
00:35:25	Barnabas:	@FLCL your time to shine
00:35:29	Marius:	6
00:35:57	Gabriel Trintinalia | Besu:	Haven’t seen any PR
00:36:13	Tim Beiko:	Does anyone support >6?
00:36:14	iPhone:	Reacted to "Let me see what I ca…" with ❤️
00:36:16	Ansgar Dietrichs:	Replying to "Goal for Glamsterdam..."

I mean long term there should not be any cap on code size, e.g. once we chunk. should just charge proportionally
00:36:35	Luis Pinto | Besu:	Replying to "Goal for Glamsterdam..."

Would be good if offchain labs could show a distribution curve as @Justin Florentine (Besu)  suggested of where is the sweet spot
00:36:39	Barnabas:	EIP states that we use the max by default
00:36:54	draganrakita:	Replying to "Do 48. 256 KiB w/h m..."

For example:
Nethermind/geth will have its own index
Reth/besu will add field to the account.
Erigon is going to add it to bytecode table  (they have ability to read only part of value)

So nobody is going to load full bytecode but its size first
00:37:00	Francesco:	The one thing I am strongly against is using max by default
00:37:01	milen | Erigon:	Replying to "Do 48. 256 KiB w/h m..."

Agree with Dragan - we are able to read the size without loading 256kb of code and without storing the size anywhere - already mentioned this several times
00:37:04	Luis Pinto | Besu:	Reacted to "I mean long term the..." with 👍
00:37:33	Ansgar Dietrichs:	Replying to "Goal for Glamsterdam..."

it feels like status quo bias to want to keep any cap long term. we don’t have a cap on how much ETH you can have in your account. or on how many keccaks you can use.
00:37:51	potuz:	Replying to "Goal for Glamsterdam..."

This is the right question as Lukasz points, there's only indications from teams shipping on L2 AFAICT, doesn't make sense to me to add a possible DOS on L1 without any evidence of the need on it, if the only argument is an L2 trying to keep the diff minimal to the L1 client, the L1 client can make this constant configurable or easier to maintain, but risking L1 does not make sense
00:38:29	Gabriel Trintinalia | Besu:	Today the limit is 9, right? what is the reason to reduce it?
00:39:18	Barnabas:	not a fan of txpool limit only
00:39:33	Barnabas:	that would open up a bunch of attack vectors still
00:39:52	Parithosh Jayanthi:	^+1, its gonna end up via the mev workflow then
00:40:10	Tim Beiko:	Reacted to "^+1, its gonna end u..." with 👍
00:40:17	Ansgar Dietrichs:	Replying to "Do 48. 256 KiB w/h m..."

yes fair, terminology here is imprecise. when I talk about an index, what I personally mean is “a way to access the size of a contract’s code that is at worst as slow as reading a full 24kb contract” (because that is today’s worst case, and what you get charged for)
00:40:39	potuz:	+1 Francesco's point, and rollups we've talked about didn't mind the reduction as well
00:40:56	Tim Beiko:	Replying to "+1 Francesco's point..."

Reduction from 9 to 6?
00:41:18	Barnabas:	Replying to "+1 Francesco's point..."

yes
00:41:27	Barnabas:	Replying to "+1 Francesco's point..."

currently you can send a single tx with 9 blobs in electra
00:41:44	potuz:	Replying to "+1 Francesco's point..."

I'd say even less, but yes 6 is fine, and I asked a few for 3 and they seemed fine as well.
00:41:44	Tim Beiko:	I personally would lean towards the simplest possible solution (hardcode at 6 or 9 and only change in “real” forks)
00:41:47	Barnabas:	Replying to "+1 Francesco's point..."

clients would need to impl logic to kick out invalid txs at fork transition
00:42:08	draganrakita:	Reacted to "yes fair, terminolog..." with 👍
00:42:18	Ansgar Dietrichs:	Replying to "Do 48. 256 KiB w/h m..."

that also means the index is not necessary for existing contracts btw, because they are all guaranteed to be 24kb or less. so can start the index for only new contracts above 24kb after the fork
00:42:33	Gabriel Trintinalia | Besu:	Replying to "I personally would l..."

No objections to this
00:42:40	Barnabas:	Reacted to "I personally would l..." with 👍
00:42:45	spencer-tb:	Reacted to "I personally would l..." with 👍
00:42:50	Gabriel Trintinalia | Besu:	Reacted to "I personally would l..." with 👍
00:43:01	Parithosh Jayanthi:	Reacted to "I personally would l..." with 👍
00:43:05	Marius:	Reacted to I personally would l... with "👍"
00:43:08	Francesco:	Replying to "+1 Francesco's point..."

@potuz I am not sure that reducing so much would be fine if a rollup needed many more txs per slot, because you have to navigate the mempool rules around queuing up multiple blob txs, which are more strict
00:43:11	potuz:	Replying to "+1 Francesco's point..."

There's no need for this as you check for inclusion at packing, and those txs will have to be anyway bumped by the rollups that sent them. Eventually they'll be pruned even if no one bumps them
00:43:13	Marius:	Replying to "I personally would l..." 

 Yep this
00:43:23	Justin Florentine (Besu):	Replying to "I personally would l..."

same yep
00:43:36	potuz:	Base doesn't care, Arbitrum does
00:43:39	draganrakita:	Replying to "Do 48. 256 KiB w/h m..."

Yes, and we will leverage that. By  making a optional account field we don’t need to touch older accounts.
00:43:39	terence:	I dont think anyone posts more than 6 blobs per tx today right? I quickly scanned through blobscan. I will check dune now
00:43:45	potuz:	Rollups that actually have contract logic do care
00:43:50	Ansgar Dietrichs:	Reacted to "Yes, and we will lev..." with 👍
00:43:54	potuz:	Base posts to an EOA I believe
00:44:04	terence:	I think all the op stack chains post to an EOA
00:44:14	Francesco:	Reacted to "I think all the op s..." with 👍
00:44:25	potuz:	Reacted to "I think all the op s..." with 👍
00:44:59	potuz:	there's no limit now
00:45:08	spencer-tb:	It’s not specified by tx on the EIP. Only block
00:45:21	Gabriel Trintinalia | Besu:	for the same reason we should remove baseFeeUpdateFraction from bpo, and have only target and max
00:45:54	Tim Beiko:	Replying to "I personally would l..."

I would support that too!
00:46:03	Barnabas:	is that a big deal to add verification for this?
00:46:17	Luis Pinto | Besu:	Replying to "Do 48. 256 KiB w/h m..."

I don’t even get the basis for charging cold/warm for code size. Some clients pull it with the account so it’s not async computed in extcodesize. Today the cost of loading code and code size is “hidden” in account loading costs. But I can live with extra charge for code size access
00:46:19	Ansgar Dietrichs:	I feel like this should be time boxed. we already made a decision on this 2 weeks ago, it’s not obvious that there is a real need to fully have this discussion again now
00:47:04	Barnabas:	issue was that nobody made the change
00:47:07	potuz:	Replying to "+1 Francesco's point..."

Oh I was replying to @Barnabas, yes @Francesco I agree, this I know used to be a major pain point for Arbitrum's batch poster. I expect this to become worse again with Fusaka when we increase the blob trhroughput to the point the mempool has to start sharding
00:47:35	Ansgar Dietrichs:	we can also choose to do more than 6 as the hard coded limit, if people prefer that as a compromise
00:47:40	Ansgar Dietrichs:	Replying to "we can also choose t..."

9 or whatever
00:48:25	Łukasz Rozmej:	@FLCL just preferes limits in BPO ;)
00:48:39	FLCL:	Reacted to "@FLCL just preferes ..." with 😅
00:48:39	Barnabas:	Replying to "@FLCL just preferes ..."

and now he is being made to remove it lol
00:48:53	Barnabas:	Reacted to "@FLCL just preferes ..." with 😅
00:48:54	potuz:	Reacted to "and now he is being ..." with 😄
00:48:56	FLCL:	Reacted to "and now he is being ..." with 🫡
00:48:59	spencer-tb:	Reacted to "and now he is being ..." with 🫡
00:49:06	Łukasz Rozmej:	Reacted to "and now he is being ..." with 🫂
00:49:21	Roman:	Reacted to "and now he is being ..." with 🫂
00:49:23	draganrakita:	Replying to "Do 48. 256 KiB w/h m..."

@Luis Pinto | Besu I do agree with this (and for reth is overhead), but nethermind expressed concern about this, and it is always better to be extra cautious.
00:49:30	felix (eest):	Reacted to "and now he is bein..." with 🫂
00:49:37	Barnabas:	yes!
00:49:42	Gabriel Trintinalia | Besu:	yes yes
00:49:46	Parithosh Jayanthi:	Is there some reason to remove the feature when we already have it?
00:49:52	Francesco:	Replying to "+1 Francesco's point..."

I think it’s the main argument for 9…
00:49:58	Ansgar Dietrichs:	wait where is that specified?
00:50:06	Parithosh Jayanthi:	Replying to "wait where is that s..."

In the BPO config
00:50:07	Barnabas:	in blob schedule
00:50:08	Tim Beiko:	Replying to "wait where is that s..."

https://eips.ethereum.org/EIPS/eip-7892#execution-layer-configuration
00:50:11	potuz:	Reacted to "I think it’s the mai..." with 👍
00:50:28	Ansgar Dietrichs:	Replying to "wait where is that s..."

and where would be the alternative specification that would make it programmatic?
00:50:48	Justin Florentine (Besu):	new client norm: configs for users, other configs for pandas
00:50:57	milen | Erigon:	Reacted to "I don’t even get the..." with 👍
00:51:01	milen | Erigon:	Reacted to "@Luis Pinto | Besu I..." with 👍
00:53:10	Marius:	Yes, make it as explicit as possible
00:53:38	Tim Beiko:	https://github.com/ethereum/pm/issues/1601#issuecomment-3031588014
00:54:07	Tim Beiko:	https://docs.google.com/presentation/d/1mpW32f8xEWoxQBtatPdx06AFJCbOJRXC4-f26Zlk_s8/edit?slide=id.g2e0b483c83e_0_0#slide=id.g2e0b483c83e_0_0
00:55:23	Tim Beiko:	Who would be most affected if we 3x the ModExp gas price?
00:56:22	Ansgar Dietrichs:	tripling in this case does seem reasonable, but I think we should generally not make these decisions based on “there is a  // 3  in the spec that is easy to remove”. if the metrics were to indicate x2 or x2.5, we should do that instead
00:56:25	Luis Pinto | Besu:	+1 on lib diversity
00:57:04	Marius:	Replying to "Who would be most af..." 

 The problem rn is that dune seems to have a bug and we can't get great numbers from them
00:58:12	Marius:	Replying to "Who would be most af..." 

 Pwel said ecc
00:58:12	Ansgar Dietrichs:	Replying to "tripling in this cas..."

but generally agree that we should raise it and accept affecting all precompile users.
00:58:14	Łukasz Rozmej:	Replying to "tripling in this cas..."

So qeustion is do we want to reprice it again soon? Otherwise what is the target we want to go?
00:58:22	Marius:	Replying to "Who would be most af..." 

 https://etherscan.io/address/0x0000000000000000000000000000000000000005/advanced#internaltx
00:58:39	Sophia Gold:	gmp is effectively load bearing for a lot of computing. It's so commonly used I don't think it's a big deal for all clients to depend on it
00:58:54	Łukasz Rozmej:	Reacted to "gmp is effectively l..." with 👍
00:59:02	Ansgar Dietrichs:	Replying to "tripling in this cas..."

x3 in this case is probably reasonable. I would be fine with any value that makes us confident it won’t be a bottleneck before Glamsterdam
00:59:04	iPhone:	Replying to "Who would be most af…"
What’s ecc?
00:59:24	iPhone:	Probably people using RSA for 8192 bits?
00:59:26	Marius:	Replying to "Who would be most af..." 

 Matter Labs
00:59:33	Łukasz Rozmej:	Replying to "tripling in this cas..."

with 3x we could go over 200Mgas (without slot restructurization)
00:59:59	iPhone:	Replying to "Probably people usin…"
I’m not convinced that there are a lot of people doing this though
01:00:07	Ansgar Dietrichs:	what’s the devnet-3 timeline, are we certain we will have another acde before its launch?
01:00:13	Parithosh Jayanthi:	Can we make a plan as to who is investigating what?
01:00:16	Parithosh Jayanthi:	i.e what are open questions?
01:00:21	iPhone:	Replying to "Who would be most af…"
Can we ask why they are using it?
01:00:29	iPhone:	Replying to "Who would be most af…"
And what bit sizes?
01:00:34	Marius:	Replying to "Who would be most af..." 

 Coinbase Smart wallet
01:01:02	Ansgar Dietrichs:	Replying to "tripling in this cas..."

right, let’s do 3x then I’d say
01:01:10	Ansgar Dietrichs:	Replying to "tripling in this cas..."

we can always make it cheaper again in Glamsterdam
01:01:37	Marius:	Replying to "Who would be most af..." 

 Eigenda avs
01:01:51	Marius:	Replying to "Who would be most af..." 

 I don't think any of these will break
01:02:08	Marius:	Replying to "Who would be most af..." 

 But they might be a bit more expensive
01:02:27	Marius:	Replying to "Who would be most af..." 

 I think it will be negligble
01:02:34	Justin Florentine (Besu):	Replying to "Who would be most af..."

i'm fully ok with breaking a business instead of breaking the network 🙂
01:02:39	Ansgar Dietrichs:	do we know what portion of their overall gas these people spend on this precompile? I would guess it’s a super small fraction. can’t imagine a 3x price is a major hit for them
01:02:40	Francesco:	Replying to "Who would be most af..."

They will also benefit from gas limit increases like everyone else
01:03:06	Barnabas:	main modexp user not gonna say: “sure increase the cost”
01:03:13	Marius:	Reacted to main modexp user not... with "👍"
01:03:14	Mario Vega:	Reacted to "main modexp user not..." with 👍
01:03:36	Tim Beiko:	Replying to "main modexp user not..."

Well if we tell them that’s the blocker to 100M gas, they very well might!
01:03:41	Francesco:	Reacted to "Well if we tell them..." with 👍
01:03:46	Tim Beiko:	Replying to "main modexp user not..."

Eigen, Coinbase and Matter Labs all want a higher gas limit 😄
01:03:48	Parithosh Jayanthi:	Reacted to "Well if we tell them..." with 👍
01:03:58	Daniel Lehrner (Besu):	Replying to "Who would be most af..."

We can’t expect people to deploy immutable contracts when we break those afterwards. Breaking existing contracts should only ever be a last resort against attacks.
01:03:59	Mario Vega:	Reacted to "Well if we tell them..." with 👍
01:04:10	Toni Wahrstätter:	Replying to "Who would be most af..." 

 I did an analysis here:
https://github.com/nerolation/eth-7883-analysis/blob/master/eip7883_comprehensive_analysis.md
01:04:31	Francesco:	Replying to "main modexp user not..."

Yeah, I doubt even the biggest modexp user uses it enough for the downside of higher modexp gas cost to outweigh the upside of gas being cheaper in general
01:04:33	potuz:	Reacted to "We can’t expect peop..." with 👍
01:05:01	Ahmad Bitar | Nethermind:	Unless we have at least 3 different implementations, having less than 3 wont be beneficial
01:05:47	Tim Beiko:	We can agree to 3x the gas cost for devnet-3 today and worst case walk it back if ther are major issues from that
01:06:52	Ameziane Hamlat:	Reacted to "I did an analysis he..." with 👍
01:08:40	Ansgar Dietrichs:	The downside here is super asymmetric:

if we raise cost 3x, we slightly inconvenience a small % of users
if we don't raise cost, we risk not being able to deliver meaningful extra throughput to all users of the chain

seems like a super clear cut case, even if we are unsure whether that 3x price is necessary
01:09:19	Felix (geth):	again
01:09:25	Tim Beiko:	Reacted to "The downside here is..." with 👍
01:09:28	Ansgar Dietrichs:	Replying to "The downside here is..."

so “making sure we need it” should not even be a priority here - a plausible chance we need it is good enough for this decision
01:09:38	Mario Vega:	Reacted to "The downside here is..." with 👍
01:10:17	Marius:	We've been fuzzing gnark for a few years now, I feel pretty comfortable with it. The issue we found was just in marshaling code
01:10:27	Justin Florentine (Besu):	Replying to "The downside here is..."

this reasoning sounds objectively neutral to me
01:10:42	jochem-brouwer:	Antwoord verzenden naar "The downside here ..."

Also regarding repricing, just a thought, if these gas limits are hardcoded then people could indeed state things break, but this could thus also be used to take this gas pricing "hostage". I think it is clear gas prices might change and we should ship the rather aggressive 3x so we can raise the general gas limit (indeed for all users)
01:10:52	Francesco:	Reacted to "Also regarding repri..." with 👍
01:10:52	Kev:	Reacted to "We've been fuzzing g…" with 👍
01:10:59	Ansgar Dietrichs:	Reacted to "Also regarding repri..." with 👍
01:11:11	Marius:	Reacted to Also regarding repri... with "👍"
01:11:17	Ansgar Dietrichs:	Reacted to "this reasoning sound..." with ❤️
01:11:25	Ameziane Hamlat:	Reacted to "We've been fuzzing g..." with 👍
01:11:30	Francesco:	+1, clearly we’re anyway nearing the end of gas limits being able to be hardcoded and expecting they won’t break
01:11:45	spencer-tb:	For 7918, during the last ACDE, I think we agreed on changing the BLOB_BASE_COST from 2**14 to 2**13 for devnet-3. Is this still the case, we need a PR?

I think there was also 7951 repricing considerations for devnet-3 too. Is this still the case?
01:11:51	Ansgar Dietrichs:	Reacted to "+1, clearly we’re an..." with 👍
01:12:02	jochem-brouwer:	Heeft gereageerd op "+1, clearly we’re..." met 👍
01:12:08	Carson | STEEL (EELS):	Reacted to "For 7918, during t..." with 👆
01:12:13	Louis:	Reacted to "For 7918, during the..." with 👆
01:12:24	potuz:	Replying to "Unless we have at le..."

client diversity always requires at least 2 to hopefully avoid finalizing a bad block and at least 4 not 3 to avoid one client stoping finalization.
01:12:24	Francesco:	I can do it 😄
01:12:31	Carson | STEEL (EELS):	Reacted to "I can do it 😄" with ❤️
01:12:56	Gabriel Trintinalia | Besu:	which one?
01:13:02	Tim Beiko:	https://eips.ethereum.org/EIPS/eip-7951
01:13:17	Gabriel Trintinalia | Besu:	I thought we would double the price?
01:13:55	Ansgar Dietrichs:	if we don’t have more data on this, we should just 2x
01:14:08	Ansgar Dietrichs:	Replying to "if we don’t have mor..."

again, better safe than sorry
01:14:13	Carson | STEEL (EELS):	Reacted to "again, better safe..." with 👍
01:14:19	spencer-tb:	Reacted to "again, better safe t..." with 👍
01:14:25	Marius:	Reacted to if we don’t have mor... with "👍"
01:14:35	Mario Vega:	Reacted to "I can do it 😄" with ❤️
01:14:35	Gabriel Trintinalia | Besu:	Reacted to "again, better safe t..." with 👍
01:14:45	Ansgar Dietrichs:	we can aim to have all these prices more precise and with less safety buffer in Glamsterdam
01:15:25	nixo:	nope
01:15:43	Som | Erigon:	Replying to "We've been fuzzing g..." 

 It's assuring, but not enough, i think, I am no auditor myself. We need an audit sponsored by EF :P I am happy to proceed after that
01:16:05	Justin Florentine (Besu):	1 month was my instinct too
01:16:15	jochem-brouwer:	Heeft gereageerd op "if we don’t have ..." met 👍
01:16:15	Łukasz Rozmej:	IMO too many headliners already proposed
01:16:16	Ansgar Dietrichs:	I think it’s fine to extend the decision (not proposal!) deadline.

Always good to have the original plan around fastest possible Fusaka, but clearly we are not on track for that
01:16:17	jochem-brouwer:	Heeft gereageerd op "again, better safe..." met 👍
01:16:25	Ahmad Bitar | Nethermind:	Reacted to IMO too many headlin... with "➕"
01:16:29	Łukasz Rozmej:	now it is just the art of trimming
01:16:31	Barnabas:	Reacted to "IMO too many headlin..." with ➕
01:16:34	Tim Beiko:	Replying to "IMO too many headlin..."

Wait for all the other EIPs!
01:16:39	potuz:	Replying to "We've been fuzzing g..."

We have at least 5 different clients using an unaudited crypto library for hashing 😅
01:16:49	Łukasz Rozmej:	Replying to "IMO too many headlin..."

TooManyEIPsException
01:16:58	nixo:	rather than 1 month, think we should aim for some equal # of ACDEs and ACDCs?
01:17:10	potuz:	Replying to "We've been fuzzing g..."

which was only fuzzed by the EF for a couple of hours
01:17:15	Barnabé Monnot:	Reacted to "rather than 1 month,..." with 👍
01:17:16	Justin Florentine (Besu):	Reacted to "rather than 1 month,..." with 👍
01:17:18	Ansgar Dietrichs:	if we think next call is still about devnet-3, then we probably need 2 calls after that tbh
01:17:21	jochem-brouwer:	What about EIPs which are not proposed as headliner but as extras? How does this process work?
01:17:30	Parithosh Jayanthi:	Replying to "We've been fuzzing g..."

The hash tree one?
01:17:43	Sophia Gold:	We should make sure there's time to draw in attention from outside just core devs and researchers
01:17:52	Justin Florentine (Besu):	great idea, i think 2-3 calls per layer feels right. should also do some impromptu breakout rooms
01:17:54	Barnabé Monnot:	Reacted to "We should make sure ..." with 👍
01:18:35	nixo:	maybe a good time to mention that Marc & I have been working on https://forkcast.org/upgrade/glamsterdam as a resource to compare across headliners. Would love feedback on things people might find useful
01:18:41	Francesco:	Replying to "We should make sure ..."

Also from core devs and researchers 😅
01:18:42	potuz:	Replying to "We've been fuzzing g..."

yep, it's used by us, caplin, Lodestar, Teku, Nimbus
01:18:55	Ameziane Hamlat:	Just to be sure related to ModExp, we’re taking about 3X on top of https://eips.ethereum.org/EIPS/eip-7883 , correct ?
01:19:00	Ahmad Bitar | Nethermind:	Reacted to maybe a good time to... with "🚀"
01:19:00	Ansgar Dietrichs:	“these 2 calls” can you clarify, does that include the next call already?
01:19:01	potuz:	Reacted to "Also from core devs ..." with 😄
01:19:04	Peter:	Reacted to "maybe a good time to..." with 🚀
01:19:09	Tim Beiko:	Replying to "“these 2 calls” can ..."

It does not
01:19:13	Ansgar Dietrichs:	Reacted to "It does not" with 👍
01:19:15	Barnabé Monnot:	Reacted to "maybe a good time to..." with 🚀
01:19:38	Anna Thieser:	Reacted to "maybe a good time to..." with 🚀
01:19:41	Ansgar Dietrichs:	sounds like a good plan.
01:20:13	jochem-brouwer:	forkcast... this name is genius 😍
01:20:24	Mario Vega:	Reacted to "forkcast... this nam..." with ❤️
01:20:25	Tim Beiko:	Reacted to "forkcast... this nam..." with 🔥
01:20:27	Parithosh Jayanthi:	Reacted to "forkcast... this nam..." with ❤️
01:20:41	Enrico Del Fante (tbenr):	Reacted to "maybe a good time to..." with 🚀
01:20:46	felix (eest):	Reacted to "forkcast... this n..." with ❤️
01:20:49	nixo:	Reacted to "forkcast... this nam..." with ❤️
01:20:54	Ansgar Dietrichs:	Reacted to "forkcast... this nam..." with 🔥
01:21:14	Som | Erigon:	Replying to "We've been fuzzing g..." 

 I fuzzed and didn't find a pre image of a hash doesn't make the hash a good one
01:21:14	Allan | Offchain Labs:	Reacted to "forkcast... this nam..." with ❤️
01:21:17	Allan | Offchain Labs:	Reacted to "forkcast... this nam..." with 🔥
01:21:22	Allan | Offchain Labs:	Reacted to "forkcast... this nam..." with 🎨
01:21:26	Tim Beiko:	https://github.com/ethereum/EIPs/pull/9970
01:21:33	Som | Erigon:	Reacted to forkcast... this nam... with "❤️"
01:21:35	Tim Beiko:	https://github.com/ethereum/EIPs/pull/9970
01:21:51	Ansgar Dietrichs:	I think it’s fine to not be super strict about general EIP discussion though, they can already be relevant for headliner discussion.

fine to say we only make decisions once headliner(s) is locked in, but discussion should be possible
01:21:52	jochem-brouwer:	Just for clarity is there a PFI deadline already?
01:22:07	potuz:	Replying to "We've been fuzzing g..."

yeah, agreed, but the point remains, that using unaudited crypto libraries across Ethereum is something that has already sailed
01:22:48	potuz:	Replying to "We've been fuzzing g..."

at any rate, fuzzed and did a differential fuzzing against established libraries does make the hash good
01:23:06	nixo:	Reacted to "forkcast... this nam..." with 🎨
01:23:10	Justin Florentine (Besu):	Glamsterdam PFI deadline was june 20, right?
01:23:18	Ansgar Dietrichs:	Replying to "Glamsterdam PFI dead..."

just for headliners
01:23:23	Tim Beiko:	https://github.com/ethereum/EIPs/pull/9970/files
01:23:30	Justin Florentine (Besu):	Replying to "Glamsterdam PFI dead..."

ahhhhhh LFG then bring 'em on
01:23:30	potuz:	Replying to "Glamsterdam PFI dead..."

^^
01:23:39	Ansgar Dietrichs:	Replying to "Glamsterdam PFI dead..."

general EIPs will still have 2-3 months I’d expect
01:24:09	Ben Adams:	Replying to "Glamsterdam PFI dead..."

Denied for headliners become smaller EIPs ;)
01:24:15	Ansgar Dietrichs:	do we want to set some preliminary general PFI deadline for Glamsterdam already? can always extend it a bit, but just to give people a heads up
01:24:15	potuz:	Reacted to "Denied for headliner..." with 😁
01:24:32	Justin Florentine (Besu):	Replying to "Glamsterdam PFI dead..."

see, thats how we get EOF back in
01:24:40	Ansgar Dietrichs:	Replying to "do we want to set so..."

could set it to 2 months from now initially
01:24:43	potuz:	Replying to "Glamsterdam PFI dead..."

Changing the slot time is just a constant change in the spec :)
01:24:48	Łukasz Rozmej:	Can we choose multiple headliners?
01:25:01	Ansgar Dietrichs:	Replying to "Can we choose multip..."

there are no rules, we can do anything
01:25:08	Justin Florentine (Besu):	Replying to "Glamsterdam PFI dead..."

not sure which joke is scarier tbh
01:25:17	potuz:	Reacted to "not sure which joke ..." with 😅
01:25:29	nixo:	Reacted to "there are no rules, ..." with 😳
01:25:30	Barnabas:	“quick small fork” 😂
01:25:45	Barnabas:	can we do a nice big fork?
01:25:46	Ansgar Dietrichs:	fwiw I think one headliner for CL and EL each is fine
01:25:47	Justin Florentine (Besu):	1 for the EL, 1 for the CL?
01:25:49	jochem-brouwer:	big el fork? :)
01:25:53	Ansgar Dietrichs:	Reacted to "1 for the EL, 1 for ..." with 👍
01:25:59	potuz:	Replying to "Can we choose multip..."

We can rewrite the EIP to include two in one
01:25:59	Tim Beiko:	Reacted to "1 for the EL, 1 for ..." with 👍
01:26:16	Ahmad Bitar | Nethermind:	One headliner for el and one for cl?
01:26:19	potuz:	Replying to "Can we choose multip..."

I'm happy to add FOCIL to ePBS
01:26:20	Ansgar Dietrichs:	Replying to "fwiw I think one hea..."

ePBS or shorter slots for CL, BALs for EL
01:26:22	Justin Florentine (Besu):	so suggesting ePBS + BAL won't get me banned?
01:26:37	Ansgar Dietrichs:	Replying to "so suggesting ePBS +..."

not from my heart
01:26:46	Tim Beiko:	https://hackmd.io/pIZlxnitSciV5wUgW6W20w
01:26:47	potuz:	Reacted to "so suggesting ePBS +..." with 🙏
01:26:48	Justin Florentine (Besu):	Reacted to "not from my heart" with 🤝
01:26:50	Ben Adams:	Replying to "so suggesting ePBS +..."

BAL is a small EIP ;)
01:26:54	lightclient:	https://hackmd.io/@matt/eraE/edit
01:26:58	Barnabas:	Replying to "so suggesting ePBS +..."

epbs + focil + bal + gas to 200M 😄
01:27:00	Som | Erigon:	Replying to "We've been fuzzing g..." 

 It's assuring, yes, if that's okay enough. Because gnark screams that it's not "fully audited". The last audit was years ago and maybe some smart contract wallet depends on it.
Releasing it would be the "test on prod" auditing. But I can proceed if Geth does it
01:27:14	Justin Florentine (Besu):	Replying to "so suggesting ePBS +..."

don't tempt me i really want focil
01:27:16	Ahmad Bitar | Nethermind:	ePBS for cl and EOF for el ;)
01:27:35	Ansgar Dietrichs:	Replying to "so suggesting ePBS +..."

I personally think focil in H-star is fine, if we manage to ship that in H2 2026
01:27:38	FLCL:	Reacted to "ePBS for cl and EOF ..." with 👍
01:27:55	Som | Erigon:	Glamsterdam: The Big Beautiful fork
01:28:06	Ahmad Bitar | Nethermind:	Reacted to Glamsterdam: The Big... with "😂"
01:28:14	potuz:	Replying to "so suggesting ePBS +..."

it'd be great if we get EL folks to gauge the invasiveness of EL EIPs... doesn't need to be here, it can be on private messages for me lol, but I want to know which ones are actually invasive. PureETH didn't look so invasive to me, and then Cayman told me it was
01:28:20	Łukasz Rozmej:	Replying to "Can we choose multip..."

BAL+ePBS+FOCIL!
01:28:26	Gabriel Trintinalia | Besu:	Reacted to "epbs + focil + bal +..." with ➕
01:28:30	thomasthiery:	Reacted to "BAL+ePBS+FOCIL!" with ❤️
01:28:33	thomasthiery:	Reacted to "epbs + focil + bal +..." with ➕
01:29:04	Łukasz Rozmej:	Reacted to "BAL is a small EIP ;..." with 🍿
01:29:06	Storm Slivkoff:	are the receipts optional?
01:29:12	Enrico Del Fante (tbenr):	Reacted to "BAL+ePBS+FOCIL!" with ❤️
01:29:22	Daniel Lehrner (Besu):	Reacted to "BAL+ePBS+FOCIL!" with ❤️
01:29:27	Gabriel Trintinalia | Besu:	Replying to "so suggesting ePBS +..."

can you define invasiveness of EL EIPs
01:29:38	potuz:	Replying to "so suggesting ePBS +..."

@Ansgar Dietrichs The one reason I propose FOCIL+ePBS is that I believe shorter slot times cannot be done in the same fork as FOCIL, and if we don't include FOCIL and shorter slots in the G fork, then surely people will want shorter slot times in the H fork and that will delegate FOCIL for later. By the way, the same argument to have ePBS before shorter slot times I think applies for FOCIL
01:30:03	potuz:	Replying to "so suggesting ePBS +..."

@Gabriel Trintinalia | Besu Invasive as in it needs substantial changes to critical parts of code
01:30:18	Gabriel Trintinalia | Besu:	Reacted to "@Gabriel Trintinalia..." with 👍
01:30:26	potuz:	Reacted to "BAL+ePBS+FOCIL!" with ❤️
01:30:27	nixo:	Replying to "Can we choose multip..."

i dunno how serious you all are but isn’t the point of the headliner format to reduce the complexity and scope of a fork?
01:30:33	Justin Florentine (Besu):	Reacted to "@Ansgar Dietrichs Th..." with 🤔
01:30:34	thomasthiery:	Replying to "so suggesting ePBS +..."

I agree, I’ve heard multiple times that shorter slot times wouldn’t practically be combined with any other EIP basically
01:30:56	Ansgar Dietrichs:	Replying to "so suggesting ePBS +..."

@potuz that's a reasonable argument, I'd be open to considering ePBS + FOCIL as a package, but it does seem quite heavy
01:31:04	Gabriel Trintinalia | Besu:	Reacted to "BAL+ePBS+FOCIL!" with ❤️
01:31:12	potuz:	Replying to "Can we choose multip..."

FOCIL I think it's special: 7547 was included originally on ePBS and we removed inclusion lists only to make it so that ePBS doesn't touch the EL. IMO they should both be the same EIP
01:31:13	Francesco:	Replying to "so suggesting ePBS +..."

Seems pretty crazy to me 😅
01:31:24	Ahmad Bitar | Nethermind:	Replying to "Can we choose multip..." 

 @nixo i guess you are new here :p
01:31:31	potuz:	Reacted to "@nixo i guess you ar..." with 😁
01:31:37	Barnabas:	why do we have so many era formats? 

Cant we just have one to rule them all?
01:31:43	Justin Florentine (Besu):	Replying to "so suggesting ePBS +..."

ePBS, FOCIL, BAL seems like it adds up to 1.5 headliners per layer
01:31:47	nixo:	Reacted to "@nixo i guess you ar..." with 😁
01:31:54	Kev:	Replying to "why do we have so ma…"
Just one more
01:32:01	Tim Beiko:	Reacted to "Just one more" with 😂
01:32:03	potuz:	Reacted to "ePBS, FOCIL, BAL see..." with 😅
01:32:07	nixo:	Reacted to "pic-52a75ed1-6632-4b55-b54e-ad14b9c15239.jpg" with 😂
01:32:10	Parithosh Jayanthi:	Reacted to "Just one more" with 😂
01:32:15	draganrakita:	Reacted to "We can rewrite the E..." with 😂
01:32:23	Barnabas:	Why can’t we just keep iterating without making a whole new name?
01:32:23	draganrakita:	Reacted to "BAL+ePBS+FOCIL!" with ❤️
01:32:30	Łukasz Rozmej:	Reacted to "pic-52a75ed1-6632-4b55-b54e-ad14b9c15239.jpg" with 😂
01:32:31	Łukasz Rozmej:	Reacted to "@nixo i guess you ar..." with 😁
01:32:42	nixo:	Replying to "Can we choose multip..."

y’all are just too collaborative and wanna include everybody’s thing
01:32:49	Tim Beiko:	era1.1
01:32:54	Barnabas:	just call it  era
01:32:57	potuz:	Replying to "so suggesting ePBS +..."

@Francesco yeah,it's scary, but to me it seems scarier to face the shorter-slot EIP eventually without having force inclusion
01:33:07	lightclient:	that name is taken lol
01:33:11	Storm Slivkoff:	not sure that everyone would want receipts
01:33:13	jochem-brouwer:	its time for a new era
01:33:15	Barnabé Monnot:	Replying to "so suggesting ePBS +..."

oh this is the comment box where we pitch our favourites? then 6s slots for 6lamsterdam 🙂 and BAL for EL
01:33:17	Łukasz Rozmej:	Reacted to "ePBS, FOCIL, BAL see..." with 😅
01:33:19	spencer-tb:	Reacted to "BAL is a small EIP ;..." with 🍿
01:33:24	Marius:	Reacted to its time for a new e... with "😂"
01:33:25	spencer-tb:	Reacted to "epbs + focil + bal +..." with ➕
01:33:30	Parithosh Jayanthi:	Reacted to "its time for a new e..." with 😂
01:34:00	Barnabé Monnot:	Replying to "so suggesting ePBS +..."

@potuz what do you mean? shorter slots gives twice the CR, how does this mean that force inclusion is required?
01:34:29	potuz:	Replying to "Can we choose multip..."

differently than Pectra, these are really major things that we all want anyway, I think every one of us want better slot pipelining, forced inclusion and censor resistance and shorter slot times. I do not think we are trying to include things because of including others peoples EIPs, these three are major objectives that we do want. Unfortunately we can't all at the same time
01:34:49	thomasthiery:	Reacted to "differently than Pec..." with 👍
01:35:07	Ahmad Bitar | Nethermind:	Reacted to differently than Pec... with "👍"
01:35:13	Gabriel Trintinalia | Besu:	Besu has enabled it by default on its new release for new snap nodes
01:35:16	nixo:	Reacted to "differently than Pec..." with 👍
01:36:00	potuz:	Replying to "so suggesting ePBS +..."

\sim \infty \gg 2
01:36:28	Marc:	Nethermind ready to drop history
01:36:33	Ansgar Dietrichs:	Reacted to "Nethermind ready to ..." with 🔥
01:36:35	nixo:	Reacted to "Nethermind ready to ..." with 🔥
01:36:37	Roman:	checking with the team, but we should support it
01:36:40	Ansgar Dietrichs:	Reacted to "Besu has enabled it ..." with 🔥
01:36:55	Kev:	Reacted to "pic-52a75ed1-6632-4b55-b54e-ad14b9c15239.jpg" with 😂
01:37:02	Gabriel Trintinalia | Besu:	Besu last release also increased to 45M by default
01:37:11	potuz:	Replying to "so suggesting ePBS +..."

I think shorter slot times will kick out a lot of nodes (even Fusaka does) like CSM operators like myself. I believe these EIPs do explicitly affect negatively CR
01:37:15	Tim Beiko:	Reacted to "Besu last release al..." with 🔥
01:37:17	Parithosh Jayanthi:	Reacted to "@nixo i guess you ar..." with 😁
01:37:19	Parithosh Jayanthi:	Reacted to "pic-52a75ed1-6632-4b55-b54e-ad14b9c15239.jpg" with 😂
01:37:28	Barnabé Monnot:	Replying to "so suggesting ePBS +..."

2 > 1 ;)
01:37:38	potuz:	Reacted to "2 > 1 ;)" with 👍
01:38:03	Barnabé Monnot:	Replying to "so suggesting ePBS +..."

@potuz the goal is obviously not to do it in a way that kicks out nodes
01:38:26	Ahmad Bitar | Nethermind:	Replying to "so suggesting ePBS +..." 

 Cant do that qithout pipelining
01:38:28	nixo:	Reacted to "Besu last release al..." with 🔥
01:38:29	Kev:	Replying to "so suggesting ePBS +…"
6lamsterdam — I see what you did there @Barnabé Monnot
