00:02:15	Barnabas:	Ansgar > Tim
00:03:21	Ansgar Dietrichs:	Reacted to "Ansgar > Tim" with 🔥
00:03:27	Ansgar Dietrichs:	Replying to "Ansgar > Tim"

many are saying this
00:03:47	Wei Tang:	@Ansgar can we also add EOF to the Glamsterdam agenda. There hasn't been a formal introduction before for this headliner and I'd want to briefly give my perspective.
00:04:09	Barnabas:	Replying to "@Ansgar can we also ..."

EOF had many formal introductions already 😄
00:04:48	Ansgar Dietrichs:	agenda: https://github.com/ethereum/pm/issues/1569
00:05:22	stokes:	gm
00:05:22	Wei Tang:	Replying to "@Ansgar can we als..."

It does contain some changes and I'd prefer to just make sure we're on the same page.
00:06:16	Ben Adams:	bit quiet
00:06:25	EF Berlin:	better?
00:06:27	Ben Adams:	👍
00:06:28	Justin Florentine (Besu):	we can hear you, but is suboptimal. better
00:06:31	Mario Havel:	Reacted to "better?" with 👍
00:06:32	Mario Vega:	Reacted to "better?" with 👍🏼
00:06:33	Ameziane Hamlat:	Reacted to "better?" with 👍
00:06:34	Ben Adams:	Reacted to "better?" with 👍
00:06:35	Peter:	Reacted to "better?" with 👍
00:06:49	Barnabas:	Reacted to "better?" with 👍
00:07:36	Barnabas:	https://dora.berlinterop-devnet-2.ethpandaops.io
00:08:09	Barnabas:	Yes
00:08:35	Barnabas:	fusaka-devnet-2
00:08:43	Gabriel Trintinalia | Besu:	Reacted to " fusaka-devnet-2 " with 👍
00:11:45	stokes:	r1: ship it
00:12:13	Barnabas:	Reacted to "r1: ship it" with 💯
00:12:22	stokes:	Replying to "r1: ship it"

Cost should be higher
00:12:26	Mario Vega:	Reacted to "r1: ship it" with 💯
00:12:32	Luis Pinto | Besu:	Reacted to "Cost should be highe..." with ➕
00:12:51	Fredrik:	Reacted to "r1: ship it" with 💯
00:13:06	Barnabas:	Replying to "r1: ship it"

Is there a PR for the cost increase?
00:13:13	Fredrik:	Reacted to "Cost should be highe…" with ➕
00:13:29	stokes:	Replying to "r1: ship it"

no
00:13:34	stokes:	Replying to "r1: ship it"

We don’t know how to raise it
00:13:43	stokes:	Replying to "r1: ship it"

The specific number
00:14:07	Gabriel Trintinalia | Besu:	Reacted to "Cost should be highe..." with ➕
00:14:19	Barnabas:	Replying to "r1: ship it"

looks like due to gas limit changes repricing will be required either way. 

so a devnet 3 will be required either way.
00:14:47	Gabriel Trintinalia | Besu:	Replying to "r1: ship it"

🚢
00:14:55	spencer-tb:	Reacted to "🚢" with 🛳️
00:15:12	spencer-tb:	Replying to "r1: ship it"

Devnet-3 please!
00:15:17	stokes:	If we can get to an updated price Monday, that’s great
00:15:23	stokes:	But lets not block inclusion in devnet-2
00:15:25	Gabriel Trintinalia | Besu:	Reacted to "Devnet-3 please!" with ➕
00:15:26	Luis Pinto | Besu:	Yeah keep the price but revisit in other devnets
00:15:34	Gabriel Trintinalia | Besu:	Reacted to "Yeah keep the price ..." with ➕
00:16:44	Kamil Chodoła:	Perf wise doesn't seem like except modexp and log we need repricing for now
00:17:38	Som - Erigon:	Why don't we re-price the heavy precompiles with a much higher gas target in mind?
00:18:05	Louis:	Nothing returns when r1 fail or invalid signature
00:18:23	Barnabas:	lmao
00:18:32	stokes:	Consistency good
00:18:47	felipe:	Reacted to "Consistency good" with ➕
00:18:48	EF Berlin:	make the chain beautiful
00:18:57	Barnabas:	consistently unaesthetic
00:19:02	stokes:	Reacted to "consistently unaesth..." with 😂
00:19:07	EF Berlin:	Replying to "consistently unaesth..."

also known as beauty
00:19:11	stokes:	Ship it
00:19:12	Barnabas:	SENDIT
00:20:58	Potuz:	I’d like to get the audio at the EF office room, something very funny is happening there
00:21:23	EF Berlin:	Replying to "I’d like to get the ..."

just some weird stuff happening outside the window
00:21:28	EF Berlin:	Replying to "I’d like to get the ..."

nothing to worry about
00:21:36	Potuz:	Replying to "I’d like to get the ..."

Oh now please move the camera 😛
00:22:41	stokes:	Can we get 7907 in place in time for devnet-2?
00:22:44	Barnabas:	Thats a problem for future us.
00:22:56	stokes:	Could make final call on ACDT, if someone wants to put in the work over next few days
00:23:06	jochem-brouwer:	Heeft gereageerd op "Could make final c..." met 👍
00:23:10	Derek Lee:	I would like to advocate for the inclusion of EIP7907 (on behalf of Arbitrum)
00:23:12	stokes:	Replying to "Thats a problem for ..."

Metering is better than none
00:23:28	stokes:	Replying to "Thats a problem for ..."

For zk we may need code chunking, but yeah it is a problem for tomororw
00:23:51	Barnabas:	Reacted to "For zk we may need c..." with 👍
00:24:04	stokes:	Main issue  right now is just doing sufficient testing in time for spec freeze
00:24:21	Ansgar Dietrichs:	Replying to "Main issue  right no..."

spec freeze is today
00:24:32	CPerezz:	Reacted to "spec freeze is today" with 😅
00:24:39	stokes:	Replying to "Main issue  right no..."

Right and we don’t have full analysis in place :/
00:24:44	Derek Lee:	What would it take (time wise) to do that analysis?
00:24:46	stokes:	Replying to "Main issue  right no..."

I do think we should find a path to bigger contracts though
00:24:52	Ansgar Dietrichs:	Replying to "Could make final cal..."

that would mean delaying devnet-2
00:24:57	Derek Lee:	And we are confident in a smaller increase, absent of these analyses?
00:25:52	Barnabas:	I don’t think 7954 was considered anymore.
00:26:43	Łukasz Rozmej:	Maybe we can do 7907 with some "small" limits for now like 64kb, and increase it in future forks later if needed?
00:26:43	Derek Lee:	So is the current discussion EIP7907 or nothing at all (for contract size limit increases)
00:26:44	Barnabas:	can we do the same for 7907 as 7951? SFI it and allow repricing?
00:26:50	Derek Lee:	Reacted to "can we do the same f..." with 👍
00:26:54	Łukasz Rozmej:	I'm afraid of that 256kb number
00:26:56	Derek Lee:	Replying to "can we do the same f..."

Definitely in favor of this please
00:27:02	Derek Lee:	Lets do 128kb then
00:27:26	Giulio:	Maybe we should do 48kb
00:27:28	jochem-brouwer:	I can make any benchmark test we like, just need to know what we want. We should increase contract code size lim
00:28:02	jochem-brouwer:	7907 but now with 48kib lim? Instead of the 256kib
00:28:18	EF Berlin:	Reacted to "I can make any bench..." with 🚀
00:28:21	Francesco:	Reacted to "I can make any bench..." with 🚀
00:28:23	stokes:	Reacted to "I can make any bench..." with 🚀
00:28:35	Mario Vega:	Reacted to "I can make any bench..." with 🚀
00:28:40	jochem-brouwer:	👍
00:29:02	EF Berlin:	my pr to 7907 based on feedback from 7907 https://github.com/ethereum/EIPs/pull/9910
00:29:03	stokes:	We should freeze as much as we can
00:29:54	Barnabas:	we can’t freeze the spec as we already discussed we need to reprice r1
00:29:57	jochem-brouwer:	Heeft gereageerd op "my pr to 7907 base..." met 👍
00:30:00	EF Berlin:	Reacted to "we can’t freeze the ..." with 👍
00:30:10	EF Berlin:	we are going to need a devnet 3
00:30:14	EF Berlin:	that is certain
00:30:35	jochem-brouwer:	Antwoord verzenden naar "my pr to 7907 base..."

I like this PR
00:30:43	EF Berlin:	are we going to have the numbers by monday for r1?
00:30:50	stokes:	“Freeze” today should mean final EIP set
00:30:55	Barnabas:	Reacted to "“Freeze” today to sh..." with 👍
00:30:56	EF Berlin:	Reacted to "“Freeze” today to sh..." with 👍
00:30:59	Andrew Ashikhmin:	Reacted to "“Freeze” today to sh..." with 👍
00:31:05	Mario Vega:	Reacted to "“Freeze” today to sh..." with 👍
00:31:09	stokes:	Replying to "“Freeze” today to sh..."

Ok to have some details to sort out, as long as it isn’t a large number of such details
00:31:58	Ben Adams:	Replying to "my pr to 7907 based ..."

fix linting :)
00:32:09	stokes:	Ok to launch devnet-3 with the clients who are ready
00:32:14	nixo:	Replying to "we are going to need..."

blog post is already out of date 😭
00:32:15	stokes:	Esp if only a day or two for others to join
00:32:36	Potuz:	+1 I think it’s absolutely fine to launch without all ready
00:32:45	EF Berlin:	we can freeze fusaka and just say 7907 is going in
00:32:51	Barnabas:	@lightclient promised me that geth will be ready by monday
00:32:56	Derek Lee:	Reacted to "we can freeze fusaka..." with 👍
00:33:12	Justin Florentine (Besu):	"firm" >>>>> "freeze" because words mean things and freezing stuff isn't really in our culture
00:33:19	EF Berlin:	Reacted to ""firm" >>>>> "freeze..." with 👍
00:33:32	Gabriel Trintinalia | Besu:	Besu has an implementation ready, without codehash index
00:33:42	stokes:	Reacted to "@lightclient promise..." with 👀
00:34:28	Barnabas:	Reacted to "Besu has an implemen..." with 🎉
00:34:35	Roman:	reth has an implementation ready as well
00:34:49	Barnabas:	@Ansgar Dietrichs  this is the pr: https://github.com/ethereum/EIPs/pull/9910
00:35:47	Barnabas:	erigon copying geth behaviour. They start talking to each other on ACD calls 😂
00:36:39	Trent:	Reacted to "erigon copying geth ..." with 😁
00:36:47	Mercy Boma Naps-Nkari:	Reacted to "erigon copying geth ..." with 😁
00:37:08	Barnabas:	Sounds like geth/reth/besu should be gtg
00:37:28	Gabriel Trintinalia | Besu:	Reacted to "Sounds like geth/ret..." with 👍
00:39:03	Roman:	devnet 2 as specified has 7907
00:39:26	milen | Erigon:	Replying to "erigon copying geth ..."

@Barnabas this quite an unnecessary comment which shows you have very limited knowledge about Geth vs Erigon differences
00:40:13	FLCL:	devnet-2  = Jun 30?
00:40:24	stokes:	24th
00:40:39	FLCL:	(it's suggestion)
00:40:46	Barnabas:	Devnet 2 - Jun 23 - all EIPs
Devnet 3 -  Jul 7 - All final repricings
00:40:52	EF Berlin:	Reacted to "Devnet 2 - Jun 23 - ..." with 👍
00:40:52	Potuz:	I advocate not delaying devnet 2, as long as there are 2 clients ready we should start that devnet
00:40:58	EF Berlin:	Reacted to "I advocate not delay..." with 👍
00:41:00	Barnabas:	Reacted to "I advocate not delay..." with 👍
00:41:02	Gabriel Trintinalia | Besu:	Launch devnet-2 as it is, and merge the lighthouse’sPR for devnet-3?
00:41:28	stokes:	Reacted to "Devnet 2 - Jun 23 - ..." with 👍
00:41:31	stokes:	Reacted to "I advocate not delay..." with 👍
00:41:48	Barnabas:	Replying to "I advocate not delay..."

welcome back to ACD btw 😄
00:42:19	Potuz:	Replying to "I advocate not delay..."

Was promised by @ethDreamer (Mark) that LH was committing to 7732
00:42:24	Potuz:	Replying to "I advocate not delay..."

lol
00:42:28	Barnabas:	Reacted to "Was promised by @eth..." with 😂
00:42:59	stokes:	We can code chunk the bigger sizes
00:43:15	Łukasz Rozmej:	@Guillaume do you have some code chunking spec examples?
00:43:16	stokes:	I’d like to include in fusaka
00:43:23	Andrew Ashikhmin:	Include in fusaka
00:43:26	Derek Lee:	On behalf of Arbitrum, I would like to see this included in Fusaka
00:43:38	Barnabé Monnot:	Reacted to "I’d like to include …" with 👍
00:43:41	Derek Lee:	Reacted to "I’d like to include ..." with 👍
00:43:43	Derek Lee:	Reacted to "Include in fusaka" with 👍
00:43:46	Potuz:	Let’s not delay devnet 2 🙂
00:44:02	EF Berlin:	🚢
00:44:17	Barnabas:	Replying to "Launch devnet-2 as i..."

Matt has been rechristened
00:44:32	Potuz:	Are there 2 clients that have this ready for Monday?
00:44:36	stokes:	Devnet 2 as soon as clients are ready
00:44:38	Potuz:	I think that’s the question
00:44:41	Roman:	devnet 2 on Mon
00:44:46	stokes:	Replying to "Devnet 2 as soon as ..."

As in only 2
00:44:49	Giulio:	Devote 2 on Mon
00:44:49	stokes:	Replying to "Devnet 2 as soon as ..."

monday/tuesday
00:44:57	Giulio:	*devnet
00:45:00	EF Berlin:	let’s do devnet-2 then
00:45:05	Roman:	yes
00:45:06	spencer-tb:	Can we push devnet-2 to Wednesday/Thursday? We can at least get some basic tests out for 7907.
00:45:13	Giulio:	Do it without
00:45:16	Roman:	on Mon we launch devnet 2 as is today
00:45:17	Giulio:	Then add later
00:45:20	stokes:	yes
00:45:21	Som - Erigon:	7907 on devnet-3 completely
00:45:23	stokes:	Launch on monday
00:45:32	Barnabas:	Test in prod 😂
00:45:37	Potuz:	This can be added to the same devnet without needing to run on dev3
00:45:38	Barnabas:	who needs tests?
00:45:40	felix (eest):	Reacted to "Test in prod 😂" with 🔥
00:45:41	Łukasz Rozmej:	Reacted to "Test in prod 😂" with 👍
00:46:03	Potuz:	+1 Alex
00:46:10	Sophia Gold:	Sorry, what kimd of code chunking could we have in glamsterdam?
00:46:19	Louis:	Reacted to "Test in prod 😂" with 😂
00:46:21	stokes:	Replying to "Sorry, what kimd of ..."

There’s a previous EIP
00:46:24	stokes:	That would be a good starting point
00:46:25	spencer-tb:	Replying to "Test in prod 😂"

Game! Don’t want to delay
00:46:35	spencer-tb:	Reacted to "who needs tests?" with 😢
00:46:36	Trent:	lol
00:46:41	Potuz:	Reacted to "who needs tests?" with 😂
00:46:49	Trent:	Tim 🐐
00:46:53	Gabriel Trintinalia | Besu:	Either way is okay, 48kb on Monday or original spec. Tests before devnet would be perfect
00:46:59	stokes:	Replying to "Sorry, what kimd of ..."

But code chunking would be good for zk context
00:47:01	Roman:	Reacted to "Either way is okay, ..." with 👍
00:47:07	Barnabas:	Reacted to "Tim 🐐" with 💯
00:47:09	CPerezz:	Replying to "Sorry, what kimd of ..."

https://eips.ethereum.org/EIPS/eip-2926 😄
00:47:09	EF Berlin:	Reacted to "Tim 🐐" with 💯
00:47:20	Roman:	stokes is not an EL dev
00:47:21	Guillaume:	Replying to "Sorry, what kimd o..."

Yes that one
00:47:23	Barnabas:	The pr is so fresh, it needs more time
00:47:25	Ansgar Dietrichs:	Reacted to "Tim 🐐" with 💯
00:47:27	spencer-tb:	Reacted to "stokes is not an EL ..." with 😢
00:47:27	stokes:	Replying to "stokes is not an EL ..."

He is also misrepresenting me
00:47:28	Potuz:	Reacted to "stokes is not an EL ..." with 😂
00:47:29	stokes:	Replying to "stokes is not an EL ..."

Its ok tho
00:47:30	Barnabas:	so lets stick to devnet 2 spec as it was
00:47:37	Guillaume:	Replying to "Sorry, what kimd o..."

Updated with the learnings from verkle
00:47:38	CPerezz:	Replying to "Sorry, what kimd of ..."

I’d go for this and skip the EIP. The problem is that if this doesn’t happen in Glamsterdam it’s a double loss
00:47:40	nixo:	Reacted to "Tim 🐐" with 💯
00:47:40	Sophia Gold:	Reacted to "Tim 🐐" with 💯
00:47:51	Sophia Gold:	Reacted to "But code chunking ..." with 💯
00:48:10	Wei Han Ng:	Reacted to "I’d go for this and ..." with 👍
00:48:19	stokes:	Reacted to "stokes is not an EL ..." with 😂
00:48:21	EF Berlin:	Reacted to "so lets stick to dev..." with 🚀
00:48:47	Potuz:	EL clients are easy to swap on a live devnet isn’t it @Barnabas ?
00:49:02	Sophia Gold:	Replying to "Sorry, what kimd o..."

Thanks. Tbh I didn't realize there was a proposal to chunk still with the storage tries
00:49:02	ethDreamer (Mark):	Reacted to "Was promised by @eth..." with ❤️
00:49:02	Potuz:	You can launch with the full staked set
00:49:05	Łukasz Rozmej:	why do 7907 in devnet 2 if we need devnet 3? doesn't make sense for me.
00:49:12	milen | Erigon:	Reacted to "why do 7907 in devne..." with 👍
00:49:17	ethDreamer (Mark):	Replying to "I advocate not delay..."

Hell yeah lol
00:49:52	ethDreamer (Mark):	Replying to "I advocate not delay..."

Currently working on a blog for why I’m supporting 7732 for glamsterdam
00:49:53	Potuz:	It was proposed
00:50:05	Roman:	it was proposed during prioritisation, but was ignored in the process
00:50:10	Giulio:	In favour, it is already well-tested and in-devnet
00:50:46	Roman:	reth in favor
00:50:48	Barnabas:	We are not looking for potential issues, we are looking for why we want it in
00:51:01	stokes:	Replying to "We are not looking f..."

Good for contracts
00:51:06	Giulio:	Replying to "We are not looking f..."

Bitmaps
00:51:08	Potuz:	Replying to "We are not looking f..."

It saves gas
00:51:10	Giulio:	Replying to "We are not looking f..."

Makes bitmaps easy
00:51:13	nixo:	https://eips.ethereum.org/EIPS/eip-7939
00:51:14	jochem-brouwer:	Antwoord verzenden naar "We are not looking..."

gas golfing
00:51:17	Andrew Ashikhmin:	Reacted to "In favour, it is alr..." with 👍
00:51:19	Ansgar Dietrichs:	Replying to "why do 7907 in devne..."

that was my understanding as well - but apparently it was already accepted for devnet-2 last acde
00:51:19	Roman:	Replying to "We are not looking f..."

it counts leading zeros
00:52:11	stokes:	I think the process here was a bit wonky but it does seem like we are ready to ship on all other fronts
00:52:13	Łukasz Rozmej:	Replying to "why do 7907 in devne..."

we only protested the EIP (mainly due to 256kb limit) and it still got accepted… eh 🤦‍♂️
00:52:24	Gabriel Trintinalia | Besu:	Reacted to "I think the process ..." with 👍
00:52:27	Roman:	don’t set a precedent Ansgar, it WAS proposed in the past
00:52:40	Gabriel Trintinalia | Besu:	Besu in favour as well
00:52:41	EF Berlin:	Replying to "don’t set a preceden..."

it wasn’t proposed by the deadline though
00:53:05	EF Berlin:	Replying to "don’t set a preceden..."

i (light client) am in favor of it, but it technically did not get proposed in time
00:53:20	Luis Pinto | Besu:	Reacted to "Besu in favour as we..." with ➕
00:53:44	Ben Adams:	The current workarounds for not having CLZ are terrible; so for it
00:53:49	Barnabas:	Devnet 3 spec sheet: 
https://notes.ethereum.org/@ethpandaops/fusaka-devnet-3
00:53:49	stokes:	Yes 2
00:53:53	Barnabas:	Reacted to "Yes 2" with 👍
00:53:59	Gabriel Trintinalia | Besu:	Yes, devnet 2
00:54:02	spencer-tb:	Reacted to "Yes 2" with 👍
00:54:23	Vectorized (Ben):	Reacted to "The current workarou…" with ❤️
00:54:36	FLCL:	what new will be in devnet-3?
00:54:41	Potuz:	Dropping early, @Ansgar Dietrichs you’re doing a great job, you seem to be stressed, it’s not an easy job, but you’re handling it perfectly without showing any prior bias nor influencing the discussion
00:54:47	nixo:	https://github.com/ethereum/EIPs/pull/9906
00:54:51	Ansgar Dietrichs:	Reacted to "Dropping early, @Ans..." with ❤️
00:54:58	Gary Schulte:	Reacted to "Dropping early, @Ans..." with ➕
00:55:01	stokes:	Reacted to "Dropping early, @Ans..." with ➕
00:55:02	Gabriel Trintinalia | Besu:	Reacted to "Dropping early, @Ans..." with ➕
00:55:02	Christine Kim:	Reacted to "Dropping early, @Ans..." with ➕
00:55:09	felipe:	Reacted to "Dropping early, @Ans..." with ➕
00:55:22	Ben Edgington:	Reacted to "Dropping early, @Ans..." with ➕
00:55:24	stokes:	Replying to "what new will be in ..."

Any parameter changes that aren’t ready in time for 2
00:55:34	Roman:	Reacted to "Dropping early, @Ans..." with ➕
00:55:45	FLCL:	Replying to "what new will be in ..."

and https://github.com/ethereum/EIPs/pull/9906 ig?
00:55:45	Ameziane Hamlat:	Reacted to "Dropping early, @Ans..." with ➕
00:55:52	Guru:	Reacted to "Devnet 3 spec sheet:..." with 👍
00:56:00	Barnabas:	Replying to "what new will be in ..."

that needs to be still discussed
00:57:05	jochem-brouwer:	Heeft gereageerd op "Dropping early, @A..." met ➕
00:58:22	Mario Havel:	Reacted to "Dropping early, @A..." with ➕
00:59:44	Toni Wahrstaetter:	Reacted to "Dropping early, @Ans..." with ➕
00:59:47	Giulio:	We cannot do 100M without it
00:59:52	jochem-brouwer:	Heeft gereageerd op "We cannot do 100M ..." met 👍
00:59:53	felix (eest):	Reacted to "Dropping early, @A..." with ➕
00:59:54	EF Berlin:	Reacted to "We cannot do 100M wi..." with 👍
01:00:53	Anders Elowsson:	https://notes.ethereum.org/@anderselowsson/BLOB_BASE_COST
01:01:31	stokes:	IMO we should just go for 2^11 so we have the smallest change possible to achieve our goals
01:03:46	Phil Ngo:	Reacted to "Dropping early, @Ans..." with ➕
01:03:55	Barnabas:	Reacted to "Dropping early, @Ans..." with ➕
01:05:15	Caspar Schwarz-Schilling:	At a high level, 7918 was mainly chosen over a flat min blob base fee because it's more elegant to couple blob and execution fees to make sure blob basefee floor is high enough to ramp up quickly even when execution fee is very high. And then secondly, we can charge blobs something that reflects actual compute costs more accurately. When it comes to choosing BLOB_BASE_COST I would lean towards a value on the lower end, say 2**12. It fixes the ramp up problem and rules out pricing considerations.
01:05:47	stokes:	Reposting 2^11
01:07:34	EF Berlin:	i feel like we should stop changing devnet-2
01:07:52	stokes:	Replying to "i feel like we shoul..."

This is one constant
01:08:02	Barnabas:	Reacted to "This is one constant" with 💯
01:09:03	Barnabas:	I think what we need to do is talk to L2s and see if there is any actual benefit for them to have more than 6 ever
01:09:07	Barnabas:	then we don’t even need this in a config
01:09:08	stokes:	Replying to "i feel like we shoul..."

The more we can do now the better
01:09:26	Ansgar Dietrichs:	Anders can you mute?
01:09:54	Anders Elowsson:	Replying to "Anders can you mute?"

👍
01:10:19	Raúl Kripalani:	Reacted to "I think what we need…" with 👍
01:10:39	stokes:	Could even just have a single constant of 6

No need to have config data in the BPO schedule
01:10:48	Barnabas:	Replying to "Could even just have..."

this was my original idea
01:10:50	stokes:	Let me go find the PR im talking about
01:10:58	stokes:	Replying to "Could even just have..."

To have it in, or not?
01:11:13	Barnabas:	Replying to "Could even just have..."

not having it in the config
01:11:15	Francesco:	+1 on not needing more than 6, and no need to adjust it all the time
01:11:17	Barnabas:	Replying to "Could even just have..."

just clients hardcode this in their code
01:11:19	Raúl Kripalani:	And increasing it further can complicate future mempool sharding techniques
01:11:50	Barnabas:	Replying to "Let me go find the P..."

https://github.com/ethereum/EIPs/pull/9623
01:11:51	stokes:	https://github.com/ethereum/EIPs/pull/9623/files
01:12:04	stokes:	So it was put here bc we needed a way to express
01:13:12	stokes:	Yeah I can do that
01:13:15	EF Berlin:	LGTM
01:14:19	Csaba Kiraly:	Limit of 6 or 7? I think (not sure) currently one can make TXs with 7 blobs. If so, maybe setting it to 7 would make more sense.
01:14:30	stokes:	This is a mempool condition as well
01:14:39	Ben Adams:	Replying to "Limit of 6 or 7? I t..."

6
01:14:45	stokes:	So IMO cross layer (if not mostly EL scoped)
01:14:49	Csaba Kiraly:	Replying to "Limit of 6 or 7? I t..."

OK, than make it 6.
01:15:00	Ben Adams:	Replying to "Limit of 6 or 7? I t..."

Can currently do tx with 9
01:15:20	Csaba Kiraly:	Replying to "Limit of 6 or 7? I t..."

Well, not in the public mempool.
01:15:21	Ben Adams:	Replying to "Limit of 6 or 7? I t..."

but causes bad blob fills
01:15:34	stokes:	I can
01:15:37	FLCL:	it seems still useful to have an option to customize it later
01:15:37	stokes:	Make the edits
01:15:39	Csaba Kiraly:	Replying to "Limit of 6 or 7? I t..."

In the public mempool you are limited to 1MB
01:15:41	Brian:	Base is self limiting to 3 blobs per tx now for more consistent inclusion with the current 6/9 params. The one major drawback of a small per tx blob limit is that empirically it is difficult to simultaneously propagate multiple pending blob transactions into the mempool given the current gapped nonce rules.
01:15:50	Ansgar Dietrichs:	devnet-2
- EIP-7951 included, pricing as-is
- EIP-7907 included (old version, without PR)
- EIP-7934 included
- EIP-7939 included
- EIP-7918 parameter change to `2**13`
01:15:51	Francesco:	Replying to "Limit of 6 or 7? I t..." 

 Given that the users here are a handful of L2s and it was 6 until a month ago, I wouldn't worry too much about fully preserving current functionality
01:15:51	Ansgar Dietrichs:	devnet-3
- EIP-7951 pricing
- EIP-7907 new version
- per-tx blob max move to peerdas EIP
01:16:04	FLCL:	not happy seeing this was decided in 3 minutes
01:16:15	Francesco:	Replying to "Limit of 6 or 7? I t..." 

 Going back from 7 (or 9 depending on which value you care about, mempool or private) seems just fine to me
01:16:18	Barnabas:	- EIP-7918 parameter change to `2**13` to devnet 3
01:16:19	EF Berlin:	Replying to "not happy seeing thi..."

which part?
01:16:41	FLCL:	Replying to "not happy seeing thi..."

remove blobpertx limit customization
01:17:05	stokes:	Replying to "- EIP-7918 parameter..."

I will agree if it means devnet-2 sooner
01:17:07	Brian:	As the blob target and limit increase, we may need a larger per-tx blob limit in order for the L2s to actually utilize the available capacity
01:17:09	EF Berlin:	Replying to "not happy seeing thi..."

raise your hand 🙂
01:17:46	stokes:	Replying to "As the blob target a..."

We can update the limit later
01:18:04	stokes:	Replying to "As the blob target a..."

We don’t want to the per-txn number to go much higher as it becomes harder to deal w/ on the mempool
01:18:04	FLCL:	Replying to "As the blob target a..."

that's what this option was designed for
01:18:08	Brian:	Reacted to "We can update the li…" with 👍
01:18:33	nixo:	Reacted to "raise your hand 🙂" with ➕
01:18:41	Gabriel Trintinalia | Besu:	Replying to "As the blob target a..."

This is only for Fusaka, isn’t it? you still can change for the bpos
01:18:47	Barnabas:	Replying to "As the blob target a..."

couldn’t L2s just send blob txs in multiple multiple txs?
01:18:58	nixo:	https://eips.ethereum.org/EIPS/eip-7745
01:18:59	Barnabas:	Reacted to "raise your hand 🙂" with ➕
01:19:03	stokes:	Replying to "As the blob target a..."

They can, although e.g. nonce mgmt can become trickier
01:19:13	stokes:	There’s a fairly high-dimensional tradeoff space to navigate here
01:19:53	Barnabas:	Replying to "As the blob target a..."

then maybe this decision shouldn’t taken so lightly
01:19:54	Gabriel Trintinalia | Besu:	Replying to "not happy seeing thi..."

This is only for Fusaka, isn’t it? you still can change for the bpos
01:20:02	Brian:	Replying to "As the blob target a…"
Base does this now with 3-blob transactions. We tried using 1 or 2 blob txs but it's too difficult to get these propagated through the mempool consistently. This is likely due to EL rules - for example Geth will drop any blob tx with a gapped nonce.
01:20:37	Barnabas:	Replying to "As the blob target a..."

@Brian do you see base ever needing more than 6 blobs in a single tx?
01:20:46	Csaba Kiraly:	Replying to "As the blob target a..."

I’m working on reviewing those rules, but that’s also an important protection mechaism
01:20:52	FLCL:	Replying to "not happy seeing thi..."

not using schedule but with new eips
01:20:58	Csaba Kiraly:	Replying to "As the blob target a..."

So we don’t want to just “bump the numbers”.
01:22:41	Csaba Kiraly:	Replying to "As the blob target a..."

@Brian One thing I wanted to signal is that there are inherent cons of bumping maxBloblsPerTx.
If you see also advantages, we can definitely look into them.
01:22:42	Brian:	Replying to "As the blob target a…"
We see Base needing more blob throughput. We're not strongly opinionated about the number of blobs per tx as long as we can consistently post these to the L1. This means avoiding issues with block packing as well as mempool propagation issues. I could see a future where we only send 1 blob per tx if the mempool allowed
01:22:52	FLCL:	Replying to "As the blob target a..."

12blob tx can allow to increase l2 throughput by x10. Specific tool was designed to allow it later in safe manner. The tool has been just removed in 3 minutes
01:23:34	Sina Mahmoodi:	An important point about EIP-7745: it improved log search speed in geth by 20x (that’s in addition to making log query response provable)
01:23:36	Etan (Nimbus):	https://xcancel.com/sina_mahmoodi/status/1930565142183387627
01:23:43	EF Berlin:	you’re saying 1 blob per tx isn’t allowed by txpool?
01:24:04	jochem-brouwer:	Heeft gereageerd op "An important point..." met 🚀
01:24:14	felipe:	Reacted to "An important point a..." with 🔥
01:24:46	Mario Havel:	Reacted to "An important point..." with 🚀
01:25:35	Brian:	Replying to "As the blob target a…"
It's not practical if we need to post >1 blob per block. If we submit multiple transactions to an L1 node (or cluster of nodes), as they propagate through the mempool any tx could get dropped due to inclusion rules.
01:26:19	Raúl Kripalani:	Replying to "not happy seeing thi…"
increasing the limit can produce high variability in mempool bandwidth requirements. more blobs per tx actually harms tx submission to inclusion latency (takes longer to propagate). and can result in spiky shard sizes going forward (if we shard the mempool)
01:26:23	EF Berlin:	Replying to "As the blob target a..."

okay i see, the issue is more the gaps that occur during propagation
01:26:27	Brian:	Reacted to "okay i see, the issu…" with 👍
01:27:24	Brian:	Replying to "As the blob target a…"
By the time the tx makes a few hops, the probability of a nonce gap increases dramatically
01:29:08	EF Berlin:	Reacted to "An important point a..." with 🔥
01:30:33	FLCL:	such effects will be revealed with way higher blob count. And the idea is to invest further in more effective tx pool
01:31:38	Trent:	I hit "allow”
01:33:10	nixo:	https://ethereum-magicians.org/t/glamsterdam-headliner-proposal-pureth/24459
01:38:34	Wei Tang:	Doesn't seem we have time any more, so I'll move my EOF headliner discussion to next call. Anyway, just want to briefly talk about my perspective for the small new changes since it was proposed in Fusaka.
01:38:35	Csaba Kiraly:	Replying to "As the blob target a..."

We want to increase overall system level blob throughput, and we should also increase the “per-user” throughput. The two are related but slightly different goals.

The current mempool protection mechanisms were not designed for a case where one user sends 50 blobs per slot into the mempool (especially if these are not sent through the same entry point). I would say we should work on these, rather than just bumping the parameter. I think we can achieve better results this way.
01:39:06	Gary Schulte:	thx Ansgar
01:39:11	stokes:	Thank you!
01:39:20	jochem-brouwer:	👍👍
