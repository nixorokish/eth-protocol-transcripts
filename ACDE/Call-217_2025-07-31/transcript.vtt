WEBVTT

1
00:00:31.020 --> 00:00:31.910
Tim Beiko: Let me

2
00:03:56.320 --> 00:03:59.270
Tim Beiko: everyone. We'll get started in a minute or so.

3
00:04:59.210 --> 00:05:01.399
Tim Beiko: Okay, Josh, you wanna move us over.

4
00:05:07.830 --> 00:05:11.869
Justin Florentine (Besu): Happy birthday to us.

5
00:05:12.920 --> 00:05:16.160
Justin Florentine (Besu): Happy birthday to us!

6
00:05:17.020 --> 00:05:24.569
Justin Florentine (Besu): Happy birthday to my ether. Friends! Happy birthday! You're 10.

7
00:05:26.660 --> 00:05:27.620
Josh Davis: And that was like.

8
00:05:29.285 --> 00:05:31.880
Tim Beiko: Nice thanks, Justin.

9
00:05:32.750 --> 00:05:45.029
Tim Beiko: Happy birthday ethereum so officially kicking off the second decade of ethereum awkward Evs. So

10
00:05:45.520 --> 00:06:02.920
Tim Beiko: bunch of things on the agenda today, mostly some Fusaka clarifications and then talking through the rollout of the upgrade. And then we can continue the discussion around Glamsterdam headliners.

11
00:06:03.480 --> 00:06:05.845
Tim Beiko: But yes, to kick us off

12
00:06:06.500 --> 00:06:11.159
Tim Beiko: Harry or Barnabas. Do either of you want to give an Update on the Fusaka despots.

13
00:06:17.270 --> 00:06:29.629
Barnabas: Yeah, sure I can get started. So physical has been mostly stable. We have 2 sales that are a bit struggling North Star and Nimbus.

14
00:06:30.070 --> 00:06:33.000
Barnabas: so they seem to have different bugs.

15
00:06:33.350 --> 00:06:42.520
Barnabas: Loot Star is having a library. b 2 b bug, that they are debugging in the past few days or few weeks.

16
00:06:43.140 --> 00:06:49.299
Barnabas: Maybe someone from can give us an update if anyone is here. Otherwise.

17
00:06:52.850 --> 00:06:59.609
Barnabas: Nimbus had a Mev related. Bug that should be fixed now. And

18
00:07:00.450 --> 00:07:05.780
Barnabas: yeah, participation is up to 94%. So should be good to go.

19
00:07:05.960 --> 00:07:08.110
Barnabas: We're gonna be doing some

20
00:07:08.640 --> 00:07:15.139
Barnabas: perfect previous testing in the coming days, and hopefully that will also work for all the Cls.

21
00:07:19.770 --> 00:07:20.589
Tim Beiko: Thank you.

22
00:07:21.114 --> 00:07:25.379
Tim Beiko: Any client theme, or anyone else want to add anything to the dead notes?

23
00:07:31.000 --> 00:07:42.109
Tim Beiko: Okay? If not, then there were 2 issues that came up this week that we should discuss the 1st is very much an El issue

24
00:07:42.300 --> 00:07:46.200
Tim Beiko: which has to do with the and

25
00:07:46.340 --> 00:07:49.050
Tim Beiko: which which has to do with the transaction

26
00:07:49.160 --> 00:08:11.869
Tim Beiko: size capping so duncan brought this up on ethereum magicians. Saying that if we cap at 16.8 million gas it would cause some problems for some of the applications. And hired a couple a couple of them on this thread.

27
00:08:12.090 --> 00:08:16.520
Tim Beiko: I don't know if he's on the call today, and

28
00:08:18.590 --> 00:08:22.882
Tim Beiko: otherwise I saw that Tony and Vitalik had responded to this. So

29
00:08:23.870 --> 00:08:28.689
Tim Beiko: If Duncan is out here. Maybe Tony or Vitalik can give an update.

30
00:08:31.140 --> 00:08:33.119
Toni Wahrstätter: Yes, I can do so.

31
00:08:33.230 --> 00:08:37.269
Toni Wahrstätter: Yeah, I think. It's it's fair to acknowledge.

32
00:08:37.270 --> 00:08:37.640
Toni Wahrstätter: Sorry.

33
00:08:38.750 --> 00:08:40.809
ethDreamer (Mark): I wanna say Duncan is on his way. I.

34
00:08:41.690 --> 00:08:42.070
Toni Wahrstätter: Okay.

35
00:08:42.070 --> 00:08:45.250
ethDreamer (Mark): I gave him the link. He was just having trouble finding the link. But yeah, exactly.

36
00:08:45.250 --> 00:08:45.840
Tim Beiko: Right.

37
00:08:46.610 --> 00:08:49.760
Toni Wahrstätter: Yeah, I think that compatibility super important.

38
00:08:50.120 --> 00:08:53.349
Toni Wahrstätter: I think backwards compatibility is super important. But we had.

39
00:08:53.540 --> 00:08:57.100
Toni Wahrstätter: like a lot of discussions around exactly this topic.

40
00:08:57.840 --> 00:09:08.830
Toni Wahrstätter: It feels like the 30 million were just a problem for many different edge cases like the extent contract or a lot of attack vectors that's just dependent on using everything for

41
00:09:09.370 --> 00:09:20.410
Toni Wahrstätter: the for one purpose, and especially thinking of parallelization. We just get nothing from it. And then there were also concerns from Ckvms around 30 million.

42
00:09:21.020 --> 00:09:24.179
Toni Wahrstätter: So this was this were the reasons why this was lowered.

43
00:09:24.370 --> 00:09:33.970
Toni Wahrstätter: and it seemed like a good trade off between getting some more scalability, some more security without really affecting

44
00:09:34.983 --> 00:09:36.350
Toni Wahrstätter: many users.

45
00:09:39.450 --> 00:09:46.889
Tim Beiko: Okay, thanks. I see Duncan is here. Duncan, do you want to give more context on the actual issue? And then we can go to Ben.

46
00:09:47.620 --> 00:09:51.240
Duncan Townsend (0x): Yeah, thanks. Sorry about that. I had a trouble finding the the video link.

47
00:09:51.670 --> 00:09:52.360
Tim Beiko: Almond.

48
00:09:52.900 --> 00:09:57.030
Duncan Townsend (0x): Yeah. The bottom line is that

49
00:09:57.190 --> 00:10:05.099
Duncan Townsend (0x): decreasing the transaction gas limit from 30 million to 16.8 million is a breaking change for application developers.

50
00:10:05.220 --> 00:10:06.920
Duncan Townsend (0x): And

51
00:10:09.250 --> 00:10:16.560
Duncan Townsend (0x): yeah, it's causing a lot of complexity in our application. I'm sure there are other ecosystem wide impacts.

52
00:10:18.310 --> 00:10:21.599
Duncan Townsend (0x): It's frustrating

53
00:10:21.720 --> 00:10:34.579
Duncan Townsend (0x): that this change appears so late breaking. I like to think that I do keep reasonably well appraised of the acde process. And so, you know, having this change be 3 weeks out

54
00:10:34.720 --> 00:10:41.200
Duncan Townsend (0x): does not grow my confidence that a thorough ecosystem impact review was performed.

55
00:10:44.640 --> 00:10:47.560
Tim Beiko: Thanks Ben.

56
00:10:49.456 --> 00:10:54.480
Ben Adams: I mean, I'm I'm sympathetic to the the issue.

57
00:10:55.208 --> 00:10:57.580
Ben Adams: But one of the examples that uses

58
00:10:57.790 --> 00:11:02.449
Ben Adams: given that uses over 16 million, and it probably uses more now.

59
00:11:03.920 --> 00:11:09.410
Ben Adams: Was deployed in 2,021 when

60
00:11:09.690 --> 00:11:13.440
Ben Adams: the block limit was 12 million, so

61
00:11:14.090 --> 00:11:17.299
Ben Adams: it would have been possible. And that's sort of like a

62
00:11:17.790 --> 00:11:24.089
Ben Adams: a a complete loop around every single attached contract to to a pool.

63
00:11:25.502 --> 00:11:32.900
Ben Adams: So essentially, that would taken to his extreme that would need a transaction of infinite gas.

64
00:11:33.840 --> 00:11:38.609
Ben Adams: based on yeah, how it's written, because people could keep adding

65
00:11:40.710 --> 00:11:43.950
Ben Adams: pull pulls to the to the contract.

66
00:11:44.987 --> 00:11:50.450
Ben Adams: One of one of the issues is supporting

67
00:11:50.980 --> 00:11:55.250
Ben Adams: these larger transactions reduces the overall

68
00:11:55.830 --> 00:11:59.019
Ben Adams: gas that can be offered to the network.

69
00:11:59.606 --> 00:12:16.120
Ben Adams: So there's like a a balance there. So if you wanna if you wanna do more transactions, then overall and have higher block gas, then we need to reduce how much any individual transaction can do.

70
00:12:20.590 --> 00:12:22.930
Vitalik Buterin: Yeah, I mean, I could

71
00:12:23.670 --> 00:12:33.420
Vitalik Buterin: just elaborate a bit on some of the arguments I gave on magicians. Basically, I think like one is that

72
00:12:33.600 --> 00:12:53.709
Vitalik Buterin: we have had a yeah history of situations where, like we like, we historically have not followed a rule that if X is a breaking change, then X cannot be done right. And like, there have been things in the past that we have done like, for example, some of the gas limit increases are one

73
00:12:54.530 --> 00:12:55.950
Vitalik Buterin: and then

74
00:12:56.060 --> 00:13:09.882
Vitalik Buterin: some of the the removal of of self destruct is another one, and I think that one's pretty instructive because there is no case that it was secure security critical that one was

75
00:13:10.650 --> 00:13:34.339
Vitalik Buterin: very significant gain in client development simplicity. But like, if we had wanted to, we could have done without it. And I think, the yeah, like, the reason why I want to do these things is because if we don't, then effectively, we're suffering a permanent penalty in order to avoid a 1 time switching cost right? And generally. Yeah, like.

76
00:13:34.400 --> 00:13:59.229
Vitalik Buterin: the thing with invariance is that the more invariance you can have, the more they often have positive benefits to simplicity or to security, or opening up new client design, choices that often we did not even realize right. And so like with the self-destruct removal. For example, like we gave ourselves an extra invariant that bounded the number of storage slots that can change in a simple block, and that

77
00:13:59.470 --> 00:14:09.199
Vitalik Buterin: allowed a bunch of things to actually, yeah, in things in client development and caching to become quite a bit simpler. Right? So.

78
00:14:09.700 --> 00:14:14.389
Vitalik Buterin: I, yeah, would argue that also the kinds of breaks that are

79
00:14:14.930 --> 00:14:40.943
Vitalik Buterin: here, like, they yeah will happen in the context of things that we want to do in the future, like multi dimensional gas, like per coach chunk gas, pricing like, very serious repricing of breaking piles. And so I do think that we need a procedure for being able to do to do things like this?

80
00:14:41.720 --> 00:14:49.319
Vitalik Buterin: I, yeah, right? I think, is that. Yeah. See? Is, is that a breaking change or not? I mean from the

81
00:14:50.260 --> 00:15:12.220
Vitalik Buterin: arguments that I've right. The question is also like, is the way that we've looked at these things historically is like breaking for how many users right? And like what level of inconvenience? Right? Because, like, if there's an application that has no natural path for rewriting itself, that's 1 thing. But if on the other hand, we're just talking about like, for example.

82
00:15:12.220 --> 00:15:24.330
Vitalik Buterin: any of the like bot activity, like, I'm personally, yeah, totally fine. Making changes that force mev bots to read to rewrite their code. Right? So

83
00:15:24.360 --> 00:15:28.784
Vitalik Buterin: it's like, like, that's 1 of the balances. I mean, I do think we should.

84
00:15:29.630 --> 00:15:38.539
Vitalik Buterin: How be more thoughtful to having a procedure having a a procedure for this? I mean, I am like perfectly happy

85
00:15:38.710 --> 00:15:45.990
Vitalik Buterin: deal delaying things like this. I'm also, I'm happy. Yeah, to

86
00:15:46.450 --> 00:15:58.776
Vitalik Buterin: like having having time delays and and explicit deprecations is, I think, something that's good. Having explo explicitly. Yeah, like, specified invariance is

87
00:15:59.770 --> 00:16:02.252
Vitalik Buterin: good having,

88
00:16:04.930 --> 00:16:19.450
Vitalik Buterin: you know. And we continuing to like, have lists of things that we keep in mind as we change gas per gas prices is or is good so

89
00:16:19.883 --> 00:16:34.430
Vitalik Buterin: right, wouldn't 30 million per transaction be enough? I think the one use case that I would worry about there is distributed proving right? Because, like, basically a yeah, distributed prover is going to be yeah.

90
00:16:34.430 --> 00:16:58.685
Vitalik Buterin: constrained by yeah, like, basically like the way that it parallelizes is it paralyzes across different participants? Right? And the way Ckvms work is that, like basically, all of them, they parallelize between transactions. They don't parallelize within transactions because parallelizing within transactions is like 10 times harder. Right? And so we yeah, the like. The value is

91
00:16:59.490 --> 00:17:14.319
Vitalik Buterin: basically that the more we can like right now, probably. Yeah, there, we're not going to be in a position even with like a 10 x improvement in proof of time to be able to say, Well, let's

92
00:17:14.690 --> 00:17:40.529
Vitalik Buterin: have a distributed prover that would actually be able to handle a worst case block which involves a single prover keyword transaction. That's across 30 million gas, right? Yes. And even when non-distributed, these kinds of things are an issue, right? So I think, in terms of right, also paralyzable execution. I mentioned that right? So just like in terms of worst case mitigations.

93
00:17:40.530 --> 00:17:57.949
Vitalik Buterin: There's a huge number of these like weird edge cases that exist within transaction boundaries that just don't exist at all between transaction boundaries, because between transaction boundaries, like basically all over the State gets flushed. I mean, except for obviously in the state tree itself. So

94
00:17:58.280 --> 00:18:01.350
Vitalik Buterin: that's kind of how I yeah.

95
00:18:01.530 --> 00:18:20.309
Vitalik Buterin: I would argue the case for doing things like this. In principle. I mean, I definitely don't have a strong opinion personally about timing. And like, I'm actually yeah, like, I think it's reasonable to be conservative on timing for for things that break things.

96
00:18:24.830 --> 00:18:29.669
Tim Beiko: Thank you. There were a couple of comments in the chat. I don't know if anyone

97
00:18:30.330 --> 00:18:32.560
Tim Beiko: wants to speak up about them.

98
00:18:33.750 --> 00:18:38.840
Duncan Townsend (0x): Yeah, I I was asked to explain the use case.

99
00:18:39.670 --> 00:18:50.326
Duncan Townsend (0x): yeah. So you know, to be clear. I'm not arguing for no limit. I think having a limit is a really really good idea, especially in as much as it means

100
00:18:51.540 --> 00:18:52.170
Duncan Townsend (0x): It

101
00:18:52.410 --> 00:18:59.680
Duncan Townsend (0x): unlocks scalability, parallelism, and also constrains the design space for dap developers and makes it easier to reason about the system.

102
00:18:59.800 --> 00:19:14.370
Duncan Townsend (0x): Really, all I'm arguing is that the limit of 16.8 million is too low. Specifically my use case. You know, I can't speak to the was it 100 and something 1 million gas that the

103
00:19:14.480 --> 00:19:23.060
Duncan Townsend (0x): contract I link to consumes today, but I can talk about the transactions that I develop, which

104
00:19:23.300 --> 00:19:36.729
Duncan Townsend (0x): on chains with oh, I suppose I should back up and say I represent 0 XA dex aggregator. So we're building Erc 20 swaps that will touch a whole bunch of different pools to achieve best price.

105
00:19:38.505 --> 00:19:39.470
Duncan Townsend (0x): And

106
00:19:40.920 --> 00:19:50.199
Duncan Townsend (0x): when gas is cheap and liquidity is highly fragmented, as we see on many. Evm. L. 2 s. 16.8 million. You can blow past that in a

107
00:19:50.340 --> 00:20:16.050
Duncan Townsend (0x): $100 $1,000 swap fairly easily, and if we scale l. 1 and bring execution costs down on l 1, we would likely see similar gas consumption for low notional swaps. And so the problem is that the problem of optimal Dex aggregation routing under a low gas limit is Np-hard

108
00:20:17.300 --> 00:20:18.140
Duncan Townsend (0x): which

109
00:20:18.490 --> 00:20:36.739
Duncan Townsend (0x): we've developed approximations for and can solve this problem in production, but it significantly increases the problem, and I think is one of the reasons why you don't see a thriving competitive Dex aggregation ecosystem on chains like Solana, because that constraint is so low and the problem is so difficult.

110
00:20:38.900 --> 00:20:43.580
Duncan Townsend (0x): So, for reasons of competitiveness, I think increasing the limit

111
00:20:44.020 --> 00:20:49.500
Duncan Townsend (0x): to the historical block gas limit of 30 million is a very good idea.

112
00:20:54.435 --> 00:20:56.669
Tim Beiko: Let's do, Ben. And then Tony.

113
00:20:58.626 --> 00:21:06.123
Ben Adams: How much is the gas on on the aggregation from storage versus

114
00:21:06.820 --> 00:21:11.820
Ben Adams: calculations? So would, for instance, repricing

115
00:21:12.370 --> 00:21:15.800
Ben Adams: non storage opcodes down which is planned.

116
00:21:15.900 --> 00:21:17.320
Ben Adams: Help resolve that.

117
00:21:18.950 --> 00:21:20.899
Duncan Townsend (0x): Most of the time.

118
00:21:21.100 --> 00:21:27.449
Duncan Townsend (0x): and you know this depends very heavily on a lot of specifics, but most of the time you are storage. Limited

119
00:21:27.710 --> 00:21:37.629
Duncan Townsend (0x): exceptions would be things like Pendle finance curve finance. Really anything that has to do Newton-raphson approximation of a constant function.

120
00:21:40.760 --> 00:22:04.679
Duncan Townsend (0x): The reason why you couldn't do 2 transactions is atomicity. Slipper checking has to be performed at the end of a swap, and so you need to be able to roll back the entire swap from the moment the user's tokens are moved in order to achieve that atomicity and avoid some really bad impacts of Mev. And so you know, again, with Solana, making the comparison.

121
00:22:04.830 --> 00:22:22.300
Duncan Townsend (0x): not being able to achieve that atomicity in protocol causes people to seek out of protocol solutions which are typically centralized because you're making a promise for multi transaction atomicity that you can only guarantee based on some sort of handshake agreement rather than you know, actual crypto economic security.

122
00:22:29.660 --> 00:22:30.700
Tim Beiko: And Tony.

123
00:22:33.400 --> 00:23:02.163
Toni Wahrstätter: Yeah, I think the the concerns here are totally valid. And I and I want to stress that I definitely acknowledge them. And also, I hope this you had that feeling during my the magician's replies, but I think in the end it's just a trade off, and we have to take a decision on where we put that point. Now, we are at 45 million. So 30 million, we can be like, okay, hopefully, there was no use case in the meantime. That needs those

124
00:23:02.710 --> 00:23:05.930
Toni Wahrstätter: additional 50 million guests. I think that's a fair assumption.

125
00:23:06.100 --> 00:23:13.650
Toni Wahrstätter: But I still think I'm going to 60 million, which is currently the default on the defnets.

126
00:23:13.780 --> 00:23:21.709
Toni Wahrstätter: Is, is there a better choice? Just because we get those additional benefits from parallelization?

127
00:23:21.890 --> 00:23:26.509
Toni Wahrstätter: And of course we affect slightly more users.

128
00:23:26.660 --> 00:23:31.160
Toni Wahrstätter: but if this is exactly the trade-off here, we will always affect some users.

129
00:23:31.360 --> 00:23:35.349
Toni Wahrstätter: but other users will benefit from us, being able to scale.

130
00:23:35.500 --> 00:23:42.129
Toni Wahrstätter: And yeah, so totally valid. But I still think we should stick to the limit that we have.

131
00:23:51.980 --> 00:24:06.336
Tim Beiko: Yeah, I I guess, like, yeah, the define. The actual limit is maybe part of the question is, you know, we originally had 30 sets, because it was, I think, the gas limit when the eip was drafted. And obviously the gas that gets gone up since then.

132
00:24:06.740 --> 00:24:11.920
Tim Beiko: And then it got lowered at the the 16.8 or something. But is there a number

133
00:24:12.610 --> 00:24:17.329
Tim Beiko: like, yeah, if we did it, the 20? Or is there some number today that we feel would

134
00:24:17.710 --> 00:24:26.896
Tim Beiko: actually allow most. You know, large use cases that have been used in productions that are like somewhat reasonable.

135
00:24:28.370 --> 00:24:31.580
Tim Beiko: and yeah, we're still asked about it, and.

136
00:24:36.800 --> 00:24:40.310
Toni Wahrstätter: Just from the numbers we know that around. So in

137
00:24:40.530 --> 00:24:51.569
Toni Wahrstätter: I did a 6 6 month analysis and the 3 years analysis. And it's around 0 point 0 3 8. So 0 point 0 4% of the

138
00:24:51.750 --> 00:24:54.760
Toni Wahrstätter: transactions that were affected. And

139
00:24:54.920 --> 00:25:07.530
Toni Wahrstätter: it's even lower for the users, because it's mostly people that use certain contracts. So I think the vast majority of them was Xen. So different accounts using the Xen contracts. This accounted for like

140
00:25:07.750 --> 00:25:19.879
Toni Wahrstätter: the majority of it. I don't remember how much, but I think like 30, 40, 50%. And then there were a lot of batch use cases like batch ens registrations and batch payouts, and all that kind of stuff that.

141
00:25:20.180 --> 00:25:21.480
Tim Beiko: Do you have a link to this.

142
00:25:21.480 --> 00:25:22.040
Toni Wahrstätter: Edged.

143
00:25:22.250 --> 00:25:24.339
Toni Wahrstätter: Yes, I have a link.

144
00:25:24.460 --> 00:25:32.270
Toni Wahrstätter: Let me. I post it into the. I will post it into the Acd discord right now, because I am on a different device than mine.

145
00:25:33.260 --> 00:25:37.200
Toni Wahrstätter: like, let me check here.

146
00:25:38.050 --> 00:25:39.820
Toni Wahrstätter: Okay. I posted it right now.

147
00:25:41.490 --> 00:25:42.389
Tim Beiko: Okay, thank you.

148
00:25:43.165 --> 00:25:49.814
Tim Beiko: I'll cross post it in the chat here just for people referencing. Oh, thanks. Josh,

149
00:25:57.300 --> 00:26:19.835
Tim Beiko: yeah. And I guess. Yeah. So there's a trade off here. 1 1 approach we could take is, you know, we set a relatively high limit with the expectation it might go down in the future. The problem is, then, as soon as we set the limits, people will rely on it for something. So there's a risk that if we say, Hey, we do 30 million in this fork, and we want to take it down in the next fork.

150
00:26:20.870 --> 00:26:26.636
Tim Beiko: you know, like there, by the time the next fork happens we

151
00:26:27.330 --> 00:26:31.382
Tim Beiko: by the time the next project happens we we can't lower it.

152
00:26:32.740 --> 00:26:35.760
Tim Beiko: but yeah, we could also commit the same like.

153
00:26:36.100 --> 00:26:44.100
Tim Beiko: we put a hard limit today at 30 million. And then we deprecate these yeah.

154
00:26:44.350 --> 00:26:49.532
Tim Beiko: So it's actually pass some amount on the next fork, and it gives time for people to migrate.

155
00:26:51.990 --> 00:26:56.899
Tim Beiko: and I guess on the like, yeah, on the 0 X use case, like, what would happen

156
00:26:57.170 --> 00:27:04.911
Tim Beiko: if this cap existed today, and someone was trying to do a transaction that you know touched a bunch of routes.

157
00:27:05.720 --> 00:27:10.000
Tim Beiko: is it just that the transaction would fail. Would the 0 X,

158
00:27:10.310 --> 00:27:16.749
Tim Beiko: I assume the ui, or you know, the front end is able to catch this in the wallet to some way that like?

159
00:27:18.350 --> 00:27:19.669
Tim Beiko: Yeah, well, what? Like.

160
00:27:20.250 --> 00:27:20.650
Duncan Townsend (0x): Yeah, I mean.

161
00:27:20.650 --> 00:27:23.580
Tim Beiko: User like, what what would the experience be if, like you.

162
00:27:23.980 --> 00:27:26.149
Tim Beiko: you try to exceed this limit today?

163
00:27:27.400 --> 00:27:36.920
Duncan Townsend (0x): Well, so today, it's a non-issue for Xerox, because we've developed the technique for handling this and producing optimal routes under the limit.

164
00:27:37.120 --> 00:27:43.579
Duncan Townsend (0x): And it's actually probably better for us because it cements our position in the ecosystem.

165
00:27:43.830 --> 00:28:03.650
Duncan Townsend (0x): What I'm saying is that the problem is, if you want there to be more competition in the solver searcher, aggregator ecosystem. Then you are raising the minimum level of technical skill required in order to produce valid routes by requiring that they also solve for the transaction gas limit.

166
00:28:04.170 --> 00:28:11.819
Duncan Townsend (0x): because right now the problem is largely limited by profitability due to the relatively higher gas prices on l. 1 compared to L. 2.

167
00:28:13.220 --> 00:28:16.870
Tim Beiko: And so the gas, the transaction gas limit is very rarely a problem.

168
00:28:17.980 --> 00:28:18.380
Duncan Townsend (0x): Right.

169
00:28:18.380 --> 00:28:28.870
Duncan Townsend (0x): If if a potential Dex aggregator were to produce a route that's above the limit, the front end would catch it immediately. Because you can't. You obviously can't submit a transaction with that high of a limit.

170
00:28:31.290 --> 00:28:33.280
Tim Beiko: Got it. Thanks. And I guess.

171
00:28:34.720 --> 00:28:41.029
Tim Beiko: is there a future where we would imagine going even below the 16 million? Because,

172
00:28:42.320 --> 00:28:50.229
Tim Beiko: yeah, I I maybe don't have an intuition, for what's the lowest we would actually consider if is that 16 million, or is that

173
00:28:50.340 --> 00:28:51.080
Tim Beiko: yeah?

174
00:28:52.060 --> 00:28:56.213
Tim Beiko: Is there an argument to say should be, you know, 10 million or 8 million

175
00:29:00.570 --> 00:29:02.040
Ben Adams: I mean 6

176
00:29:02.290 --> 00:29:10.020
Ben Adams: at 16 million. That's 16 million, for, like 45 million gas, you're looking at 3 transactions that can be run

177
00:29:10.707 --> 00:29:18.110
Ben Adams: in parallel. And then, you know, when we go to a hundred 1 million,

178
00:29:18.860 --> 00:29:23.410
Ben Adams: yeah, it's it's a lot more. And we're specifying that you need 8 cores.

179
00:29:23.840 --> 00:29:31.770
Ben Adams: I'm run a validator. So essentially saying, Well, you can't use it. This entirely single threaded is.

180
00:29:32.410 --> 00:29:40.449
Ben Adams: you know, wasteful because we have the capacity to increase using parallelism, but setting the

181
00:29:41.373 --> 00:29:48.629
Ben Adams: the limit higher causes of the worst case to get worse. But setting the limit lower

182
00:29:48.820 --> 00:29:53.239
Ben Adams: in the situation where the block gas is getting higher. I don't think necessarily gains much.

183
00:29:57.160 --> 00:29:59.589
Tim Beiko: Vitalik, you're gonna say something.

184
00:29:59.810 --> 00:30:06.639
Vitalik Buterin: Yeah, I mean, I've like, thought about this. And even talked through some

185
00:30:06.730 --> 00:30:27.119
Vitalik Buterin: defi people. And like, there is a case to be made that a kind of theoretically spherical cow better ethereum would be if you push the gas, the transaction gas cap all the way down potentially to low millions, but with some specific carve outs for contract for contract creation.

186
00:30:27.120 --> 00:30:49.450
Vitalik Buterin: Obviously as but like, the reality is that the benefits of doing that are low. So like one. Basically, in all of the cases where there are benefits of doing that, you could do specific stuff like, say, only low gas transactions are eligible for fossil or only low gas transactions are eligible for

187
00:30:49.530 --> 00:30:55.332
Vitalik Buterin: account. Some account abstraction, feature, or something similar. So it's

188
00:30:56.130 --> 00:31:16.689
Vitalik Buterin: like, the balance is basically, yeah, getting like, how much you you would get in terms of some of these nice separate, nice properties in terms of like client side paralyzability and dealing with quadratic attacks, and so on. I mean, like, what's what this brings to mind. Right is back in 2,016. When we had

189
00:31:16.690 --> 00:31:26.609
Vitalik Buterin: our most serious dos attacks, we pushed to the gas limit all the way down 500 k. And that actually like, let the chain run while while those bugs were

190
00:31:26.950 --> 00:31:32.569
Vitalik Buterin: unresolved. So. But it's like once you.

191
00:31:32.700 --> 00:31:51.850
Vitalik Buterin: you go lower the yeah. Like. Benefits do get accrue. Keep accruing. But the returns start marginally down like start decreasing quite a bit, and also the costs start increasing increasing quite a bit. Right? So like once you go into

192
00:31:52.000 --> 00:32:17.030
Vitalik Buterin: single digit below single digit millions then I think, starks start start becoming impossible. And then potentially. They're like just the number of people that have to rewrite keeps going up so like, I like, I, personally would like, don't feel a strong need to start pushing into like

193
00:32:17.590 --> 00:32:21.680
Vitalik Buterin: lower, single digit millions or anything like that. And like.

194
00:32:23.530 --> 00:32:28.959
Vitalik Buterin: I, I feel like, Oh, there we go! That's a good dash.

195
00:32:29.420 --> 00:32:38.080
Vitalik Buterin: a good chart from from Tony. There, that just shows how the portion of stuff that breaks is like base, basically exponential.

196
00:32:41.590 --> 00:32:57.060
Tim Beiko: Thanks. And, Daniel, yeah, thanks for putting the sorry to go, Tony. And then Daniel said that you know if we remove the contract size limits, then the transaction gas limit also becomes in a way, the the contract size limit.

197
00:32:59.980 --> 00:33:13.040
Tim Beiko: my proposal to move this forward would be to consider having the limit be 20 million instead of 16. It seems like it addresses some of the cases that were that were raised.

198
00:33:13.040 --> 00:33:37.999
Tim Beiko: I also think 20 million is maybe a nice number, because the gas limit is 40 or 36 million. Now we expect, or sorry 45 million. We expect to probably go to 60 ish around Fusaka. And so 20 million gives us the ability to actually run. In the worst case, you know, 2 transactions, 3 transactions in parallel. If we're if we're doing parallel execution, whereas if we're at 30,

199
00:33:38.080 --> 00:33:44.490
Tim Beiko: it's like until we raise the gas limit to 60 million, there's still cases where maybe we're not able to

200
00:33:44.650 --> 00:33:46.710
Tim Beiko: to to paralyze. So I

201
00:33:49.960 --> 00:33:56.800
Tim Beiko: yeah, I don't. That would be my proposal, and that you know, this this 16 million number was

202
00:33:57.230 --> 00:34:03.286
Tim Beiko: basically just the power of 2. So if 20 is slightly better,

203
00:34:05.480 --> 00:34:08.029
Tim Beiko: yeah, I think we could make that change. And.

204
00:34:10.820 --> 00:34:15.109
Toni Wahrstätter: Yeah, I think it us into one direction of the trade-off.

205
00:34:15.650 --> 00:34:17.249
Toni Wahrstätter: We should be aware of that.

206
00:34:19.960 --> 00:34:25.170
Tim Beiko: Yeah. And I think the feedback we've gotten is we're a bit too far in the other direction. But yeah, that's good.

207
00:34:25.770 --> 00:34:33.759
Duncan Townsend (0x): Yeah, yeah, I just put out a call to some of our data guys at Xerox to do some analysis for like

208
00:34:34.300 --> 00:34:44.909
Duncan Townsend (0x): gas consumption by notional trade size on low gas. L, 2 s. So I can also provide you guys some some hard numbers specifically for Dex aggregation on the impact of this eip.

209
00:34:45.679 --> 00:34:47.049
Duncan Townsend (0x): But that'll be later today.

210
00:34:47.340 --> 00:34:50.988
Vitalik Buterin: Yeah, perfect. And would you mind like also finding some

211
00:34:51.440 --> 00:34:59.380
Vitalik Buterin: transaction hashes? I think, like specifically of some of these like, create, like massively multi atomic arbitrage, things.

212
00:35:00.641 --> 00:35:03.719
Duncan Townsend (0x): Yeah, we're not in the business of arbitrage. But but yeah, right? Right? I know.

213
00:35:03.720 --> 00:35:04.580
Duncan Townsend (0x): Yeah, it is.

214
00:35:04.580 --> 00:35:06.100
Vitalik Buterin: Oh, sure! Me too.

215
00:35:08.120 --> 00:35:11.860
Tim Beiko: Okay? And so I guess there's 2 things you can do, either. We

216
00:35:12.910 --> 00:35:18.700
Tim Beiko: like soft agreed to go to 20 million dollar 20 million gas now, and if we

217
00:35:19.157 --> 00:35:25.819
Tim Beiko: if we find something that disproves that being a good number, we change it again, or do we prefer to wait?

218
00:35:27.340 --> 00:35:49.480
Tim Beiko: a week or 2 to make the final call. This kind of ties into the fork deployment cycle like if we need to write some tests and update the clients. I I imagine this is fairly simple. But yeah, the clients have a preference between coming to a decision now and potentially reversing that or waiting a week or 2.

219
00:35:49.960 --> 00:35:52.439
Tim Beiko: and and yeah, having it be more final.

220
00:35:52.560 --> 00:35:53.620
Tim Beiko: Maru.

221
00:35:54.330 --> 00:36:17.899
Mario Vega: Yeah, I would like for us to make the least amount of changes possible, because it has not been easy to go through all the static legacy tests and finding out which ones break because of these transaction gas limits, has been extremely hard to put it like softly, and so the least amount of changes that we do. The transaction that has limit cap the better in the testing.

222
00:36:17.900 --> 00:36:18.370
Tim Beiko: And right.

223
00:36:18.370 --> 00:36:18.870
Mario Vega: Okay.

224
00:36:19.230 --> 00:36:24.379
Tim Beiko: And right now the testing team is assuming we're doing 16.8, not 30. Is that correct?

225
00:36:24.380 --> 00:36:27.090
Mario Vega: Exactly 60 million is the is the one that we.

226
00:36:27.090 --> 00:36:29.620
Tim Beiko: Okay, then, in that case let's

227
00:36:29.810 --> 00:36:42.680
Tim Beiko: leave it at that, for now. Get the numbers, and if we are to change it, we make that decision on the next call 2 weeks from now. And this gives us 2 weeks. And I,

228
00:36:43.390 --> 00:36:46.890
Tim Beiko: if if we were to change it in 2 weeks, Mario, like I'll

229
00:36:47.650 --> 00:36:54.530
Tim Beiko: big of a change. Would it be 10 like once you've identified all these tests? Is it easy to go back? And

230
00:36:55.310 --> 00:36:56.060
Tim Beiko: you know.

231
00:36:56.240 --> 00:37:21.370
Mario Vega: Yeah. So the approach is that we have to analyze what exactly test is doing to be able to not break it. And still, like, provide test coverage for these legacy tests. We have the the procedure now. We didn't have. We had not done this before. So we now have the procedure, it should be easier, but I I still would like lean towards changing it least less frequently as possible. In my opinion.

232
00:37:21.670 --> 00:37:26.789
Tim Beiko: So less frequently and later, is better for you than more frequently and sooner.

233
00:37:27.120 --> 00:37:28.609
Mario Vega: That that's correct. Yeah.

234
00:37:28.610 --> 00:37:36.520
Tim Beiko: Okay? So in that case, okay, let's leave it as is now make a final call in 2 weeks. If we are to change it. And

235
00:37:36.947 --> 00:37:43.300
Tim Beiko: yeah, just give us some time to discuss it. And yeah, look into the details and the edge cases.

236
00:37:47.960 --> 00:37:50.119
Tim Beiko: So anything else on this.

237
00:37:55.660 --> 00:38:01.335
Tim Beiko: See if we can make the final call on Monday instead of 2 weeks from now.

238
00:38:03.160 --> 00:38:07.416
Tim Beiko: I don't know how quickly we can get the numbers and get through them.

239
00:38:13.289 --> 00:38:16.980
Duncan Townsend (0x): I can probably have numbers, at least for 0 X.

240
00:38:17.310 --> 00:38:19.389
Duncan Townsend (0x): By tomorrow morning.

241
00:38:21.260 --> 00:38:28.233
Tim Beiko: Okay, so let's right. Okay, if you have that, let's discuss it again. On Monday's testing call. And

242
00:38:29.610 --> 00:38:47.147
Tim Beiko: yeah, if we feel like we have all the information to make a decision. Then then great and at the very least, if it's leaning towards, we think we're gonna change it. Then we'll know on Monday that we we need to set up a new definite. And we can also figure out the exact right value.

243
00:38:53.670 --> 00:38:56.720
Tim Beiko: okay, anything else on this.

244
00:39:01.170 --> 00:39:05.617
Tim Beiko: Okay, well, thanks everyone. Thanks, Duncan, for writing this and coming on.

245
00:39:07.000 --> 00:39:17.496
Tim Beiko: okay, next up is another spec issue. This one is more of a cl one. Oh, it's actually just a cl one about pure. Das

246
00:39:18.160 --> 00:39:31.840
Tim Beiko: it's come up in the thread that basically the increased requirements on cl nodes can affect can affect some of these community staking module like Lido and Rocket will have.

247
00:39:31.980 --> 00:39:32.840
Tim Beiko: and

248
00:39:33.450 --> 00:39:40.499
Tim Beiko: and I know that this is the El call, but it's a pretty significant change. So I wanted to

249
00:39:41.050 --> 00:39:52.359
Tim Beiko: leave some room for people to discuss it today, and at the very latest. It feels like we should resolve this on next week. Cl, call. So if we, if there's anything we can move forward today on this topic, it would be good.

250
00:39:52.500 --> 00:40:01.090
Tim Beiko: and I don't know if either Dimitri who raised the issue, or anyone who's engaged on the Pr.

251
00:40:01.700 --> 00:40:03.019
Tim Beiko: Send the call or.

252
00:40:03.790 --> 00:40:06.689
Dmitry Gusakov: Yeah, I'm I'm here. Thank you. Team.

253
00:40:06.820 --> 00:40:23.359
Dmitry Gusakov: So the quick context about the thing and why we are discussing that in pure das, there is a constant that determines how many samples of this new blob samples, which is

254
00:40:23.370 --> 00:40:36.859
Dmitry Gusakov: 128. Right now Cl Node is obligated to custody, depending on the number or the eth amount attached to the validators to the node.

255
00:40:37.750 --> 00:40:55.459
Dmitry Gusakov: So there is a feeling that the current number, which is 128 or 4,01896. Eth. Attached to the node being the top requirement for the node to be a super node

256
00:40:55.710 --> 00:40:57.980
Dmitry Gusakov: might have a

257
00:40:58.350 --> 00:41:19.379
Dmitry Gusakov: like, possibly a negative effect on homestakers. Specifically, home stakers in the fractional staking protocols like rocket pool or Lido Csm or stater, or whatever else protocol where people only provide a fraction of the capital to custody a full 32 e. For validator, or

258
00:41:19.530 --> 00:41:46.020
Dmitry Gusakov: in the future, maybe Oxo to validators as well. So the the proposal from my side, from my aside from Csm side is to increase this limit from like 4 times from the current value, so that the obligation to be a super node, and to custody all of the segments will appear. Once there are 512

259
00:41:46.260 --> 00:41:51.659
Dmitry Gusakov: validators attached to the node, or 16,000. Eth.

260
00:41:52.090 --> 00:42:07.699
Dmitry Gusakov: I personally think that this wouldn't make a significant change regarding professional operators and large notes that we already have in the network, because, from my experience, negotiating with the professional operators almost all of them

261
00:42:08.338 --> 00:42:14.559
Dmitry Gusakov: have at least 500 validators, and then balance validators attached to the node right now.

262
00:42:14.560 --> 00:42:38.460
Dmitry Gusakov: so it means that their nodes would still be mandatory super nodes, while it will make a curve less stiff, and would ensure that both storage and bandwidth requirements would not go crazy high, for homestakers like myself, for example, who are running validators from home, using a very common hardware like Dap Node, for example.

263
00:42:38.460 --> 00:42:48.849
Dmitry Gusakov: and who are limited by a household Internet connection which might be not super perfect and given that the requirement

264
00:42:49.040 --> 00:42:59.919
Dmitry Gusakov: would result in not just storing or custody more segments, but also downloading them in a limited 4 second period.

265
00:42:59.930 --> 00:43:10.569
Dmitry Gusakov: Oh, I believe that this limit can be raised, especially given the initial rationale behind selecting the initial value which was 1st of all

266
00:43:10.570 --> 00:43:37.990
Dmitry Gusakov: compiled, I believe, either a year or year and a half ago, when functional staking was not such a big thing, and the second is that I believe the rational was just one segment per validator. Maybe it is not a very robust thing, and there is a chance that we can increase the value, so that we will allow homestakers to still maintain relatively low requirements both to their hardware and to their bandwidth.

267
00:43:43.740 --> 00:43:47.650
Tim Beiko: Thank you. See, Asgar has his hand up.

268
00:43:48.650 --> 00:44:05.650
Ansgar Dietrichs: Yeah, I just wanted to say that I would argue, for we should just be very aware that this is not primarily a technical question, but more kind of philosophical question of sorts, and I personally am pretty strongly opposed to this change, because I think

269
00:44:05.960 --> 00:44:26.960
Ansgar Dietrichs: in principle, what we're trying to achieve is trying to basically have as few economies of scale as possible in staking right? Because that those always push against solo stakers and send this specific concern is not about solar stakes. But that's kind of the point, right? Because in principle, staking 32 Eth and staking 64 Eth already like should

270
00:44:27.010 --> 00:44:39.770
Ansgar Dietrichs: basically be twice the effort, because you also get twice the payoff. Right? So of course, you need twice the capital. But ideally, you should also run basically 2 nodes in 2 locations with twice the bandwidth and twice the everything

271
00:44:39.770 --> 00:45:01.729
Ansgar Dietrichs: in practice. Of course, we can't actually fully get there, but that is actively bad. And so like. The more we are leaning into economies of scale, the more we are making life harder for solar stakers, especially now that the staking ratio is increasing more and more, and the kind of the yield comes down quite a bit. And so the margins get slimmer and slimmer.

272
00:45:01.730 --> 00:45:26.760
Ansgar Dietrichs: So I personally think at least we should be very, very careful with this kind of change. And if you look at numbers right like so for people that actually fully stake their own. Eth, we're basically talking about this change like from you could already, you know, like you could now stake, I don't know. Up to 4 million dollars of capital before before you'd even start having to like classity more than the very minimum of of columns.

273
00:45:26.830 --> 00:45:42.949
Ansgar Dietrichs: I personally think that's excessive. I understand that this is specifically to enable these use cases where you have, like a very high multiplier between your own capital and the underlying capital. But in that case, there's just a lot of fees that should then just go into making sure you can actually

274
00:45:42.950 --> 00:46:09.289
Ansgar Dietrichs: and still do that. I am sympathetic to this in the sense that I think we should look at this into solutions like someone like that being able to just run nodes in multiple locations that then communicate with each other to basically like, so that no one location just has to custody all the columns or something like this. So I do think we should try to facilitate this, but I personally think that the easing the requirements and leaning more into economies of scale is the wrong approach. But I do think people can have different opinions here.

275
00:46:13.430 --> 00:46:29.529
Dmitry Gusakov: I'm not quite sure that the proposed change is leaning towards the economies of scale. Maybe like is either my misunderstanding of how the protocol works or my bad English. But I'm not quite sure that we are talking here about leaning towards economies of scale.

276
00:46:30.080 --> 00:46:33.269
Dmitry Gusakov: I believe we are talking more here about?

277
00:46:36.200 --> 00:46:42.979
Dmitry Gusakov: How many nodes would be affected by that, and raising the limit, like anything in between

278
00:46:43.910 --> 00:46:47.890
Dmitry Gusakov: one validator and 500 validator is.

279
00:46:48.330 --> 00:47:13.129
Dmitry Gusakov: can barely be considered an economy of scale. And again, as I mentioned, from my experience with professional operators, like all of them, they're trying to maximize what they, what they are earning. So they're trying to minimize hardware costs. And that's why they all already run more than 500 validators. And the question is, how much do we affect those running? Not like a 500 validators, but

280
00:47:13.130 --> 00:47:25.759
Dmitry Gusakov: say, I don't know 50 validators, for example, in Csm. Or in light of simple Dvt, or just in Dvt clusters. So imagine you have 7 Homestakers who are now

281
00:47:25.760 --> 00:47:30.390
Dmitry Gusakov: building a cluster of 7 nodes. It means that they will need to have each

282
00:47:30.400 --> 00:47:52.718
Dmitry Gusakov: 7 times less capital. But they will all have to run the same number of validators just because of the fact how Dvt technology works. And in this case, if they're say running to, I don't know 30 validators or 40 validators altogether, the steeper the curve would be, the more they will be affected, and from my personal experience

283
00:47:53.350 --> 00:48:03.759
Dmitry Gusakov: right now, like any change that makes it harder to become homestaker, makes it less profitable, less convenient, less comfortable, is

284
00:48:03.910 --> 00:48:18.220
Dmitry Gusakov: essentially net negative, because even with the current conditions that ethereum has to offer, that protocols on top of ethereum has to offer, it is still extremely hard to get like additional 100 operators on ethereum network.

285
00:48:18.330 --> 00:48:37.550
Dmitry Gusakov: So for me personally, there is a chance to make a curve less steep, so that we will still be able to allow for, like a semi professional node operators to be not, or it's like large homestakers. Let's call them this way, not to get affected that much by this team.

286
00:48:43.560 --> 00:48:44.400
Tim Beiko: Yeah. Bonus.

287
00:48:45.460 --> 00:49:05.609
potuz: I want to mention that there is an actual technical side to this. I want you guys to go and look into that thread on discord on R. And D. Francesco, for example, brought up that it might be beneficial to have a distribution of nodes where we have more nodes.

288
00:49:05.790 --> 00:49:19.459
potuz: That custody, the minimal number of columns. And then this bimodal distribution in which we have these nodes. And then suddenly we have nodes that are super nodes that have everything these nodes like

289
00:49:19.570 --> 00:49:46.639
potuz: they do different kind of things. For p. 2. P. The super nodes allow to like, reconstruct the blob, reconstruct the blob, and serve the other nodes, and having a bunch of nodes in the middle ground, might be detrimental because it increases the number of subnets, and it just degrades blob propagation. So it might be worth, just from that perspective, to increase the number of validators that you run while still keeping the minimum number of columns

290
00:49:46.830 --> 00:49:53.760
potuz: according to numbers. I mean, of course, this would affect depending on what sort of like the leverage

291
00:49:53.870 --> 00:50:04.780
potuz: that the staking pool mechanism allows. I believe, with rocket pool. I think Nixo just pointed that this would be like 4 million or something like this.

292
00:50:04.990 --> 00:50:11.209
potuz: with Csm. The numbers, as far as I can see in the from the Pr.

293
00:50:11.360 --> 00:50:20.780
potuz: You would need about 36, Eth. Not more than this to hit this this limit in which you start

294
00:50:20.950 --> 00:50:24.460
potuz: having more columns to to to keep.

295
00:50:24.620 --> 00:50:32.629
potuz: So I think that's not so so large of a number. I think we do have home stakers that do stake for about 36 East.

296
00:50:32.770 --> 00:50:55.440
potuz: I mean, many of them would actually like split their own validator and try to take many keys from from a protocol like Lido, because they just earn more. And I think we do want to incentivize this kind of staking, because this kind of staking is what's taking out stakers from institutions. So I don't think that this is

297
00:50:55.660 --> 00:51:02.319
potuz: this is something something dramatic, I think, in that Pr. Many client devs supported it.

298
00:51:02.480 --> 00:51:11.849
potuz: and it seems to me that research also supports it, and it seems that it's not dangerous. It might actually even help on p. 2. P. Propagation. So I don't see why to be opposed to this.

299
00:51:13.040 --> 00:51:15.360
Tim Beiko: Thanks. Thanks.

300
00:51:16.780 --> 00:51:29.329
stokes: Yeah, so I think there is this general conversation to have. And yeah, you know, having another look at how this custody works and how it scales, you know, that seems to make sense. Given all the above arguments.

301
00:51:29.630 --> 00:51:34.130
stokes: there's a separate question, though, of like, when is the right time to do this, I think.

302
00:51:34.290 --> 00:51:43.589
stokes: given where we are in the R&D process. Also, a key factor is we don't expect to like, scale the blob significantly immediately after Socca.

303
00:51:43.710 --> 00:51:47.390
stokes: I think we'll have time to get to a place where this would even start to be an issue.

304
00:51:47.550 --> 00:51:50.269
stokes: So I propose we kind of table this change, for now

305
00:51:50.560 --> 00:51:56.060
stokes: keep looking into it, and you know, as we need to do something about it down the line, we can pretty easily.

306
00:51:57.130 --> 00:52:00.910
Tim Beiko: And you mean table. This change from Fusaka completely like.

307
00:52:00.910 --> 00:52:02.149
stokes: Yeah, yeah.

308
00:52:09.670 --> 00:52:12.070
Tim Beiko: Do people feel about this?

309
00:52:13.230 --> 00:52:22.079
Tim Beiko: yeah, you know, we can make a final decision of this on Monday as well. Like, I think it's important that we at least discuss it now, and people have time to review. But

310
00:52:24.040 --> 00:52:25.480
Tim Beiko: yeah, I

311
00:52:30.700 --> 00:52:32.029
Tim Beiko: I'm fine

312
00:52:32.420 --> 00:52:38.255
Tim Beiko: making the change, making the decision on Monday or at the latest on the Cl call next week.

313
00:52:51.480 --> 00:52:52.170
Tim Beiko: go ahead.

314
00:52:52.460 --> 00:52:53.989
Tim Beiko: Yeah, let's try to.

315
00:52:54.840 --> 00:53:00.200
Tim Beiko: I I guess. Actually, yeah, is it better to do this on the scale call, or on Monday, like, I know that there's a lot of.

316
00:53:00.200 --> 00:53:06.809
stokes: I think, as quickly as possible. I would have liked to make a decision today. Let's aim for Acd. Then

317
00:53:07.010 --> 00:53:11.180
stokes: I think we might sort of nominally have more cl participation there. So.

318
00:53:11.540 --> 00:53:14.310
Tim Beiko: Yeah. And we can at least yeah.

319
00:53:14.580 --> 00:53:22.109
Tim Beiko: ping the cl and try to get them to. If they can't show up. Articulate their reasoning. Async. Ahead of the call.

320
00:53:27.430 --> 00:53:34.119
Tim Beiko: Okay, let's do that, then and then there's obviously the Pr people can engage on. I think

321
00:53:35.630 --> 00:53:37.769
Tim Beiko: anything else on this before we move on.

322
00:53:47.220 --> 00:53:49.766
Tim Beiko: Yeah, but there is Frank, I think.

323
00:53:50.290 --> 00:53:56.580
Tim Beiko: it would be good for all of the Cl teams to either share their opinion before act or

324
00:53:56.710 --> 00:54:01.950
Tim Beiko: on the call and

325
00:54:08.190 --> 00:54:19.169
Tim Beiko: I guess the question is, if the Cl teams are mostly gonna look at it from an implementation perspective? Or do we expect them to look at it from a process or philosophical perspective, as well.

326
00:54:21.210 --> 00:54:24.860
Parithosh Jayanthi: Cause. I think that was the reason it was brought up in Acd.

327
00:54:25.710 --> 00:54:26.690
Tim Beiko: That.

328
00:54:26.970 --> 00:54:29.310
Tim Beiko: Okay, yeah. Barnabas.

329
00:54:29.450 --> 00:54:42.620
Barnabas: Yeah. So I've tested the change on, and all the different Cls can adjust it as expected. So it's a complete change. There's no technical question about it.

330
00:54:52.460 --> 00:54:55.659
Tim Beiko: Then I think I would be inclined to make

331
00:54:56.930 --> 00:55:00.300
Tim Beiko: to give people some more time to voice like

332
00:55:00.650 --> 00:55:08.900
Tim Beiko: their views on it at that level and make the call next week on this Pl. Call rather than Hdt, even if it's a bit further out

333
00:55:09.170 --> 00:55:10.080
Tim Beiko: and.

334
00:55:12.300 --> 00:55:21.660
stokes: Yeah, I mean, so it is like a 1 line change. Literally, it's just then this implies probably more devnets, more testing like it. Just.

335
00:55:21.860 --> 00:55:23.709
Tim Beiko: Yeah, do we want to actually do it?

336
00:55:24.480 --> 00:55:25.890
Tim Beiko: Yeah, I mean.

337
00:55:25.890 --> 00:55:31.690
stokes: Yeah, I mean, my take is, we want to do something here at some point. I just don't think it's right now.

338
00:55:36.450 --> 00:55:38.380
Tim Beiko: Okay, on. Skype.

339
00:55:39.670 --> 00:55:50.970
Ansgar Dietrichs: Yeah, I mean, I would just also say, for process reasons, this is a big change, not not technically. I understand this technically, it's pretty trivial, even though it would imply no devnet and everything. But it is conceptually like a very big change.

340
00:55:51.080 --> 00:56:19.799
Ansgar Dietrichs: and also, I mean, as was even brought up when describing it. It's not something that was only said a couple of weeks ago like this, specific value has been in the spec for like over a year. So people had a lot of time to look at it to potentially propose changes. I just think it's too late into the process to now discuss like a very meaningful change with basically not giving people a lot of time to like to form opinions, to not have this debate. I really think it's a meaningful enough topic that would require a lot of debate. And I think, just rushing to a decision.

341
00:56:20.350 --> 00:56:25.749
Ansgar Dietrichs: I think it's just not appropriate. Given the kind of fog process.

342
00:56:30.540 --> 00:56:32.229
Tim Beiko: Right. But I guess yeah, to be clear.

343
00:56:32.340 --> 00:56:38.923
Tim Beiko: we will still be rushing to a decision. The decision would just be maintained. The spec, as is right.

344
00:56:39.600 --> 00:56:47.650
Tim Beiko: So if there's if there's anything that we would learn in the next week that we think could

345
00:56:48.240 --> 00:56:49.899
Tim Beiko: help shape the decision.

346
00:56:50.070 --> 00:56:58.739
Tim Beiko: I think it's worth trying to do that. If we don't think so, then yeah, I would also bias towards not making changes at this point.

347
00:57:19.250 --> 00:57:23.160
Tim Beiko: what sorry subway is not just blob parameter.

348
00:57:33.110 --> 00:57:35.739
Barnabas: Basically, he wants to change the value in the Bpo.

349
00:57:36.780 --> 00:57:42.720
Csaba: Yeah, Vto is is a interesting concept. But we will be more more running into

350
00:57:43.050 --> 00:57:48.230
Csaba: Ppo, not just being a parameter. Only change and.

351
00:57:48.780 --> 00:57:49.739
Tim Beiko: I mean I don't.

352
00:57:49.740 --> 00:57:50.210
Tim Beiko: I guess.

353
00:57:50.210 --> 00:57:50.620
Csaba: Sure.

354
00:57:50.620 --> 00:57:57.380
Tim Beiko: An option is, we could not have this launch with Fusaka. And then, to the extent it becomes.

355
00:57:58.280 --> 00:58:03.226
Tim Beiko: Yeah, more urgent to address. We can overload the vpo to also have this

356
00:58:04.500 --> 00:58:05.399
Csaba: Yeah, exactly.

357
00:58:06.220 --> 00:58:11.140
Barnabas: Yeah, we also assume that the Cgc value doesn't go down. By the way.

358
00:58:14.720 --> 00:58:21.619
Barnabas: So once we introduce this technically, you're not gonna go down in your Cgc value

359
00:58:22.980 --> 00:58:25.719
Barnabas: unless you yeah. Neutral. dB, but.

360
00:58:27.070 --> 00:58:27.720
Tim Beiko: Right?

361
00:58:32.200 --> 00:58:36.720
Tim Beiko: Okay? Then I guess I would lean towards not making this change.

362
00:58:39.270 --> 00:58:44.236
Tim Beiko: And yeah, just because we're selecting the process trying to minimize, minimize

363
00:58:44.930 --> 00:58:47.659
Tim Beiko: the amount of changes to the specs.

364
00:58:48.370 --> 00:59:07.210
Tim Beiko: we should still have the discussion and think through kind of the the design principle implications. Further. But if we find that there's something so important that needs to be addressed, we can do that in one of the Vpos but for Fusaka. We can admit this change.

365
00:59:09.200 --> 00:59:10.330
Tim Beiko: Does that make sense.

366
00:59:12.520 --> 00:59:20.100
stokes: It makes sense to me. But I guess just clarifying. Are we making? Are we starting this today? Or we're just

367
00:59:20.380 --> 00:59:25.040
stokes: stating it as a summary, and then we'll take this to Acdt or C next week.

368
00:59:25.810 --> 00:59:30.850
Tim Beiko: I'm fine not discussing it on acbt if people here okay with it. But.

369
00:59:32.150 --> 00:59:39.290
stokes: Okay? So yeah, let's just say, this is like the the preference right now and then. Yeah, we can finalize on next week's Acdc.

370
00:59:40.580 --> 00:59:47.929
Barnabas: Well, on Monday we're gonna find out if we're gonna need a new that, anyway, regarding Max transaction. So I think it.

371
00:59:48.030 --> 00:59:53.629
Barnabas: If if we can make a decision about that. Then. On that call, I think we can also make a decision about this.

372
00:59:55.500 --> 01:00:01.400
Tim Beiko: Yeah. Like, if we don't need a new definite, then I think that would lead us much more heavily towards not including this change.

373
01:00:01.580 --> 01:00:03.440
Tim Beiko: And yep.

374
01:00:07.040 --> 01:00:07.680
stokes: Agree.

375
01:00:08.130 --> 01:00:08.445
Tim Beiko: Okay.

376
01:00:12.010 --> 01:00:15.100
Tim Beiko: okay, anything else on this one before we move on.

377
01:00:24.330 --> 01:00:29.430
Tim Beiko: Yes, we are discussing the transaction gas limit gap on Monday, Mario.

378
01:00:32.870 --> 01:00:36.469
Tim Beiko: Okay? And then the the last 2 second thing I want to discuss is just

379
01:00:37.100 --> 01:00:44.354
Tim Beiko: continuing your timeline discussion. We had last time. So Alex had proposed

380
01:00:45.360 --> 01:01:01.542
Tim Beiko: a timeline which would mean that around September. 1st we get the fine releases for test nets, and then for test nets through September, October, and potentially main net early mid November

381
01:01:02.850 --> 01:01:09.139
Tim Beiko: and then, you know, some concerns about working during dev connect but

382
01:01:09.370 --> 01:01:20.140
Tim Beiko: I think any of the proposed schedules that get us a fork before on disconnect, assume that we have the client test net releases out

383
01:01:20.300 --> 01:01:23.679
Tim Beiko: around September first, st which is a month from now.

384
01:01:25.770 --> 01:01:33.522
Tim Beiko: The people think this is realistic, are there things we should be doing to make sure we can get there?

385
01:01:35.600 --> 01:01:36.310
Tim Beiko: yeah.

386
01:01:41.890 --> 01:01:48.280
Tim Beiko: are things we should not be doing like. For example, you know, if we do change this transaction limit cap.

387
01:01:48.770 --> 01:01:55.649
Tim Beiko: The client teams feel like it makes a difference between whether they can have a test and release in 4 weeks or not.

388
01:01:57.210 --> 01:01:58.380
Tim Beiko: Yeah, Sean.

389
01:01:58.680 --> 01:02:10.669
sean: So for lighthouse. We were talking about this yesterday for us. Yeah, the 4 weeks for the release is like aggressive. But we think doable. We're a little concerned about like

390
01:02:10.920 --> 01:02:20.269
sean: there's some adversarial testing that we're trying to start doing right now, and if that were to reveal some bad stuff that might push back the timeline a little bit, but so maybe like an extra

391
01:02:20.400 --> 01:02:29.009
sean: week or 2, padding would be good for the 1st release. But we still want to hit the Dev connect timeline. So, yeah, that was our thought process.

392
01:02:31.030 --> 01:02:35.190
Tim Beiko: Thanks anyone else.

393
01:02:42.430 --> 01:02:57.930
Tim Beiko: Okay? Then, if there's no other major comments, then I think, yeah, we should basically plan everything as though we're releasing the 1st testnet on September first.st Obviously, if we find a major bug, you know, we should always fix that, and that might delay things.

394
01:02:58.790 --> 01:03:11.059
Tim Beiko: Then, in terms of the test nets? Did people have preferences between forking sepulia first? st Hudi first, st and whether or not we should fork Holeski

395
01:03:17.850 --> 01:03:19.510
stokes: Doing husky.

396
01:03:23.350 --> 01:03:28.689
stokes: The upside is. It's just another sort of strong goal, so to speak, Downside is. It's just another

397
01:03:28.860 --> 01:03:30.100
stokes: attention sync.

398
01:03:31.230 --> 01:03:40.820
Parithosh Jayanthi: Yeah, I think the only benefit of 14 is that we do have enough public nodes. So we will collect some p 2 p data.

399
01:03:41.190 --> 01:03:43.620
Parithosh Jayanthi: But yeah, the downside is extra time.

400
01:03:47.650 --> 01:03:57.409
Tim Beiko: There's a comment by still saying that. You know, we talked about doing some non finality testing with the releases. Should we use Holesky for that.

401
01:04:00.300 --> 01:04:13.749
Parithosh Jayanthi: Yeah, we can use Host Key for that. We also wanted to spin up a different network for non finality. We're just waiting for like a proper final spec freeze, and all the other bugs to be sorted out before we spend the money on non finality test.

402
01:04:17.200 --> 01:04:21.500
Tim Beiko: Because then, you know, one schedule could be something like we release.

403
01:04:21.660 --> 01:04:44.700
Tim Beiko: you know, on the week of September 1st we fork Helesky on the week of yeah, if we have 2, basically, if we if we have 2 weeks between every test net and we fork all 3 that brings us to October 15, and that means, if we want to wait a month after the last test, that we would be forking during that connect which feels

404
01:04:45.470 --> 01:04:50.140
Tim Beiko: feels not ideal. So if we do want to fork Holeski, then

405
01:04:50.270 --> 01:04:54.400
Tim Beiko: we probably should do something where maybe we have like.

406
01:04:55.310 --> 01:05:04.540
Tim Beiko: and a 1 week between the release and Helesky, and then, you know, a week or 2 between Holeski or between between Sepulia.

407
01:05:04.880 --> 01:05:24.199
Parithosh Jayanthi: We could use the same release for wholeski as well as sepulia, and one of the benefits of having non finality testing on hold key as well is that it shows people explicitly that we want to deprecate the network, and it'll avoid the scenario where my infra has worked well. So I forgot to migrate.

408
01:05:25.420 --> 01:05:26.020
Tim Beiko: Right?

409
01:05:30.550 --> 01:05:34.450
Tim Beiko: So yeah, 1 1 option could be that, like.

410
01:05:34.600 --> 01:05:41.459
Tim Beiko: you know, week of September. 1st we put out the releases for Heleski and sepulia week of September 8th

411
01:05:41.680 --> 01:05:50.609
Tim Beiko: Forks. Because I assume we're controlling most, if not all, of the nodes on this. So we can. We could clearly like

412
01:05:50.750 --> 01:05:56.180
Tim Beiko: update in time, and then week of the 7, the 15, th the polio forks.

413
01:05:56.960 --> 01:06:07.539
Tim Beiko: We we put out another release after that, and then we Fork, who d. On the week of October 29.th Assuming all of this goes well. It means we could fork

414
01:06:10.480 --> 01:06:13.120
Tim Beiko: Sorry, like, yeah. Sorry. On the week of September.

415
01:06:13.510 --> 01:06:20.176
Tim Beiko: September 29, th and this means, if everything goes well, it means we can fork Mainnet on the week of

416
01:06:20.770 --> 01:06:28.680
Tim Beiko: October 27, th or or November 3, rd which are yeah, which are right before death connect?

417
01:06:37.770 --> 01:06:46.629
Tim Beiko: yeah. So I guess my, yeah, my schedule is basically with Barnabas posted, but then potentially shifted one week earlier on everything so that we can do

418
01:06:47.741 --> 01:06:54.318
Tim Beiko: wholeski one week after the client releases. Given that, we're gonna do non finality testing and

419
01:06:56.110 --> 01:06:59.510
Tim Beiko: and that we control most of the of the nodes.

420
01:07:00.120 --> 01:07:07.526
Tim Beiko: And and yeah, we don't have to like 100% finalize this today. But it would be good.

421
01:07:09.150 --> 01:07:13.110
Tim Beiko: it it would be good to do so in the next week or 2.

422
01:07:14.140 --> 01:07:19.940
Tim Beiko: especially if, like, yeah, we are needing to set these blocks for for September first.st

423
01:07:24.830 --> 01:07:26.939
Tim Beiko: I guess I don't. Yeah. Maybe it

424
01:07:27.130 --> 01:07:37.629
Tim Beiko: a good way to move this forward is that if all the teams like Pen Ops posted their preferences, but I think it might be good to hear from all the different teams by next call, and

425
01:07:37.750 --> 01:07:43.409
Tim Beiko: we can kind of finalize the happy path dates by next call based on the feedback from teams.

426
01:07:44.820 --> 01:07:47.570
Tim Beiko: Does that make sense? Did you want to see how part next week.

427
01:07:52.710 --> 01:07:54.595
Tim Beiko: Okay, I have a plus one.

428
01:07:55.580 --> 01:07:59.900
Tim Beiko: But I think, like, yeah, by this point, everyone knows kind of what the constraints are, and you know

429
01:08:00.310 --> 01:08:02.598
Tim Beiko: how we can approach them. So

430
01:08:03.530 --> 01:08:19.360
Tim Beiko: yeah, let's let's let's try to get a final set of dates on on next week's call. And obviously, if we find a bug and things. You know things are problematic. We should always like revisit that. But at least, having, like our happy path, set of support, blocks would be good.

431
01:08:27.700 --> 01:08:30.300
Tim Beiko: Okay, anything else on the rollout?

432
01:08:36.580 --> 01:08:40.824
Tim Beiko: If not, then yeah, we can use the rest of the call to discuss Amsterdam.

433
01:08:41.229 --> 01:09:07.380
Tim Beiko: We discussed it. A bunch in the past couple of weeks. On last week's cl call. It seemed like there was strong support by the Cl teams about epbs. Still some open questions around potentially some other headliners. So we cfi the Epbs delayed execution, and fossil, I believe, as candidate headliners

434
01:09:07.769 --> 01:09:14.771
Tim Beiko: and then on the Cl. Call. We didn't want to discuss block access list too much, but it

435
01:09:15.569 --> 01:09:22.680
Tim Beiko: It is kind of the main thing that's come up on the El side. And so I guess.

436
01:09:23.310 --> 01:09:30.622
Tim Beiko: yeah, how do people feel about making block access lists? Kind of the El headliner?

437
01:09:32.689 --> 01:09:35.120
Tim Beiko: are there any objections to this? At this point?

438
01:09:35.439 --> 01:09:38.340
Tim Beiko: It seems like the kind of okay.

439
01:09:38.470 --> 01:09:45.090
Tim Beiko: least controversial, and also somewhat smallest of the headliners. And

440
01:09:46.450 --> 01:09:50.999
Tim Beiko: so, yeah, I feel we may be able to lock this one in on the El side today and then

441
01:09:51.510 --> 01:09:55.920
Tim Beiko: finalize the discussion about epbs, shorter slot times than possible next week.

442
01:10:06.050 --> 01:10:11.129
Tim Beiko: Okay, so bae su guest, like bals Francis.

443
01:10:12.250 --> 01:10:19.409
Francis: Hi, just to kind of like express basis opinion on this a little bit or preference.

444
01:10:19.956 --> 01:10:45.710
Francis: For the el sides. We kind of like prefer delayed execution to bals, and we like. I think we like both, and the reason we prefer, like delayed execution is that we think delayed execution can provide benefit to both the l. 1 scaling and l. 2. Scaling, and also provide benefit to faster confirmations. It moves the actual execution to the next blocks, which

445
01:10:45.940 --> 01:10:48.740
Francis: I think it's a very good property to have.

446
01:10:49.325 --> 01:11:13.264
Francis: And it has, I think, from other analysis, has 80% of the benefits, for as opposed to for of Pbs without the the Ptc, the new folk choice rules and the other stuff. So yeah, that's just like our opinion, just want to express it. But if everybody is like already aligned on that

447
01:11:14.390 --> 01:11:16.630
Francis: I guess that's okay, too.

448
01:11:17.060 --> 01:11:21.280
Tim Beiko: Yeah, I guess. Yeah. 1 1 question. I just posted in the chat as well. But

449
01:11:21.721 --> 01:11:31.690
Tim Beiko: from what I've heard of people supporting delayed execution. It seems like they would also want to do block access list. But I'd be curious to hear from fine teams like

450
01:11:31.800 --> 01:11:32.700
Tim Beiko: M.

451
01:11:34.990 --> 01:11:40.329
Tim Beiko: Yeah. Like, if we do delayed execution. Do we think that this is

452
01:11:41.460 --> 01:11:46.229
Tim Beiko: This is somehow blocking for for block access list?

453
01:11:46.862 --> 01:11:50.490
Tim Beiko: Okay. Beizu says yes, and.

454
01:11:52.120 --> 01:11:57.409
Justin Florentine (Besu): I wouldn't simplify it down to a yes, Tim, it does change our math a little bit.

455
01:11:57.790 --> 01:11:58.330
Tim Beiko: Yeah.

456
01:12:00.030 --> 01:12:09.299
Tim Beiko: yeah. And I guess this is kind of weird, because you know, the late execution is mostly an El thing. Epbs is mostly a Cl thing, but they're kind of competing because they're both about those slots, restructuring.

457
01:12:09.720 --> 01:12:20.920
Tim Beiko: And and yeah, it seemed like all of the Cl teams, relatively strongly supported epbs, so I

458
01:12:23.210 --> 01:12:33.520
Tim Beiko: yeah, it's either we 1st make it an ebbs versus delayed execution decision. And that's gonna kind of go through another awkward cycle, or

459
01:12:33.640 --> 01:12:34.970
Tim Beiko: we make

460
01:12:35.290 --> 01:12:46.070
Tim Beiko: the call around around block access lists. And you know, commit to that, and then see whether or not we also do the execution.

461
01:12:46.240 --> 01:12:47.469
Tim Beiko: Yeah, on the bar.

462
01:12:48.060 --> 01:12:53.540
Ansgar Dietrichs: Yeah, I mean, I agree with you that the kind of decision process is a bit weird here because of the elcl interactions.

463
01:12:53.730 --> 01:13:02.618
Ansgar Dietrichs: I mean, I think, in principle, we probably just all agree that if we do ups, then the El headliner should be block level access lists.

464
01:13:03.900 --> 01:13:32.829
Ansgar Dietrichs: I do think that in a way, maybe I don't know. It's weird to make that conditional decision. But like, I do think, and I also think, that the Cl. Will choose epbs. But I do think in a way we should not preempt like it is weird to just lock in bls now and then. If the Cl. After all, says no! Actually, we want to push Epbs to H. Star, and we're doing 6 second slots in Glamsterdam. Then, of course, I do think we should revisit. And actually I would prefer delayed execution for us to do, or at least consider that over blocks list.

465
01:13:32.830 --> 01:13:41.220
Ansgar Dietrichs: So I don't know, like I think the really the main decision for Grumpstem is this. Ebbs was delayed execution, and I think that is more a Cl. Question.

466
01:13:43.270 --> 01:13:59.220
Ansgar Dietrichs: I mean, I do think at this point it is becoming pretty obvious that we are going to go with epbs. But I still feel like, in a way, maybe we should just like only conditionally lock in block lab access lists to saying, like, okay, we assume it's going to be epbs, so we say, block level access. But we revisit this. If the Cl surprises us, basically.

467
01:14:03.250 --> 01:14:07.400
Tim Beiko: Yeah, I agree. So I kind of feel like I'm passing the buck here. But like, I think

468
01:14:07.580 --> 01:14:13.643
Tim Beiko: we can probably Cfi block access list like it seemed at least as

469
01:14:14.450 --> 01:14:29.820
Tim Beiko: there's as at least as strong of a content consensus on this than the 3 other ones we have. Cfi. We could make that like the 4 candidate headliners, and then we can make the call next week about the Pps, which is delayed execution, and then, assuming we do delayed

470
01:14:30.350 --> 01:14:36.469
Tim Beiko: execution or sorry assuming we do, I think, assuming we do epbs, then

471
01:14:37.440 --> 01:14:44.585
Tim Beiko: it would make sense to just also include block access lists. If we don't end up doing the Pbs, then I think we'll need some more discussion.

472
01:14:45.330 --> 01:14:50.770
Tim Beiko: and it is a bit weird in terms of conditionals. But that's also not that crazy? So

473
01:14:51.420 --> 01:14:55.690
Tim Beiko: yeah, I would move to Cfi Block access list. Make a call on Evds.

474
01:14:57.160 --> 01:15:03.730
Tim Beiko: Make a call on Egbs, which is delayed. Execution. And then yeah, it

475
01:15:03.970 --> 01:15:12.670
Tim Beiko: a a line on the on the El side, based on on the result of that. But default to doing block access list. If it's Pbs, yeah. A MoD.

476
01:15:17.230 --> 01:15:20.009
Ahmad Bitar | Nethermind: Hey? So I wanted to

477
01:15:20.160 --> 01:15:29.509
Ahmad Bitar | Nethermind: like express a different opinion from Francis on a delayed execution being beneficial to L twos. Because

478
01:15:29.710 --> 01:15:52.699
Ahmad Bitar | Nethermind: unless you're doing like block building and doing the execution and and like, even if you're doing block building, you're executing as you're building. But if you are just grabbing batches of transactions from from the mempo and sequencing them, whatever the highest priority fee, or whatever

479
01:15:52.800 --> 01:15:58.747
Ahmad Bitar | Nethermind: like delayed execution, will not actually provide you with that much benefit.

480
01:15:59.540 --> 01:16:06.589
Ahmad Bitar | Nethermind: that's my personal opinion. But maybe there is other considerations that I'm not. That I'm not seeing.

481
01:16:06.620 --> 01:16:24.769
Ahmad Bitar | Nethermind: But there is another consideration also about delayed execution versus Apbs here, which, as far as I'm concerned, Apbs delayed execution does not bring the same scaling benefits as Apbs when it comes to blobs. Because the

482
01:16:24.770 --> 01:16:37.650
Ahmad Bitar | Nethermind: and blobs are important for L twos. So this is another consideration that if we want to actually scale blobs higher, we should probably consider apbs over delayed execution.

483
01:16:37.920 --> 01:16:43.570
Ahmad Bitar | Nethermind: But yeah, I'm also I would like to hear feedback from others on this.

484
01:16:48.860 --> 01:16:50.492
Francis: To answer your questions.

485
01:16:51.440 --> 01:17:13.099
Francis: for delay. Execution does have a tangible benefits for pre-confs, at least in l. 2. For example, for flash blocks that the Ob stack is kind of like getting on right. Now we have to reserve 500 ms of time at the end of the slot to just do insertion of the block of the preconfer blocks into the actual sequencer.

486
01:17:13.120 --> 01:17:29.579
Francis: and if we can do delayed execution, that 500 ms can become, can move to the next slot, which becomes a total 2 seconds for the execution, and it makes the precons like much more smoother and like truly like like pre-confs in the time slots that we

487
01:17:29.630 --> 01:17:52.890
Francis: we are building. So that's the 1st thing. The second thing about the Epps has better benefits for the broad scaling definitely. Yes, our thinking currently, maybe it's not entirely accurate is that based on what we've seen seems like delayed execution can provide 80% of the benefit. And the other thing that into the consideration is that

488
01:17:55.180 --> 01:18:17.590
Francis: I kind of like, maybe like, it's just me. But I feel like the Epbs testing could be a very tricky thing to get to. I understand it's more stable. It's more mature at its current state right now, but I kind of fear. With all the introduced changes, the testing can be very hard to get right, and can like delay the timelines. And finally, regarding the blob throughput.

489
01:18:17.730 --> 01:18:38.479
Francis: my current thought is that with peer that's going out, that we can potentially theoretically get to 48 blocks, and the 80% of the benefits from delayed execution seems good enough for the foreseeable future. For like block scaling. So yeah, that's that's my overall thinking.

490
01:18:45.550 --> 01:18:46.220
Tim Beiko: Thanks.

491
01:18:48.140 --> 01:18:51.459
Tim Beiko: And okay, Mark, yeah, do you have that as well.

492
01:18:52.470 --> 01:18:54.479
ethDreamer (Mark): Yeah, I mean, I just wanted to

493
01:18:54.630 --> 01:19:00.929
ethDreamer (Mark): make explicit that that line of reasoning is their prerogative. But it's sort of like.

494
01:19:01.636 --> 01:19:13.760
ethDreamer (Mark): you know we're advocating for delayed execution on l. 1, because it makes it puts code that can best be reused on L. 2, not necessarily because it's the best option for l 1

495
01:19:15.510 --> 01:19:18.539
ethDreamer (Mark): and like that's obviously their prerogative, and

496
01:19:18.690 --> 01:19:27.060
ethDreamer (Mark): and so on. But I mean, I think we also have a line of clients. Don't. We have like an implementation of like.

497
01:19:27.820 --> 01:19:33.499
ethDreamer (Mark): I mean, I think we're committed to maintaining a version of guest for L. 2 s. That has these kinds of features.

498
01:19:33.650 --> 01:19:36.719
ethDreamer (Mark): and it doesn't necessarily mean that if we have a better

499
01:19:37.160 --> 01:19:44.230
ethDreamer (Mark): option, not that he's saying that it is a better or worse option, but if we do have a better option for l 1 that we can, we can take that

500
01:19:45.930 --> 01:19:52.170
ethDreamer (Mark): and then yeah, I mean, I think

501
01:19:52.580 --> 01:19:55.739
ethDreamer (Mark): for me the one of the biggest reasons to do.

502
01:19:55.890 --> 01:20:05.820
ethDreamer (Mark): Epbs over delayed execution is the block payload. Separation is the the synergies with fossil and just like

503
01:20:06.230 --> 01:20:07.395
ethDreamer (Mark): better.

504
01:20:08.680 --> 01:20:16.349
ethDreamer (Mark): what is it like the types of low car, like proposer equivocation, low car, Crusader type attacks become better.

505
01:20:18.310 --> 01:20:22.739
ethDreamer (Mark): Yeah, like, there's a lot of reasons to still do, Epps.

506
01:20:24.450 --> 01:20:29.739
ethDreamer (Mark): And yeah, I guess that debate is probably going to happen next next call. But

507
01:20:32.820 --> 01:20:42.110
ethDreamer (Mark): yeah, so I would. I guess my my counter to that would be like. Could we not do something like delayed execution for the layer? 2 fork of yes.

508
01:20:45.630 --> 01:20:54.519
Tim Beiko: I mean, we've struggled to do more basic things on L. Two's and get them like adopted. So I

509
01:20:55.690 --> 01:21:03.670
Tim Beiko: I'm personally quite bearish on the idea that L. Twos would adopt like a pretty big minor size feature

510
01:21:04.080 --> 01:21:07.221
Tim Beiko: without a 1 supporting it.

511
01:21:09.110 --> 01:21:11.480
Tim Beiko: yeah, Francis, I don't know if you want to add more. There.

512
01:21:12.221 --> 01:21:18.800
Francis: The adopting that is definitely a concern. But it's, I think, as Mark mentioned, it's not

513
01:21:19.000 --> 01:21:38.699
Francis: absolutely not doable like, I guess my question is that my understanding for delayed execution is that it still has benefits for l. 1 s. As well. Just because, like moving execution to the maybe the latest, the later block can free up to the preconsistence to be able to kind of truly like using the entire slot.

514
01:21:38.810 --> 01:21:41.189
Francis: So please correct me if I'm wrong. There.

515
01:21:49.356 --> 01:21:56.700
Tim Beiko: Yeah. So data execution would be helpful on l. 1 as well. Yes, and.

516
01:21:58.340 --> 01:22:00.560
Francis: Okay, then, in that case.

517
01:22:01.510 --> 01:22:09.690
Francis: I think our kind of like previous argument is still valid. It's both good for l, 1 and L, 2. And yeah.

518
01:22:12.660 --> 01:22:15.589
Tim Beiko: Alright, thanks see Felix and Tony.

519
01:22:17.210 --> 01:22:23.459
Felix (Geth): Yeah. So I can just quickly go because you mentioned explicitly like implementation of this in Geth.

520
01:22:23.560 --> 01:22:29.699
Felix (Geth): So as far as I know, there's no active implementation of this change in Gath.

521
01:22:30.940 --> 01:22:59.970
Felix (Geth): Ultimately, the current strategies of on our side is that we do now, since the beginning of the year, care a lot more about basically trying to keep the upstream friendly, for, like any changes that are made in support of the downstream L 2 forks of Geth. So I would actually love to discuss, like the implications of implementing delayed execution for the use by L. 2 s. In Geth. But I also think it's maybe not entirely

522
01:23:00.600 --> 01:23:03.650
Felix (Geth): worth discussing it on this call.

523
01:23:04.840 --> 01:23:07.350
Felix (Geth): And also, I think it's like there's no

524
01:23:07.540 --> 01:23:13.560
Felix (Geth): like the timeline, for it is also a bit different, like we can definitely discuss it. But it's not like in the context of

525
01:23:13.920 --> 01:23:16.810
Felix (Geth): the Glamsterdam l. 1 fork.

526
01:23:20.180 --> 01:23:20.800
Tim Beiko: Thanks.

527
01:23:21.280 --> 01:23:23.110
Tim Beiko: I'm Tony.

528
01:23:25.960 --> 01:23:36.959
Toni Wahrstätter: Yeah, I think one thing that would be very helpful to have and to help us. To guide the decision would be having some numbers on the final deadlines within the slot.

529
01:23:37.060 --> 01:23:49.729
Toni Wahrstätter: because there was this free option problem that everyone heard of, and it would be super interesting to know what the actual difference between delayed execution and epbs is, finally, because

530
01:23:49.980 --> 01:24:12.990
Toni Wahrstätter: initially, the delayed execution couldn't give you as much pipelining than Epbs, because the Ptc. Is just a smaller committee that you can put at the very end of the slot. This is essentially the trick, and it's a very nice one, but it also led to this free option problem. And then it's also worth discussing. How much does this actually impact epbs?

531
01:24:13.508 --> 01:24:19.239
Toni Wahrstätter: Right now, I think it hasn't impacted the specs yet, but this is also like published

532
01:24:19.860 --> 01:24:25.930
Toni Wahrstätter: end of last week, or something, so it would be interesting to know, like what it eventually does.

533
01:24:31.910 --> 01:24:32.610
Tim Beiko: Okay?

534
01:24:33.160 --> 01:24:41.159
Tim Beiko: So I guess, yeah, this plus the comment around the free option. Yeah, like, the free option right up.

535
01:24:41.930 --> 01:24:57.963
Tim Beiko: make meaning towards finalizing this discussion on next week's call. We should see a 5 block accesses today. And again, I think, if if we move forward with Epbs next week. We can also make it clear. We we move forward with block access lists.

536
01:24:59.260 --> 01:25:01.670
Tim Beiko: but yes, that's your downstream of that decision

537
01:25:05.100 --> 01:25:07.520
Tim Beiko: that makes sense people.

538
01:25:08.980 --> 01:25:34.710
Tim Beiko: And one thing sorry I forgot to mention as well. This came up in the chat, but we've collected on each magicians feedback from the community on which headliners they would like, and next so posted the link as well, and evbs or sorry not Evbs block accesses came up like quite frequently in that thread, too. So I think, even beyond just the core. That's group. It seems like there's strong support for for block accesses.

539
01:25:35.620 --> 01:25:36.370
Tim Beiko: yep.

540
01:25:37.100 --> 01:25:52.200
Tim Beiko: so we'll move forward with Cfi and block accesses. We'll make a final call on the headliners next week at least on the Cl. Side. If that headliners is Eps, then we'll also have block accesses alongside it.

541
01:25:54.570 --> 01:25:58.209
Tim Beiko: Anything else people want to discuss about slabsurgon before we wrap up.

542
01:26:06.190 --> 01:26:28.480
Tim Beiko: Okay? Then we can. Yeah, we can call it a day. Again, the main 3 things as figuring out next steps on the transaction size limit on the testing call next week, and then the the headliner Discussion and Timeline discussion, The Glamsterdam Headliner Discussion and Fusaka Timeline discussion on the Cl. Call next Thursday.

543
01:26:29.614 --> 01:26:32.520
Tim Beiko: Anskar, do you want to add anything before we wrap up.

544
01:26:32.520 --> 01:26:48.559
Ansgar Dietrichs: Yeah, just very quickly. I wanted to double check, because I do remember that block level access lists had some variants. Now, I think, already at interop. We looked into those right and like we, I think there was this general feeling that the current variant of the IP which basically includes just the

545
01:26:48.560 --> 01:27:09.989
Ansgar Dietrichs: read locations and then the right locations and values. That is basically the best version of block level access lists. But given that that was a bit of a design space and basically different options at some point were all thrown around. I just wanted to double check like, are we at this point now that we're cfiing it already, confident that, like the version as is in the Mp. Today, it seems to be my favorite version. But I just want to get a temperature check.

546
01:27:09.990 --> 01:27:19.910
Ansgar Dietrichs: Are we basically cfiing blocks list and saying, Oh, we're still going to like iterate on like, what exact version of it? Or is this already kind of a vote of confidence for that specific flavor of it?

547
01:27:23.540 --> 01:27:33.480
Toni Wahrstätter: I think right now we are kind of early in the process, because none of no one from the clients has a complete implementation except Gaff. So I think Jared.

548
01:27:33.993 --> 01:27:40.519
Toni Wahrstätter: is, as we are talking, collecting some 1st numbers there, so we should have them very soon.

549
01:27:40.800 --> 01:28:02.770
Toni Wahrstätter: and if we're talking about the size of the object. Then the reads wouldn't matter that much. So I think 30% of the block level 30 kB is from storage changes and only 10% from storage locations. So from the size perspective, it wouldn't matter that much if clients say we don't need the read locations

550
01:28:02.900 --> 01:28:19.590
Toni Wahrstätter: to do parallel. I/O, then we can still exclude them. We have spec both versions. There are also tests for both versions. It should be a quite easy change to move from, including the storage locations, to excluding them.

551
01:28:21.710 --> 01:28:29.079
Jared Wasinger: Wait. Just to be clear. Are you saying that, including the read locations, bumps the size by 30%? Did I understand that correctly?

552
01:28:29.080 --> 01:28:33.580
Toni Wahrstätter: No, yeah, I actually, yeah, exactly 30%. So.

553
01:28:33.580 --> 01:28:44.119
Jared Wasinger: So I guess I would say like right now, and I plan to grab some benchmarks related to the read locations. But intuitively it just doesn't

554
01:28:45.170 --> 01:28:54.639
Jared Wasinger: I? I don't understand why they're needed, because, it seem it would seem like they would be important for being able to

555
01:28:55.090 --> 01:29:02.750
Jared Wasinger: prefetch reads ahead of time. So like when you start the transaction execution. And you're right now

556
01:29:02.940 --> 01:29:10.479
Jared Wasinger: you're doing the transactions serially. If you had some pre knowledge of read locations, you could fetch them ahead of time.

557
01:29:10.840 --> 01:29:20.370
Jared Wasinger: But if we're executing transactions in parallel, that doesn't really leave time to do that. So I

558
01:29:21.300 --> 01:29:26.659
Jared Wasinger: yeah, right now I I guess I just don't see what including them brings to the table.

559
01:29:27.358 --> 01:29:30.789
Jared Wasinger: But I mean we can certainly get numbers.

560
01:29:34.960 --> 01:29:40.130
Ben Adams: I mean it does bring additionally, because you know you're not.

561
01:29:41.810 --> 01:29:51.480
Ben Adams: If you've got 8 cpus, and you're executing 8 transactions in parallel. You can do the reads for the transactions further down the pipeline already.

562
01:29:52.880 --> 01:29:56.350
Ben Adams: But just like, say, it sort of depends on

563
01:29:56.690 --> 01:30:08.890
Ben Adams: whether epbs is the choice, because that gives more time for larger blocks. And yeah, I'm not sure

564
01:30:09.740 --> 01:30:11.289
Ben Adams: load execution does.

565
01:30:13.200 --> 01:30:17.779
Ben Adams: So. The the size of the block level access list would change propagation.

566
01:30:23.270 --> 01:30:30.955
Tim Beiko: Okay? So I guess, like, yes, clearly, there will be some exploration to do on this specific variant.

567
01:30:35.380 --> 01:30:40.100
Tim Beiko: okay, anything else before we wrap up

568
01:30:45.720 --> 01:30:56.980
Tim Beiko: great? Well, yeah, thanks everyone. I'll post a summary later today. But again remain. Things are transaction limit. Susaka timelines and scale headliners to sort out next week.

569
01:30:57.390 --> 01:30:58.390
Tim Beiko: That's gusting.

570
01:30:59.710 --> 01:31:00.440
Pooja Ranjan: Thank you.

571
01:31:00.920 --> 01:31:02.000
stokes: Thank you.

572
01:31:03.280 --> 01:31:04.010
Fredrik: Thank you.

573
01:31:05.650 --> 01:31:06.359
Ansgar Dietrichs: Thanks. Everyone.

574
01:31:07.370 --> 01:31:08.300
potuz: Bye-bye.

