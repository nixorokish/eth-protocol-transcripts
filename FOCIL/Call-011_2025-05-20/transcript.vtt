WEBVTT

1
00:05:46.560 --> 00:05:47.630
thomasthiery: Hello!

2
00:05:49.880 --> 00:05:51.929
Pooja Ranjan: Hey, Thomas, hey, everyone.

3
00:05:53.680 --> 00:06:02.905
thomasthiery: Sorry. But the back and forth earlier, I was like, today is a bit crazy. I have 6 back to back calls, but

4
00:06:03.680 --> 00:06:15.490
Pooja Ranjan: No, no worries, I can totally understand. I would still like to make some other changes, but I'm hoping to share a document with you before you make the next meeting agenda. So that might yeah.

5
00:06:15.490 --> 00:06:26.720
thomasthiery: Yeah, that sounds great. Yeah, thanks. I've honestly not been exactly sure how to deal with the whole but situation. But yeah, if you have a dog. That would be amazing.

6
00:06:26.720 --> 00:06:33.850
Pooja Ranjan: Yes, I I think that would be helpful to many other facilitators. We have been receiving this kind of inconsistencies. Yeah, no.

7
00:06:33.850 --> 00:06:34.200
thomasthiery: Okay.

8
00:06:34.200 --> 00:06:34.750
Pooja Ranjan: Yeah.

9
00:06:34.880 --> 00:06:37.580
thomasthiery: Okay, that makes sense nice, great.

10
00:06:39.170 --> 00:06:48.940
Pooja Ranjan: Alright. So this meeting is already going to be recorded, Thomas, so we don't have to start the recording button, but it would be nice when you let us know like, whenever you're starting.

11
00:06:49.790 --> 00:06:56.950
Pooja Ranjan: give us a 2 to 5 second interval, so we can switch over. Just let us know, and we can switch over the stream.

12
00:06:57.340 --> 00:06:59.790
thomasthiery: Okay, yeah, that sounds good. Perfect. Thanks.

13
00:09:00.660 --> 00:09:04.070
thomasthiery: Hello, hello, everyone. Thanks for joining.

14
00:09:17.150 --> 00:09:21.790
thomasthiery: Let's wait another minute, and then we can start.

15
00:10:14.960 --> 00:10:18.859
thomasthiery: Alright. Yeah, I think we can.

16
00:10:19.010 --> 00:10:26.500
thomasthiery: Well, the recording is already started. But maybe we can just go ahead and start the session. Nice

17
00:10:26.630 --> 00:10:35.579
thomasthiery: thanks so welcome everyone to fossil breakout number 11, I think. Yes,

18
00:10:37.488 --> 00:10:44.461
thomasthiery: today, we're gonna have a presentation by Michael on relay inclusion lists before this.

19
00:10:45.090 --> 00:10:51.569
thomasthiery: just want to tell you about the few updates related to fossil.

20
00:10:52.455 --> 00:11:08.609
thomasthiery: Yeah. First, st I think I mentioned it last time. But we are planning the fossil session during the Berlin interrupt, which is, gonna be in June. Exactly on. Wait. Let me check exactly the day

21
00:11:09.450 --> 00:11:23.410
thomasthiery: it's gonna be on Wednesday, the 11, th I think so, for those of you who are around. You are, of course, invited and just. Dm, me, and let me know, and I'll just like tell you the exact time and location

22
00:11:23.980 --> 00:11:37.510
thomasthiery: most speakers are like confirmed and basically, the sessions are gonna be for sole implementation progress. We're gonna have one that by, that's gonna be by Jihoon.

23
00:11:37.620 --> 00:11:54.849
thomasthiery: one on fossil synergies with other eips that's going to be by Francesco. We're going to have one on fossil and statelessness by Carlos, one on Zk fossil, by Benedict, one by fossil and the future of nodes by Barnaby.

24
00:11:55.998 --> 00:12:07.500
thomasthiery: So I think that's gonna be very exciting to just like, talk about all these in in person. And yeah, if you're around, just join us, I think would be fun.

25
00:12:08.290 --> 00:12:35.369
thomasthiery: yeah. But like the fossil synergies, another update is like, sort of like the progress made on the interaction between fossil delayed execution and block access lists. It's nice. Because basically, if you have block access list with post transaction values, that mostly allows attestors to statically validate

26
00:12:35.830 --> 00:12:53.750
thomasthiery: blocks and especially like the fossil conditions in a much like simpler way that than before. So I mean Tony and Francesco, I think I'm mostly working on this. I've been just like

27
00:12:53.810 --> 00:13:15.750
thomasthiery: following along and providing inputs. But yeah, it's it's just like nice to see that a couple of like different eips actually make make it easier for each other. So that's something I think we need to follow up on. But yeah, I think it's it's just like, nice.

28
00:13:16.466 --> 00:13:21.819
thomasthiery: Yeah. Just also wanted to highlight highlight one of it that exposed.

29
00:13:22.010 --> 00:13:26.249
thomasthiery: But the local node favoring Delta to the scaling roadmap.

30
00:13:26.500 --> 00:13:35.979
thomasthiery: I recommend checking it out, cause it actually quite related to verbs. So validity, only

31
00:13:36.030 --> 00:14:01.159
thomasthiery: partial statelessness, something we presented during a previous breakout room. And you know, in the comments there are like, sort of like a lot of discussions, and back and forth on the future of fossil. And what fossil can be like and how it interacts with full native account abstraction. So, yeah, if you have opinions or want to

32
00:14:01.170 --> 00:14:07.309
thomasthiery: comment or participate in the discussions, you can check it out there.

33
00:14:08.234 --> 00:14:28.359
thomasthiery: Other update, I think. It's also nice to highlight when new people join like discord conversations. And it's been the case lately. So yeah, it's just like great to have, like more and more people engaging on on this and like asking questions and being curious, but also

34
00:14:28.842 --> 00:14:33.829
thomasthiery: so if you have any more questions you can also ask them during this breakout?

35
00:14:35.430 --> 00:14:38.560
thomasthiery: And yeah, I think that's mostly for me.

36
00:14:39.840 --> 00:14:44.909
thomasthiery: Are there any questions on any of these small updates.

37
00:14:51.470 --> 00:14:52.660
thomasthiery: Nope.

38
00:14:52.810 --> 00:15:02.209
thomasthiery: then we can go ahead. And with the presentation. So I think, yeah, it's gonna be Michael on relay inclusion lists.

39
00:15:04.815 --> 00:15:10.170
Kubi & Michael: Yeah, Hi, guys, we are sharing our screen. We should be in in a second.

40
00:15:12.930 --> 00:15:17.099
Kubi & Michael: Okay? Just to confirm, can you guys see the screen.

41
00:15:17.790 --> 00:15:18.185
thomasthiery: Yep.

42
00:15:19.290 --> 00:15:33.580
Kubi & Michael: Okay, perfect. So 1st of all, thanks for the opportunity to present our design here today, relay inclusion lists. We have a post up on Eve research, and thanks also to everybody that provided feedback on this design.

43
00:15:33.750 --> 00:15:46.330
Kubi & Michael: we can also then continue the discussion on Eve research. There's already some good exchange of ideas going on there. But in any case, without further ado, let's jump in.

44
00:15:47.550 --> 00:15:54.409
Kubi & Michael: So the agenda for the presentation is to 1st quickly describe the goals of relay inclusion lists

45
00:15:54.550 --> 00:16:09.979
Kubi & Michael: specifically what we want to achieve here. There's 3 goals, and we'll walk over them first, st then to sketch out the design. That is the architecture of the system. And then there's basically 2 more or less discretionary dimensions

46
00:16:10.100 --> 00:16:33.769
Kubi & Michael: which will deep dive separately. And the 1st of those is what transactions to include. So the inclusion rule. And then the second is, how many transactions do we include which is the size in question? The size of the inclusion list in terms of network size. So bytes specifically. And then, lastly, we want to talk quickly about the future directions.

47
00:16:36.090 --> 00:16:43.249
Kubi & Michael: So the design goals. Well, first, st we want to use relays to immediately improve censorship resistance.

48
00:16:43.360 --> 00:16:48.589
Kubi & Michael: And we want to do this in, you know a certain, a certain aligned way.

49
00:16:48.730 --> 00:16:57.130
Kubi & Michael: First, st we want to avoid introducing protocol changes or other technical complexity which would make the design forbidding.

50
00:16:57.250 --> 00:17:08.699
Kubi & Michael: So specifically, our goal is to have something that could be applied tomorrow and immediately start increasing censorship resistance adding value. In this type of transparent way.

51
00:17:08.839 --> 00:17:37.819
Kubi & Michael: We also don't want to introduce qualitatively new trust assumptions. What that means is that relay inclusion lists can be accomplished by the existing actors in the Pbs. Pipeline and validators wouldn't need to trust somebody new. They also wouldn't need to make a decision if they trust somebody more. So basically, the relays that they would be using these would be the relays that would start delivering relay inclusion lists.

52
00:17:37.960 --> 00:18:01.520
Kubi & Michael: And lastly, one thing I want to highlight, we ideally would like to see relay inclusion lists as a baseline. So this should be a new default feature for non-censoring relays where the validator may opt out if it really desires that, but generally for a non-censoring relay, it should be building relay inclusion lists by default.

53
00:18:02.220 --> 00:18:16.010
Kubi & Michael: Now, the second goal of the design is to prepare the block production pipeline for a future in protocol inclusion list put a different way. Relay inclusion lists are not a substitute.

54
00:18:16.210 --> 00:18:22.429
Kubi & Michael: for in protocol inclusionists we we see them as a logical step in this direction and a quick step.

55
00:18:22.670 --> 00:18:47.949
Kubi & Michael: What that means in practice is, first, st we want real inclusion lists to roughly reflect the fossil specifications. And the way we would like this to reflect is that the risks of the design incremental. Right? There's something that's rolled out step by step. There's testing and it's done off chain. And then this would result in a seamless operational rollover to fossil.

56
00:18:47.960 --> 00:18:59.909
Kubi & Michael: if I put it in practical terms. If in protocol, including this, come about, builders, relays would know how to how to would know how to coordinate

57
00:18:59.940 --> 00:19:07.839
Kubi & Michael: on on such a list being being built. And this is not just technical. This is also things like bidding dynamics.

58
00:19:08.060 --> 00:19:22.390
Kubi & Michael: And then, lastly, we want to achieve these 2 overarching goals in a sustainable way, right? And which means that the relay inclusion list at the beginning should preserve, relay, competitiveness.

59
00:19:22.420 --> 00:19:42.280
Kubi & Michael: or put another way. Proposal, risk, reward. And one thing that means is what I mentioned initially, no additional load on the proposal, and then, secondly, block value should not be meaningfully decreased, because if the Relay inclusion list were very large and would add a lot of latency.

60
00:19:42.480 --> 00:20:02.120
Kubi & Michael: and the block value were to decrease, this would. This would just make the relay less competitive, and in this way timely inclusion, you know, would would kind of decrease over this separate axis of just the relay not winning the slots. But we think we have a good way of approaching all 3 of these goals.

61
00:20:04.920 --> 00:20:31.680
Kubi & Michael: Yeah, the design overview. You see, it sketched out on the right there. And again, one goal for this is to be quick, and that means it needs to be transparent and simple. There's basically 3 kind of 3 steps, and they're preceded by a setup, which is that non-censoring relays by default should build relay inclusionists for all proposals with that optional opt out.

62
00:20:31.830 --> 00:20:47.789
Kubi & Michael: Now, once the setup stage has been completed, what would happen is for each slot the relay observes the main pool and then ranks these transactions via a deterministic inclusion rule

63
00:20:47.910 --> 00:21:16.580
Kubi & Michael: assigning a score to each, and the inclusion rule is something that will be discussed on the next slide. So I will skip that part for the moment, and instead focus on the general setup. Then, once the relay has derived the weighted, the list of transactions ranked by inclusion score. It would fill the inclusion list with the respective top ranked transaction until the relay inclusion list size remit has been reached.

64
00:21:16.680 --> 00:21:20.439
Kubi & Michael: and then, lastly, once the list has been built.

65
00:21:20.600 --> 00:21:27.160
Kubi & Michael: the relay would expose a Api endpoint that builders can use to fetch the inclusion list.

66
00:21:27.600 --> 00:21:48.829
Kubi & Michael: So this is part one at the beginning of the slot. And then there's Part 2, which is after the builder has seen the inclusion list and has started to, has reflected it in its block. So this is when the builder delivers the block, then the relay simulates the execution. So 1st the relay checks.

67
00:21:49.070 --> 00:22:02.709
Kubi & Michael: If all transactions in the inclusion list are included in the block, and if a transaction in the inclusion list were not included in the block, the relay would simulate its execution against the block's post date.

68
00:22:02.910 --> 00:22:14.719
Kubi & Michael: And then, if any non-included transactions pass standard pre-execution, validity checks the block is invalid and rejected right? So this is a strict condition.

69
00:22:14.850 --> 00:22:39.749
Kubi & Michael: Thirdly, if a builder is optimistic. The reeler might not be able to reject the block in time. Instead, what would happen is there would be a penalty enforced against the builder. And the way we propose handling this penalty in our research post is that it should reflect the block value, because factually, the block would be 4 feet.

70
00:22:40.010 --> 00:22:54.430
Kubi & Michael: There's another question that came up in previous discussions, which is what happens if the builders block is already full, this would not be a scenario that we would be concerned about at the moment.

71
00:22:54.480 --> 00:23:13.530
Kubi & Michael: because the builder would have the list of transactions in the inclusion list available at the beginning of the slot, and therefore should, as part of standard procedure sorted into its block, which means that the block wouldn't be full without the transaction on the Relay inclusion list being included.

72
00:23:16.250 --> 00:23:45.999
Kubi & Michael: Now, the next thing is the inclusion rule. So we are quickly summarizing 2 options here. Option one which, by the way, thanks for that, Anders has proposed on. If research is a lot leaner than option. 2. I kind of refer to these options respectively as multiplicative without normalization, that is, option one and normalized and additive, which is option 2

73
00:23:46.360 --> 00:24:00.370
Kubi & Michael: for option one. I'm not going to deep dive both of them right now, but I'll just quickly summarize it, and then we can examine it in more depth, maybe in the discussion afterwards, or any research or Async

74
00:24:00.470 --> 00:24:17.020
Kubi & Michael: option. One basically computes the inclusion score over the waiting time of the transaction in the mempole and the priority fee of the transaction. As a multiplication of each attribute

75
00:24:17.170 --> 00:24:36.010
Kubi & Michael: optionally, there could be a weight added for each attribute. For example, if we were to want to say that the priority fee is more important than the waiting time, we could reflect this, but initially we would assume that the weights are 0, or put another way, that they're equally important.

76
00:24:36.120 --> 00:24:55.230
Kubi & Michael: And the logic behind this is that we say, you know inclusion. This happens over a time axis, so we wouldn't want the transaction to sit in the mempole forever. And but it is also a function of how quick the transaction wants to get in, which is the pro ad fee component.

77
00:24:55.370 --> 00:25:06.569
Kubi & Michael: and then the inclusion score that will have been derived would be adjusted by the total gas paid per transaction.

78
00:25:06.930 --> 00:25:15.799
Kubi & Michael: Put another way. We would want to maximize the space that is still available in the inclusion list.

79
00:25:15.900 --> 00:25:28.380
Kubi & Michael: It's worth highlighting here that the inclusion list is measured in network terms. So in Kilobyte. But the final adjustment here would basically be saying, well, the block space, the block space has to be

80
00:25:28.570 --> 00:25:32.129
Kubi & Michael: has to be maximized in terms of value.

81
00:25:32.420 --> 00:25:47.300
Kubi & Michael: Then there's option 2, which is normalized and additive. Again, one key difference here is multiplication of the waiting time, and the fee or addition of the waiting time and the fee score.

82
00:25:47.590 --> 00:26:01.870
Kubi & Michael: The implication of multiplication is that a transaction which has a priority view of 0 would not find inclusion, whereas, with addition, this would be, this would be the case.

83
00:26:03.260 --> 00:26:08.730
Kubi & Michael: Then, for the addition rule, we would again begin by

84
00:26:09.010 --> 00:26:29.930
Kubi & Michael: examining the waiting time and the priority fee, and we would normalize it by the Median waiting time or priority fee for all transactions pending in the main pool. Then we would compute a simple additive score and divide that by the bite size which would be a way of maximizing over the networking constraint.

85
00:26:30.200 --> 00:26:40.369
Kubi & Michael: So to quickly summarize the slide here before we go further, the difference between these 2 roles would be multiplication or addition.

86
00:26:40.380 --> 00:27:08.080
Kubi & Michael: which is a statement of, you know, does a transaction that only pays the base fee. Should that transaction find inclusion, it is also a way of kind of handling manipulation, resistance in different ways. Multiplication without normalization has some spam resistance built in, and again, transactions are compared to each other in both scenarios.

87
00:27:08.768 --> 00:27:15.380
Kubi & Michael: And then the inclusion score by total guess paid or by the transaction byte size. This would

88
00:27:15.520 --> 00:27:28.229
Kubi & Michael: be an implied statement, or what? The what? The bottleneck is right, is it? Is it block space, or is it networking where the byte size would go networking, and then block space would be measured in in gas?

89
00:27:28.874 --> 00:27:34.390
Kubi & Michael: Generally our feeling is that these are both appropriate ways of approaching it.

90
00:27:34.900 --> 00:27:49.319
Kubi & Michael: We find option one quite lean and and elegant, but generally we would see this as a discussion kind of with the with the stakeholders, and then we can come to a final decision from there.

91
00:27:51.560 --> 00:28:10.660
Kubi & Michael: The next point or the next kind of parameter decision is the sizing of the inclusion list. And that's basically one overarching goal here, which is that the size of the inclusion list shouldn't really meaningfully affect block value or put another way, decrease block value.

92
00:28:10.930 --> 00:28:20.280
Kubi & Michael: And the context here is that block value decreases with increased latency, and then latency. Of course, scales with the size of the inclusion list.

93
00:28:20.894 --> 00:28:31.950
Kubi & Michael: This kind of foreshadows the point that I made at the beginning, which is, that relays providing relay inclusionists must must stay competitive right to ensure timely inclusion

94
00:28:32.180 --> 00:28:37.080
Kubi & Michael: and to ensure the the design. Finding continued validator adoption.

95
00:28:37.260 --> 00:28:54.609
Kubi & Michael: which is the reason why we initially propose a shelling point, which is the constraint proposed in the fossil specs which is lean. With that said relay. Inclusion lists have a big advantage over proposal. Driven inclusion lists.

96
00:28:54.750 --> 00:29:15.850
Kubi & Michael: which is that they're not constrained by the proposal bandwidth, which is the second point on the slide here, and what that means is as relay inclusionists become more adopted. They can support larger sizing. One reason for this is that the opportunity cost of opting into relay inclusion list decreases

97
00:29:16.150 --> 00:29:34.179
Kubi & Michael: for the more relays run it, and therefore they can't be larger, right? Because you don't have to compete with relays that opt out of relay inclusion list on latency. If everybody competes on the same terms, it's possible to raise the size without incurring cost.

98
00:29:34.400 --> 00:29:52.350
Kubi & Michael: And the second thing is, the bit curve can shift to accommodate the the marginal latency that really inclusion this ad, so basically, if I know that the block will be sent around a little bit earlier, I can provide my my best bit a little bit earlier.

99
00:29:55.260 --> 00:30:04.270
Kubi & Michael: and then, just to wrap it up. We think there are some promising future directions here. And 1st of all, multi-relay inclusion lists.

100
00:30:04.340 --> 00:30:26.309
Kubi & Michael: What this would mean is, there could be a shared inclusion list that can be built from the inclusion list computed by multiple relays. One advantage of this is that it improves censorship resistance by enforcing uniform application of the inclusion rule. So there could be a single relay which kind of builds the inclusion list to

101
00:30:26.914 --> 00:30:46.319
Kubi & Michael: to maximize. It's, you know, for whatever goal it might be pursuing, there's there's a lot more. There's a lot more assurance that the inclusion role is is applied consistently, and then because it it is also the same for each relay the playing field would be even.

102
00:30:46.880 --> 00:31:13.410
Kubi & Michael: And then, secondly, if each relay builds an inclusion list only locally. There's a chance that builders want to keep a lot of optionality right? So they might build one block for relay a and another block for Relay B. Under multi-relay inclusion list, they would build one block for all relays which reduces redundancy, and then again also unlocks some efficiency. In this way.

103
00:31:13.590 --> 00:31:19.380
Kubi & Michael: The other 2 directions we see are really inclusion is for blob type transactions.

104
00:31:19.620 --> 00:31:24.960
Kubi & Michael: And lastly, what we mentioned before, larger, larger relay inclusion list.

105
00:31:25.410 --> 00:31:53.970
Kubi & Michael: To conclude the slides. There's some further reading here. The 1st is the Eve Research Post, which I would encourage people interested in this idea to consult, and then the post has a couple of references that we make all very interesting reads which are listed below it. So I would suggest checking this out, too. Yeah, so that's it from my end.

106
00:31:56.890 --> 00:32:16.949
thomasthiery: Great thanks a lot that was that was really cool. And yeah, very nice to to see that you guys have worked on on the inclusion list side of things for relays also that the work on fossil was useful to to build that up. It's very nice to see.

107
00:32:17.462 --> 00:32:27.619
thomasthiery: I have quite a lot of questions, but I want to give the opportunity of other people to ask some first.st So if anyone has some go ahead.

108
00:32:37.940 --> 00:32:51.710
Mercy Boma Naps-Nkari: Sorry. Just a random question. I want to know, could the relays prioritize certain transaction like inadvertently introducing new centralization risks like relays becoming gatekeepers, or something like that.

109
00:32:56.610 --> 00:33:00.119
Kubi & Michael: Yeah, sure. So this is something that

110
00:33:00.250 --> 00:33:22.330
Kubi & Michael: we want to avoid. And there's 1. There's 2 key key steps that have to be taken to avoid the relay kind of making these discretionary decisions. One is the inclusion list. Inclusion rule has to be very simple. So there's not a lot of room for discretion. Right? So the relay applies it. Each relay applies it in a way that is uniform.

111
00:33:22.400 --> 00:33:41.440
Kubi & Michael: And then, secondly, one of the future directions we outlined, which is relays talking to each other. That helps with that, too, because if relays collectively, decide on the final inclusion list, then individual relays have a lot less power to kind of skew the list into a direction which which they would prefer.

112
00:33:44.360 --> 00:33:56.679
Mercy Boma Naps-Nkari: Oh, okay. And one last thing is there, like a possible interaction with proposal, build separation, especially if the builders ignore leads to maximum. Mev.

113
00:33:59.990 --> 00:34:09.120
Kubi & Michael: Yeah, so I mean, the the entire design is like, purposely built such that it fits onto the current pbs, supply chain.

114
00:34:09.120 --> 00:34:31.869
Kubi & Michael: And so, yeah, the intent is just to communicate these constraints or the inclusion list to the block builders, and they have to adhere to it. So unless there are relays that don't support it, basically for a given slots. If a proposal connects to these relays, a block will not be valid. So it essentially is purposely built for the Pbs supply chain as exists today.

115
00:34:39.840 --> 00:34:43.559
thomasthiery: Nice. Okay, I will go ahead with some of mine.

116
00:34:45.770 --> 00:35:00.240
thomasthiery: Yeah, just one. No, this is more of a comment, but just wanted to point out that the fossil size is 8 kB, but there are like 16 of them. So you know, if there are, there is no overlap that will actually be 16 times 8 kB

117
00:35:00.630 --> 00:35:17.220
thomasthiery: but I know bandwidth is a concern. I just wanted to to sort of like make that clear. Also, like that was in in your last slide. But but Blob is would actually be really, really cool. It's more bandwidth for sure.

118
00:35:17.825 --> 00:35:36.019
thomasthiery: I think it's actually around the side of like 16 times 8 kB for one blob. But you know, fossil doesn't support this in its current form. We have ideas of like protocol ways to

119
00:35:36.150 --> 00:35:48.989
thomasthiery: get better sense of resistance for blobs. But it's it's really not there yet, at least like not at the same stage. As for solids. So yeah, I mean, I think that's a very exciting direction.

120
00:35:50.540 --> 00:35:57.419
thomasthiery: And then, yeah, yeah, there was more comment. But if you have any answers.

121
00:35:58.030 --> 00:36:17.770
Kubi & Michael: Yeah, so quick comments on the the blob is so, as you said correctly, the biggest concern is just the size and the additional latency, and hence preventing adoption, or like putting relays that basically adopt this like in in a worse spot, in terms of competitiveness.

122
00:36:18.337 --> 00:36:31.400
Kubi & Michael: That being said, we're currently already exploring optimistic. V, 3, for relays. Which essentially means that the builders can submit the headers

123
00:36:31.430 --> 00:36:43.150
Kubi & Michael: without submitting the payloads which effectively means they can, like on a low latency basis, keep updating their bits without having to shuffle the entire big block payload. And so

124
00:36:43.450 --> 00:36:59.359
Kubi & Michael: under optimistic V 3, the size of the block, at least from a latency perspective in terms of submitting bits to the relay, should have 0 influence. And once that is live. I think, basically blob inclusion lists also become viable.

125
00:36:59.600 --> 00:37:01.890
thomasthiery: Nice. Okay, that's pretty cool

126
00:37:02.854 --> 00:37:10.080
thomasthiery: and make sense for for the side of the size of it. Also, yeah, I understand the gradual process into

127
00:37:10.558 --> 00:37:15.180
thomasthiery: making sure you have some adoption before you increase like the the bandwidth. For sure.

128
00:37:16.810 --> 00:37:17.920
thomasthiery: Nice.

129
00:37:18.675 --> 00:37:22.689
thomasthiery: Does anyone have any other questions? Otherwise I'll just keep going.

130
00:37:28.293 --> 00:37:34.589
thomasthiery: Okay, I'll keep going. Yeah. Just wanted to know for the inclusion rule. I think

131
00:37:34.910 --> 00:37:49.924
thomasthiery: I don't. I didn't get why the multi multiplicative regime didn't have the transaction size as a an input and the additive did, because the transaction size is not only like

132
00:37:50.710 --> 00:37:53.895
thomasthiery: I don't know an optimization. It's also to avoid

133
00:37:54.490 --> 00:38:09.170
thomasthiery: that also allows to avoid the Il flooding like, you know, you can, if you submit like a very, very large transaction that gets picked, picked up, and that takes like the entire inclusion list. And then

134
00:38:09.696 --> 00:38:19.400
thomasthiery: you are able to invalidate it that sort of like crowds out other transaction. And that's an attack we want to avoid. So like sort of like

135
00:38:19.510 --> 00:38:28.410
thomasthiery: filtering by descending order of by transaction. Size is anyways a a quite good idea, I think.

136
00:38:31.110 --> 00:38:55.819
Kubi & Michael: Yeah, thanks for the comment. There, I think this is very valid. So basically, there's 2 things we considered. One is where in option 2. We are adjusting by transaction size to kind of preclude this vector that you mentioned right where a single transaction can come in and clock up the space

137
00:38:55.900 --> 00:39:11.260
Kubi & Michael: on the inclusion list, and then the angle from which we approached the other adjustment in option, one which is over the gas is, we were saying, well, what do we expect to be the bottleneck in practice? Would it be the networking constraint.

138
00:39:11.300 --> 00:39:21.329
Kubi & Michael: or would it be the the block space, constraints, or kind? Of which of these is more is more limited, and then we should, we should maximize over the over, the constraint.

139
00:39:21.350 --> 00:39:35.670
Kubi & Michael: the option with adjusting per gas to some extent also favor smaller transactions if we say that they have less gas. But of course, in a less direct way.

140
00:39:35.680 --> 00:40:04.179
Kubi & Michael: I think in summary, we don't really have a final intuition, yet on which of these approaches would be best, but it seems like there could be a hybrid approach where we adjust by both to some extent, or we have a threshold to ensure that this attack, where somebody can clog up the block, space does not happen, but at the same time we maximize the utility of the remaining block space.

141
00:40:05.570 --> 00:40:18.070
thomasthiery: Nice. Yeah, that makes total sense. and there is also. And there's comments on on it. Research, apparently, that compares these options. So I will look into this a bit more.

142
00:40:18.240 --> 00:40:23.281
thomasthiery: Thanks. And then more general, I think high level questions.

143
00:40:25.280 --> 00:40:34.339
thomasthiery: what will happen to relay inclusion lists if or let's be optimistic when fossil makes it in the protocol.

144
00:40:36.580 --> 00:40:41.910
Kubi & Michael: Yeah, I think, the from our perspective. Then it would just be deprecated.

145
00:40:42.070 --> 00:41:09.579
Kubi & Michael: And what Michael mentioned earlier, I guess the upside of having some of the actors across the supply chain already supporting inclusion lists is obviously builders, will have adopted them, but also the relays in terms of having to validate blocks based on inclusion list and things like that. But like actually gossiping or like needing to maintain and generating the inclusion list. But then, from our perspective currently be deprecated.

146
00:41:10.170 --> 00:41:21.339
thomasthiery: Okay, yeah, that makes sense. No, no, the rollout makes total sense. I I was just sort of wondering, okay, what happens? Because then it. It will feel a bit like a double like. I don't know. Repetitive sort of thing.

147
00:41:21.340 --> 00:41:26.790
Kubi & Michael: Absolutely, I think, like in protocol is obviously much stronger. And so like, yeah, there wouldn't be any need anymore.

148
00:41:27.140 --> 00:41:33.530
thomasthiery: Okay. Nice thanks. A lot any other questions from

149
00:41:33.910 --> 00:41:36.770
thomasthiery: from other people. How should we move on.

150
00:41:43.680 --> 00:41:53.869
Jihoon: I have a question, how do we make sure? Relays, build relay inclusion list according to the inclusion rule correctly. What I want to ask is.

151
00:41:54.270 --> 00:42:00.649
Jihoon: is there any gadget that prevents relay? Inclusion? Release doesn't become a vehicle for breakout?

152
00:42:04.240 --> 00:42:29.509
Kubi & Michael: Yeah. So to summarize the question, if I understood it correctly, was how we ensure that relays. Apply the inclusion rule correctly. I think one way we've approached. This is by saying, the relay is a trusted party, and the validator enforces this trust against the relay. So if a relay were to misbehave ideally, the validator should opt out.

153
00:42:29.530 --> 00:42:40.049
Kubi & Michael: And then, secondly, once the the Relay inclusion list can be shared between multiple relays. So multi-relay inclusion list. The the last point on the

154
00:42:40.160 --> 00:42:53.949
Kubi & Michael: last slide. This, this vector would be offset to a large extent, because then relays. Build one inclusion list collectively, again reducing the discretion each individual relay has over the inclusion list.

155
00:42:54.050 --> 00:43:05.259
Kubi & Michael: Yeah. And the other factor is that, given that the inclusion list will be made available publicly, which is how the builders will, or which is how they will be communicated to builders

156
00:43:05.260 --> 00:43:27.430
Kubi & Michael: if there's any massive outlier, ie. Some weird transactions that were never seen on the mempoles that ending up on the inclusion list, and things like that. I think builders will pretty quickly spot it and call relays out. And then again, it will be a huge reputational damage, which I think is one of the key things that relays optimize for.

157
00:43:31.200 --> 00:43:32.359
Jihoon: Got it. Thank you.

158
00:43:36.640 --> 00:43:54.259
thomasthiery: Right. Thanks. I guess another sort of like out of the box idea is like to use a T but might be a bit of overhead, and I agree, but like the trust assumption being sort of the same like, if you trust the relay, you could also trust it.

159
00:43:54.910 --> 00:44:11.359
thomasthiery: For building inclusion list, according to the rules they have specified. But great. Okay, thanks. Yeah. Again. Great presentation. Thanks. A lot for coming in should we move to implementation updates?

160
00:44:13.750 --> 00:44:29.164
thomasthiery: I don't have any super specific thing on the agenda, but I'm I'm I am curious to hear if there are like sort of progress across the board. Whether it's testing or implementation on, on clients or interrupt. What's

161
00:44:30.280 --> 00:44:32.280
thomasthiery: What's the status of all this.

162
00:44:34.779 --> 00:44:42.829
jacob k: Yeah, I would just. I can say a couple of things. First, st I think we should try to get this pr

163
00:44:43.410 --> 00:44:49.660
jacob k: authored by Mark merged in as soon as possible. I think there's been a lot of

164
00:44:50.950 --> 00:44:53.060
jacob k: comments on that. And

165
00:44:53.370 --> 00:44:58.820
jacob k: I think it's okay. If we just wanna like limit scope and open a subsequent pr, as long as we

166
00:44:59.200 --> 00:45:01.990
jacob k: address kind of like the core aspects of

167
00:45:02.540 --> 00:45:05.199
jacob k: what's happening on the execution layer.

168
00:45:06.493 --> 00:45:18.340
jacob k: And then, yeah, I have a draft Pr up on the execution specs we'll need to do a rebase on top of the latest Osaka

169
00:45:19.010 --> 00:45:22.859
jacob k: fork over there which didn't exist at the time that I opened it.

170
00:45:23.656 --> 00:45:34.639
jacob k: And then I'll have to. Yeah, depending on what what gets merged into the IP, maybe make some changes. I've also been working on the execution spec test

171
00:45:34.900 --> 00:45:38.599
jacob k: should have a Pr up in the next few days.

172
00:45:39.140 --> 00:45:44.029
jacob k: again. This is another thing where it'd be nice to have this pr for the IP merged.

173
00:45:46.540 --> 00:45:52.530
jacob k: Just so we're all operating from the same.

174
00:45:53.810 --> 00:46:00.395
jacob k: Yeah, from the same eip, essentially. And then, yeah, once that's

175
00:46:02.060 --> 00:46:12.360
jacob k: ready, we'll be able to have some test fixtures in the engine, new payload formats. And then, yeah, I will validate those with either ref or or geth

176
00:46:13.608 --> 00:46:20.650
jacob k: the refer. Get fossil fork before before the Pr. And then other clients can

177
00:46:21.718 --> 00:46:24.311
jacob k: consume them and validate them.

178
00:46:25.240 --> 00:46:33.463
jacob k: but yeah, I think the main thing is just try to get the the pr merged

179
00:46:34.890 --> 00:46:37.976
jacob k: in the next day or 2 would be great.

180
00:46:38.720 --> 00:46:42.956
Marc: I can. Take a look through these review comments today.

181
00:46:44.340 --> 00:46:45.020
jacob k: Great.

182
00:46:45.700 --> 00:46:49.199
jacob k: Appreciate that. Yeah, that's that's all I have.

183
00:46:50.310 --> 00:47:03.579
thomasthiery: Nice. No, that's awesome. Yeah. Yeah. I remember there was quite a bit on the Pr. But I haven't looked for a while, so I'm happy also to take another look today. See if I see anything. And

184
00:47:03.590 --> 00:47:23.339
thomasthiery: yeah, we, we should get it much because I I did see yeah, new people coming in or so, and being a bit confused about the execution parts of the eap, so would be nice to have it merged, I agree. And then what? I just didn't really follow. What was the

185
00:47:23.870 --> 00:47:29.700
thomasthiery: so like? 1st pr, not the spec test one, but the the 1st Pr was about

186
00:47:30.590 --> 00:47:33.380
thomasthiery: that you need need to rebase on on full cycle.

187
00:47:34.624 --> 00:47:39.540
jacob k: The execution specs. Yeah, I can share a link to the

188
00:47:40.160 --> 00:47:45.590
jacob k: that. Pr, but essentially, it's just, you know, taking what's in the eip and.

189
00:47:48.590 --> 00:47:50.080
thomasthiery: Thanks. Perfectly. Okay. Great.

190
00:47:50.080 --> 00:47:57.670
jacob k: Making it so that we can create test against it. And yeah, just a more formal version of the

191
00:47:58.970 --> 00:48:05.400
jacob k: of the IP, or at least execution layer aspects of it. However, yeah.

192
00:48:05.840 --> 00:48:15.719
jacob k: the diff shown is quite large, because I had to add a bunch of Osaka boilerplates. But now that there is a upstream branch with that should be able

193
00:48:16.020 --> 00:48:19.689
jacob k: remove a bunch of that.

194
00:48:20.140 --> 00:48:20.890
thomasthiery: Nice.

195
00:48:21.460 --> 00:48:24.309
thomasthiery: Yeah, that's awesome. Okay, great thanks. A lot.

196
00:48:25.290 --> 00:48:28.989
thomasthiery: And you have been talking to the steel team right.

197
00:48:30.917 --> 00:48:31.992
jacob k: Some. Yeah.

198
00:48:32.810 --> 00:48:38.850
jacob k: yeah. I mean, fortunately, the they have some pretty good docs, and I was able to figure out most of

199
00:48:39.210 --> 00:48:42.379
jacob k: most of these things myself. But yeah.

200
00:48:43.140 --> 00:48:45.919
jacob k: they've been helpful and responsive. So it's great.

201
00:48:46.440 --> 00:48:50.700
thomasthiery: Okay. Great. Okay. Very good news. Thanks for sharing.

202
00:48:52.095 --> 00:48:55.400
thomasthiery: Okay, any other updates.

203
00:48:56.990 --> 00:49:04.170
Jihoon: Yes, so on the conscious aspect. I'm working on conscious specs and conscious of spec tests.

204
00:49:04.560 --> 00:49:13.609
Jihoon: I've added basic unit tests. And there were some missing pieces in the spec. So that's what I'm currently working on. At the moment.

205
00:49:13.860 --> 00:49:19.170
Jihoon: After completing the spec, I can resume adding bunch of a test.

206
00:49:19.330 --> 00:49:27.360
Jihoon: and the fixtures will also provide enclosure list as a file, so that cl clients can consume it.

207
00:49:28.490 --> 00:49:37.659
Jihoon: Timeline, wise. Justin and I aim to ship it in the next Constances release, if it's possible, which is in 2 weeks.

208
00:49:40.530 --> 00:49:52.950
thomasthiery: Okay, sounds good. Great. Okay? So it's it's awesome. Cause you guys are like, sort of like working in parallel on both the consensus execution side of things for tests which is really cool.

209
00:49:54.650 --> 00:49:56.170
thomasthiery: Yeah, let me know if

210
00:49:56.450 --> 00:50:00.219
thomasthiery: I'll let everyone know. I guess if you need input

211
00:50:00.370 --> 00:50:17.575
thomasthiery: on ideas or things to test. At any point. I feel like there are quite a bit of scenarios we can actually sort of play around with on both sides. But maybe. Yeah, I know we are not necessarily there yet, but

212
00:50:18.100 --> 00:50:19.940
thomasthiery: would be nice to also chat about.

213
00:50:24.310 --> 00:50:29.370
thomasthiery: And then does anyone else have something to share?

214
00:50:46.530 --> 00:50:49.110
thomasthiery: Okay? If not, yeah.

215
00:50:49.505 --> 00:50:55.389
Jihoon: Yeah. So I just remember that there was a feedback, that there was a

216
00:50:55.520 --> 00:51:05.592
Jihoon: discrepancy between the overview picture of the eip and the text below, and it'd be nice if you could align them. So maybe

217
00:51:06.280 --> 00:51:09.410
Jihoon: yeah, Joe Chan, do you wanna talk about it more.

218
00:51:11.920 --> 00:51:16.079
jochem-brouwer (EthJS): Yeah, it was just something I noticed when when we did the the Erp.

219
00:51:16.630 --> 00:51:24.280
jochem-brouwer (EthJS): So I think if you if the text and the picture matches, then it is also much easier to understand, because now it it looks

220
00:51:24.490 --> 00:51:28.510
jochem-brouwer (EthJS): yeah, a bit contradicting. When you read read the Erp.

221
00:51:30.210 --> 00:51:44.509
thomasthiery: Okay, yeah. I remember seeing that in the discussion, for sure I can. I can take a look very soon. Let me just make a note of it. But yeah, no, that's a that's a good good point we'll definitely look into this. Thanks.

222
00:51:49.450 --> 00:51:54.580
thomasthiery: then, mercy! You want to talk about what you shared.

223
00:51:56.290 --> 00:52:05.909
Mercy Boma Naps-Nkari: Yeah, I can on the front end of the transaction for visualizer. It's still empty double I was hoping to

224
00:52:06.410 --> 00:52:12.009
Mercy Boma Naps-Nkari: try and populate it and see what the the transactions and and how it's going to actually look like.

225
00:52:12.240 --> 00:52:14.940
Mercy Boma Naps-Nkari: But this is where I'm out at the front end. Currently.

226
00:52:15.690 --> 00:52:18.140
Mercy Boma Naps-Nkari: body backend is mostly ready. Yeah.

227
00:52:19.030 --> 00:52:19.760
thomasthiery: Nice.

228
00:52:20.190 --> 00:52:26.239
thomasthiery: Okay, super cool. Thanks nice. And then

229
00:52:26.700 --> 00:52:30.560
thomasthiery: let me check. I remember I wanted to ask

230
00:52:31.222 --> 00:52:42.510
thomasthiery: a client team that was very, very close to. Oh, yeah, I think there was lighthouse. I I remember lighthouse being very close to interrupt, and then sort of like not hearing from you guys.

231
00:52:46.260 --> 00:52:49.389
thomasthiery: Do we have someone from night house here? No.

232
00:52:52.000 --> 00:53:00.909
thomasthiery: Okay. Yeah. We'll. We'll just follow up with them later, I guess. But great, okay.

233
00:53:01.180 --> 00:53:02.930
thomasthiery: is there anything else?

234
00:53:11.030 --> 00:53:14.656
thomasthiery: Okay? Cool. Then I think we can.

235
00:53:16.090 --> 00:53:23.790
thomasthiery: and this thanks a lot for joining and participating and see you in 2 weeks.

236
00:53:26.810 --> 00:53:27.430
jacob k: You.

237
00:53:27.890 --> 00:53:28.523
Kubi & Michael: Bye, bye.

238
00:53:28.840 --> 00:53:29.500
Marc: All right.

239
00:53:29.500 --> 00:53:30.160
Kubi & Michael: This.

240
00:53:35.870 --> 00:53:36.689
Pooja Ranjan: Thank you.

