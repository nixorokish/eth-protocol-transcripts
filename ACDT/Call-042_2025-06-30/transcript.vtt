WEBVTT

1
00:02:59.600 --> 00:03:00.360
Parithosh Jayanthi: Hello!

2
00:03:03.090 --> 00:03:05.099
Justin Traglia: Good morning. How's it going.

3
00:03:06.600 --> 00:03:08.660
Parithosh Jayanthi: Good. Good. How are you guys.

4
00:03:45.250 --> 00:03:46.720
spencer-tb: If I'm doing.

5
00:03:53.530 --> 00:03:58.090
Parithosh Jayanthi: Welcome everyone. Let's give people a minute, few minutes, and then we can start.

6
00:04:06.566 --> 00:04:10.719
Akash | ECH: Hey? Paritosh! I'm helping with the stream today. So let me know.

7
00:04:11.140 --> 00:04:12.169
Akash | ECH: Didn't say.

8
00:04:12.530 --> 00:04:16.570
Parithosh Jayanthi: Yeah, maybe in about a minute we can start. I'll let you. Thanks.

9
00:04:16.579 --> 00:04:17.129
Akash | ECH: But.

10
00:06:19.460 --> 00:06:23.289
Parithosh Jayanthi: Okay. Can you start the stream? Akash, and we can get started.

11
00:06:24.490 --> 00:06:25.559
Akash | ECH: Yeah, we are 9.

12
00:06:26.760 --> 00:06:29.140
Parithosh Jayanthi: Awesome. Thank you so much.

13
00:06:31.974 --> 00:06:40.040
Parithosh Jayanthi: Yeah. So the 1st point in the agenda, can we get an update on society? That net 2,

14
00:06:40.160 --> 00:06:48.339
Parithosh Jayanthi: and what bugs have been found, or what's the current status? Maybe barnabas gives us an overview first.st

15
00:06:49.070 --> 00:06:56.800
Barnabas: Yeah, sure. So the current overview is during the weekend we had a non finality due to a Taku and Netherland bug.

16
00:06:57.000 --> 00:07:03.970
Barnabas: both tech and the mind bug have been since fixed, and the network is now finalizing again.

17
00:07:04.630 --> 00:07:16.149
Barnabas: This morning we have had to look lots of databases there was lots of database corruptions on windowcl on. Never mind on.

18
00:07:16.410 --> 00:07:24.149
Barnabas: And currently the main, the main client that is having issues is draft.

19
00:07:24.480 --> 00:07:31.660
Barnabas: So tech rest, one tech rest, 2 nimbus rest, one nimbus ref. 2. They are failing to find peers.

20
00:07:31.920 --> 00:07:36.079
Barnabas: So there might be some peering regarded problems.

21
00:07:36.510 --> 00:07:40.290
Barnabas: and granting that the one had a corrupted database as well.

22
00:07:40.410 --> 00:07:44.099
Barnabas: and that just got restarted so it should come online soon.

23
00:07:44.670 --> 00:07:54.269
Parithosh Jayanthi: Could you? Maybe tell us why we had non finality first? st And why was that such a problem for the Els more than the Cls.

24
00:07:55.170 --> 00:08:02.868
Barnabas: So the inefficiency was caused by Netherland. And being offline, they just had over

25
00:08:03.970 --> 00:08:09.325
Barnabas: like 40% of the network. So maybe never mind, can explain what the bug was

26
00:08:10.110 --> 00:08:11.910
Barnabas: and then maybe Taco can also.

27
00:08:17.445 --> 00:08:20.925
FLCL: The bug was just about 4 K. Ids,

28
00:08:21.770 --> 00:08:26.371
FLCL: we are improperly calculated, and we we are not connected on

29
00:08:26.930 --> 00:08:41.390
FLCL: execution layer to any other peers. And yeah, probably can. The could form a a separate cluster of bears

30
00:08:41.600 --> 00:08:45.639
FLCL: with a separate fork, because of that, not sure.

31
00:08:49.700 --> 00:08:52.399
Enrico Del Fante (tbenr): On the Telco side

32
00:08:53.185 --> 00:09:03.704
Enrico Del Fante (tbenr): we we publish published the I guess a cleanup commit on the on the Fussaka dev 2 branch. And

33
00:09:04.850 --> 00:09:16.710
Enrico Del Fante (tbenr): yeah, I think it was was a a clean up P. Commit mostly, but I guess there has been some regression in that. And we

34
00:09:16.920 --> 00:09:34.730
Enrico Del Fante (tbenr): when we pushed the the commit there? We were not thinking about that. Everything now is automated, and the commit was about to be published. Anyway, on Fusaka. It's good that we have the actual immediate test, that something was wrong there.

35
00:09:34.910 --> 00:09:46.250
Enrico Del Fante (tbenr): But I don't have any more detail on that. We will take a look closer. Look to what has been changed there to find out what's was the problem. Yeah.

36
00:09:46.650 --> 00:09:47.530
Enrico Del Fante (tbenr): that's it.

37
00:09:51.490 --> 00:10:03.449
Parithosh Jayanthi: Okay, maybe one follow up for the fork. Id bug, it says, some reason we didn't really catch that in local testing, because that also sounds like it should be quite easy to reproduce.

38
00:10:06.670 --> 00:10:22.740
FLCL: So it worked before, because Genesis, most likely Genesis timestamp, was the same is a timestamps for

39
00:10:23.150 --> 00:10:27.449
FLCL: the initial forks. Maybe it was zeros or so.

40
00:10:27.820 --> 00:10:34.154
FLCL: Not sure it. It's an old part of the code. And

41
00:10:36.690 --> 00:10:44.779
FLCL: That was not changed a lot, and probably new configuration in the devnet.

42
00:10:45.270 --> 00:10:48.160
FLCL: Rebuilt it. Yeah.

43
00:10:51.860 --> 00:10:55.920
Parithosh Jayanthi: Okay, I'm glad we caught that. Then.

44
00:10:56.990 --> 00:11:06.389
Parithosh Jayanthi: and one of this did you already look into? Why, that led to hearing issues or database corruption issues or do? Does someone from that? Or

45
00:11:06.740 --> 00:11:08.940
Parithosh Jayanthi: Bezu have some update on that.

46
00:11:15.920 --> 00:11:16.550
Gabriel Trintinalia | Besu: Room, business.

47
00:11:16.970 --> 00:11:19.190
Barnabas: Yep, go for it, guys.

48
00:11:19.390 --> 00:11:30.080
Gabriel Trintinalia | Besu: Sorry from Bezel. I think there was not related to any of the blocker changes. I may be an existing Sync issue

49
00:11:30.500 --> 00:11:38.060
Gabriel Trintinalia | Besu: in bezel. With the Deb being restarted, the node is synced well and and progressing well. Now.

50
00:11:44.610 --> 00:11:48.010
Parithosh Jayanthi: Okay, so on, Bezo. It was slightly unrelated in it.

51
00:11:48.510 --> 00:11:52.320
Parithosh Jayanthi: There might still be some bug out there, cause.

52
00:11:52.320 --> 00:11:57.879
Gabriel Trintinalia | Besu: Likely I will look into it, but I don't think it's even related to the the flocker changes.

53
00:11:58.400 --> 00:12:00.520
Parithosh Jayanthi: Okay, cool. Good to know. Thank you.

54
00:12:02.880 --> 00:12:07.300
Parithosh Jayanthi: Maybe Roman from reps. Have you guys looked into the peering issue yet?

55
00:12:10.490 --> 00:12:18.389
Roman: we're trying to look into it. But the the problem is that is that we have trouble reproducing it locally.

56
00:12:19.390 --> 00:12:29.230
Roman: So the the best approach for us right now is inspecting the logs and trying to understand what happened on the tackle boxes

57
00:12:30.300 --> 00:12:32.279
Roman: under breathtack boxes.

58
00:12:32.280 --> 00:12:42.210
Barnabas: It's also on Nimbus. Is there something I can do like debug mode? Or maybe you can run locally binary on the

59
00:12:42.400 --> 00:12:47.089
Barnabas: notes, so you can actually reproduce it locally on the definition.

60
00:12:47.260 --> 00:12:52.510
Roman: Yeah. Thanks for the offer. Let's continue the discussion telegram chat.

61
00:12:52.650 --> 00:12:58.720
Roman: I'm I'm talking to Matt right now as well. So we'll look into it.

62
00:13:02.870 --> 00:13:11.699
Parithosh Jayanthi: Okay. Were there any other unexplained bugs on fossified net? 2. What's still left to be done on it?

63
00:13:16.270 --> 00:13:19.672
Barnabas: So the really 1st bug was the prism bug

64
00:13:20.450 --> 00:13:33.856
Barnabas: that should have been caught by a spec test. I actually forgot to mention that. And this caused prism to basically fork away right away. And we were able to reproduce that

65
00:13:34.370 --> 00:13:36.390
Barnabas: fairly easily with their genesis sync.

66
00:13:36.800 --> 00:13:40.129
Barnabas: There's no new spectas for it, and that has been merged.

67
00:13:46.030 --> 00:13:58.570
Parithosh Jayanthi: Awesome. Yeah, I think that also is a whole class of tests. Right? I don't know, Justin. Do you want to maybe talk about it. Do we want to back port? The validator changes to every fork.

68
00:14:00.407 --> 00:14:03.580
Justin Traglia: We could. I'll need to look into that more.

69
00:14:06.260 --> 00:14:11.720
Parithosh Jayanthi: Okay, because it seems like at least a test that's worth having irrespective, which folk we're on.

70
00:14:12.660 --> 00:14:13.810
Justin Traglia: Yeah, I agree.

71
00:14:18.560 --> 00:14:23.489
Justin Traglia: I don't have much other like information on this. But maybe Potus or someone else would.

72
00:14:28.250 --> 00:14:44.769
Parithosh Jayanthi: I don't know who from prisms here today. But yeah, we can probably get some information from them later. Irrespective. If you're a Cl. Team. Then please have a look at the test, and it should be, I guess, part of the next release. So you will. You will be using the test

73
00:14:44.910 --> 00:14:46.020
Parithosh Jayanthi: soon, anyway.

74
00:14:47.880 --> 00:14:48.799
Justin Traglia: And I can.

75
00:14:49.130 --> 00:14:56.160
Justin Traglia: I can quickly say that all other clients do pass the test, which was verified by like the nightly spec tests.

76
00:14:56.610 --> 00:14:57.909
Parithosh Jayanthi: Awesome. That's perfect.

77
00:15:00.103 --> 00:15:02.999
Parithosh Jayanthi: Anything else on Fusaka Devnet to Barnabas.

78
00:15:06.137 --> 00:15:09.180
Barnabas: Maybe I can bring up the

79
00:15:10.770 --> 00:15:17.840
Barnabas: spamming issue that we had. So currently, we have no spamming going on. So maybe that's why we were

80
00:15:18.110 --> 00:15:25.832
Barnabas: able to recover the non penalty because there was not enough load on the network. We didn't have any transactions. We didn't have any block transactions.

81
00:15:26.910 --> 00:15:34.767
Barnabas: we currently have a spammer bug that they're taking a look at right now. So hopefully, we can actually produce

82
00:15:35.800 --> 00:15:39.490
Barnabas: every element finality. And hopefully, we can also recover from that.

83
00:15:43.080 --> 00:15:48.460
Parithosh Jayanthi: Okay, is that also what you wanted to talk about Jacob, or is, did you want to bring up a different topic.

84
00:15:49.290 --> 00:15:53.689
jochem-brouwer: Yeah, it was something related to that. Maybe I can just bring that up or.

85
00:15:54.380 --> 00:15:55.390
Parithosh Jayanthi: Yeah. Go ahead.

86
00:15:55.610 --> 00:16:00.870
jochem-brouwer: Yeah, okay, so what I really want to do is also some performance tests on this def net.

87
00:16:01.140 --> 00:16:06.829
jochem-brouwer: because we have reintroduced or not reintroduced. We have introduced this 7,907 erp, which?

88
00:16:07.523 --> 00:16:10.510
jochem-brouwer: No, it's 10 times the maximum contract size.

89
00:16:10.840 --> 00:16:16.870
jochem-brouwer: And what I really want to test. There is actually calling as many contacts there as possible.

90
00:16:17.000 --> 00:16:41.089
jochem-brouwer: Because, yeah, I will not go into the details. But I think it's still possible to call about 11,000 contracts with this size within a 30 million guest transaction. And I have been setting up these tests. But for that we actually need 11,000, let's say 12,000 of these large contracts. And this is actually being done by the spammer. But yeah, as you mentioned, that likely is a built in the spam because it is not doing

91
00:16:41.220 --> 00:16:54.159
jochem-brouwer: deploying anything at all at this moment, and we are currently at 3,500 contracts. So we are not close to the actual state which we need for this. Well, this performance test

92
00:16:54.250 --> 00:17:12.980
jochem-brouwer: I just wanted to bring up that we need these performance tests because I really want to see that if we do these kind of well, let's say, attack vectors, that we do not certainly run into like blocks, which take like 3 or 4 seconds on clients to to run. And I'm working on these attack factors. And yeah, just wanted to bring that up.

93
00:17:15.040 --> 00:17:27.879
Parithosh Jayanthi: Thank you. Do you have an intuition for how long it might take to deploy also contracts and get through the test? Would would you have an some topic talking point by acde on Thursday.

94
00:17:28.459 --> 00:17:34.569
jochem-brouwer: I have started this spammer at the point where we forked. And I think that was Saturday.

95
00:17:34.739 --> 00:17:39.639
jochem-brouwer: Currently, this problem is not deploying anything, but I think we can say that

96
00:17:39.839 --> 00:17:43.819
jochem-brouwer: well, we need. We need one block per

97
00:17:44.309 --> 00:18:09.039
jochem-brouwer: per contract, and you, of course, have. Well, it actually take 2 blocks because of the pricing that we. If you deploy the 30 million gas contract in a 45 million gas block, then the gas price will rise. So let's say we need what is it? 6,000 but 8,000 blocks? Yeah, for for this to deploy? I think it is possible to deploy this by Acd.

98
00:18:09.259 --> 00:18:14.909
jochem-brouwer: E. But I'm not really sure, because then this has to be fixed. This the spammer broke has to be fixed. Yeah.

99
00:18:16.130 --> 00:18:23.090
Parithosh Jayanthi: Awesome and I see in chat that Pk already mentioned, that he's working on fixing spammer, so

100
00:18:23.420 --> 00:18:25.430
Parithosh Jayanthi: I guess you 2 will be in touch.

101
00:18:25.690 --> 00:18:28.049
jochem-brouwer: Yes. Okay. Great. Thank you. Thank you. Pk, yeah.

102
00:18:30.750 --> 00:18:40.780
Parithosh Jayanthi: Great I also see Bharat on the call. Do you maybe want to give us an update on how? The Mev testing and mev workflow is going.

103
00:18:40.910 --> 00:18:41.764
Bharath: Yeah, for sure.

104
00:18:42.150 --> 00:18:50.367
Bharath: So yeah, I've updated like, my boost and my boost relay the flashbots, one to support Hulu.

105
00:18:51.490 --> 00:19:00.980
Bharath: And the thing. And I've done a bunch of local testing there. And everything generally seems to be fine. There seem there are issues with the

106
00:19:01.180 --> 00:19:05.149
Bharath: issues which I found with with respect to the relay, there are some issues

107
00:19:06.110 --> 00:19:33.679
Bharath: like when we. I'm not locally, at least, we're not noticing, like blob transactions getting into the relay payload. I believe that's a issue with the Red R Builder. We've seen a bunch of error logs. I've reached out to the our builder folks on a Tg. Chat about that. With respect to mevboost so generally in with the Mev relay, pipeline, as I told, transactions without blobs

108
00:19:34.113 --> 00:19:51.039
Bharath: are getting in through the mev relay for the fullu fork. So mevboost and mev boost relay generally seem positive as per my local testing, but I think, like Barnabas like. Probably we will get it on like Devnet, too, and generally see how it works there. So yeah, that's that's the thing.

109
00:19:51.040 --> 00:19:52.510
Bharath: So the timeline.

110
00:19:53.070 --> 00:20:02.649
Bharath: Sorry. Sorry the the timeline. There would then be making sure that the relays, including globes so figuring out that bug, and once that's done, we would be deploying the relay on Devnet 2.

111
00:20:03.170 --> 00:20:18.889
Bharath: Yeah, yeah, for sure. Like, I believe the blobs thing might be an issue with our builder. So we've just reached out to them. And I think the our builder is not building blocks with blobs, for whatever reason I'll talk to them, and we'll see where the issue is. And yeah, once that's fixed

112
00:20:19.010 --> 00:20:23.190
Bharath: and blobs are going through Webboost relay. I think we should be good. There.

113
00:20:24.310 --> 00:20:28.554
Parithosh Jayanthi: Okay, thank you for the update. That's also looking good.

114
00:20:29.452 --> 00:20:47.949
Parithosh Jayanthi: Yeah. Just to touch upon a previous point. Casey, from the prism team mentioned that we. They had stale validator indices in their proposal. Look ahead, code and previous spec tests as well as curses did not change the active valid data set. So that is the spec test that has been added.

115
00:20:48.780 --> 00:20:51.110
Parithosh Jayanthi: Thanks for that. Update.

116
00:20:52.190 --> 00:20:55.140
Parithosh Jayanthi: Anything else related to Fusappa Devnet 2.

117
00:20:57.620 --> 00:21:14.760
Parithosh Jayanthi: I'm currently fighting with the sync test repository. I tried some local sync tests. It seems like lighthouse is taking a long time to sync. I still have to validate that. The Ci version of the sync test is currently broken, and I'll try getting it working in the next day.

118
00:21:14.960 --> 00:21:18.219
Parithosh Jayanthi: But if that's done we should have sync tests on Footsapp and Evnet, too.

119
00:21:19.720 --> 00:21:20.090
Parithosh Jayanthi: This.

120
00:21:20.090 --> 00:21:22.349
Parithosh Jayanthi: And yeah, sorry. Go ahead.

121
00:21:22.550 --> 00:21:28.729
pawan: Sorry are these sync tests with assertor? Or is it like something new? Some new tools.

122
00:21:29.270 --> 00:21:41.629
Parithosh Jayanthi: It's kurtosis in a certain. So it's just a script that starts kurtosis and then uses a certain to make sure that the nodes are synced, and then we throw it in our Github ci, so we can just run it as often as we want.

123
00:21:42.880 --> 00:21:51.310
Parithosh Jayanthi: and there's a ui to track sync time over time. So we can see how it gets worse as the State gets bigger and so on.

124
00:21:54.596 --> 00:22:02.010
Parithosh Jayanthi: Barnabas is asking about backfill. Is there any update that Cl teams want to share about that?

125
00:22:04.582 --> 00:22:19.100
pawan: We have been working on adding backfill after updating the Cgc, we haven't merged it yet, but I think we should be able to get it working soon. We have started testing it. I think.

126
00:22:24.040 --> 00:22:29.869
kasey: Prism has a branch. We're working on it. I haven't touched it since the Cdc. Changes, but that shouldn't be too far off.

127
00:22:40.340 --> 00:22:45.590
Parithosh Jayanthi: So anything else on fusa.net 2

128
00:22:52.140 --> 00:22:58.399
Parithosh Jayanthi: great do we then want to start talking about Fusaka Devnet 3. And what's the plan there.

129
00:22:59.935 --> 00:23:03.514
Parithosh Jayanthi: Do you? Wanna do you have thoughts on that, Barnabas? What's

130
00:23:04.290 --> 00:23:12.940
Barnabas: It's well, the prerequisite for that is basically deciding the 7, 9 or 7 changes.

131
00:23:13.870 --> 00:23:20.030
Barnabas: Do we have the values for that already set in stone, all the repricing vips.

132
00:23:23.892 --> 00:23:32.197
Parithosh Jayanthi: For the repricing eip, we do have values. I think we're just confirming that the values are good for scaling beyond 60 million as well.

133
00:23:33.543 --> 00:23:45.759
Parithosh Jayanthi: But for 7, 9 0 7, I would assume. That depends on Jocum's test as well as I see Marius is on the chat. He had some thoughts on indexes. Do you maybe want to bring it up? Marius?

134
00:23:51.910 --> 00:24:01.779
Marius: Sorry I took modify my zoom stuff. Yeah. So the problem with indices is

135
00:24:02.140 --> 00:24:04.940
Marius: like, without the without the index.

136
00:24:05.460 --> 00:24:11.127
Marius: I don't think the result is is workable because we

137
00:24:12.750 --> 00:24:22.289
Marius: we kind of need to look up too much data in order to answer the question whether we have enough gas to look up this much data.

138
00:24:22.880 --> 00:24:31.370
Marius: And you can construct these weird fringe cases where you have like sub calls that look up

139
00:24:32.004 --> 00:24:39.560
Marius: data and then run out of gas, and then you have the outer call. Call into the sub call again, and and so on.

140
00:24:40.710 --> 00:24:48.400
Marius: So the I think the index is needed by all clients.

141
00:24:48.590 --> 00:24:53.760
Marius: The question is whether the index should be in protocol or out of protocol.

142
00:24:54.260 --> 00:25:03.170
Marius: and the problem with having it out of protocol. Is that in a stateless world?

143
00:25:04.089 --> 00:25:10.709
Marius: This would mean that the witnesses could be bloated with this data.

144
00:25:11.215 --> 00:25:19.450
Marius: Because you can just do export size on a on a bunch of contracts, and and then the witness had to contain all of these contracts.

145
00:25:21.750 --> 00:25:27.699
Marius: I guess right now. We don't have stateless, and we don't have witnesses.

146
00:25:27.830 --> 00:25:28.929
Marius: So

147
00:25:33.560 --> 00:25:47.199
Marius: I don't know if we need to over index on on this this future of of of witnesses of like. But I think that is something that we need to be very mindful of when we move to stateless

148
00:25:47.310 --> 00:25:54.150
Marius: is that we need to make this index be in protocol at some point.

149
00:25:54.830 --> 00:25:57.129
Marius: So the question is, should we do it now.

150
00:25:57.940 --> 00:26:01.130
Marius: or should we do it later on?

151
00:26:04.830 --> 00:26:06.560
Parithosh Jayanthi: Yeah, Ben, do you wanna go.

152
00:26:07.321 --> 00:26:14.139
Ben Adams: Yeah, and related to that is, should we charge extra for it? Because it's essentially would be

153
00:26:15.365 --> 00:26:19.580
Ben Adams: adding the equivalent S load to

154
00:26:20.507 --> 00:26:24.480
Ben Adams: essentially, you're not doing another database lookup to get right.

155
00:26:32.250 --> 00:26:34.729
Parithosh Jayanthi: I, wanna okay, Anskar, do you wanna go.

156
00:26:35.860 --> 00:27:05.010
Ansgar Dietrichs: Yeah, I mean on that point. Basically, I have a similar, I mean similar general concern as as Marius, that basically, I feel kind of uncomfortable with the index not being in protocol, I think doing it in protocol, for Fussaka at the same time, seems to me like not really an option. Maybe people disagree. But yeah. And then, as Ben was saying, actually like, also the fact that now we, if we have the index that it's not really priced is also a problem. But if you price it, then actually, you kind of have to. That means that you have to also reprice

157
00:27:05.416 --> 00:27:24.379
Ansgar Dietrichs: contract loads for existing small contracts right? Because they also 1st go to the index. And the whole point of this index was that we wanted to avoid having to reprice contract loads for existing use cases because they might break. So it really feels like, no matter which which way we approach it. It just seems to create complications.

158
00:27:24.653 --> 00:27:30.130
lightclient: I mean, the pricing is kind of weird, because we don't really charge for the lookup for code right now.

159
00:27:30.310 --> 00:27:45.090
lightclient: kind of bundled into this account to read thing, but if you think about it like, we pay the same to read the balance as we do to load the code for the account and loading the code hashes, like, you know, 2 lookups in the database where the balance is just one.

160
00:27:46.112 --> 00:27:48.940
lightclient: So I think to me it's

161
00:27:49.780 --> 00:27:57.070
lightclient: I mean it. It is slightly different, like, you're not mercolizing the the code size index. So

162
00:27:57.460 --> 00:28:01.250
lightclient: I'm not convinced that we really need to price it like this.

163
00:28:10.540 --> 00:28:24.979
jochem-brouwer: I just want to bring up that Guillaume will likely present something at Acde which solves this problem. Yeah, I will not go into detail, but this will not reprice the existing contracts, and it will put the code size into the account rop.

164
00:28:25.170 --> 00:28:25.830
jochem-brouwer: so.

165
00:28:30.940 --> 00:28:34.010
Parithosh Jayanthi: That's good to know meeting. Do you wanna go.

166
00:28:34.676 --> 00:28:42.070
milen | Erigon: Yeah, Hi, I just wanted to make a small comment that I was looking into this in in Aragon. And

167
00:28:42.603 --> 00:28:51.870
milen | Erigon: I think I also discussed it with other people in Aragon. And we we think that we actually can load the code size without loading the code

168
00:28:52.120 --> 00:28:59.359
milen | Erigon: and memory, and we actually don't need any extra index for this operation.

169
00:28:59.460 --> 00:29:02.230
milen | Erigon: So we don't need to store any extra data.

170
00:29:02.838 --> 00:29:09.639
milen | Erigon: So kind of like, my preference would be to sort of leave this out of protocol unless there's very

171
00:29:10.030 --> 00:29:16.050
milen | Erigon: good reasons like, in terms of future direction, or why we would want to add it in protocol.

172
00:29:16.663 --> 00:29:27.979
milen | Erigon: So yeah, I just wanted to highlight that. But if if you guys kind of foresee that there's any strong reasons to add it in in the try. Then I guess we'll we'll have to.

173
00:29:28.846 --> 00:29:33.440
milen | Erigon: But yeah, we don't really need this index, for example.

174
00:29:38.550 --> 00:29:46.219
Parithosh Jayanthi: Is there, then, any concrete thing we should be working on between now and Acde? Besides the test that your team is running.

175
00:29:51.570 --> 00:29:57.259
Parithosh Jayanthi: and I guess we make a decision at Acd about how 7, 9, 1, 7 goes ahead.

176
00:30:01.450 --> 00:30:07.530
jochem-brouwer: Yeah, I will make sure that I will try to get these benchmarks and these performance tests done by ace, yeah.

177
00:30:12.000 --> 00:30:19.529
Parithosh Jayanthi: Okay, anything else, you guys think needs to happen before Ecd Onskar or Marius regarding the cip.

178
00:30:24.980 --> 00:30:49.710
Ansgar Dietrichs: The only question because I was briefly way when Johan talked about the tests that we want to run, anyway. And does that include the test where we basically do this clever kind of running out of gas at the right moment in time to basically stress test the worst case test? Or is it only the regular test where you're actually fully load and able to pay for the full load.

179
00:30:49.940 --> 00:31:08.859
jochem-brouwer: No, this is exactly the test which you say. What you do is you do a call, or should call to a contract where you want to call a target contract for this target contract, you will have exactly enough code to call into a 24 kB or less contract, but you will not have enough gas to actually pay for this this code size. Well, cost.

180
00:31:09.110 --> 00:31:18.690
jochem-brouwer: So what you can then do, you will force clients to actually look at this code, and it can either be via the site index or for clients which do not have the site index. They will. They are forced to load the entire code

181
00:31:18.730 --> 00:31:34.440
jochem-brouwer: to actually look up the code size so they can determine the price. And yeah, of course, this will run out of a guess, but that also means that we can still read the same amount of contacts which are like now, bigger than the 74 kB.

182
00:31:34.440 --> 00:31:54.599
jochem-brouwer: And that's indeed the performance test. So likely that's what I would expect. But yeah, my attack is not working, or every client has already done this successfully, but that would mean that every client which does not have this site index has low something like 3 GB of data. So yeah, I think, yeah, this performance test. That's that's the goal of this test. Yeah.

183
00:31:57.300 --> 00:32:01.810
Ansgar Dietrichs: Awesome. Yeah, no, that's exactly the test that I think we just need to run. So that sounds good. Then.

184
00:32:07.331 --> 00:32:14.040
Parithosh Jayanthi: There was also a comment in the eip that Mario linked. Do you? Maybe you want to just bring it up, Mario.

185
00:32:14.590 --> 00:32:17.560
Mario Vega: Yeah, of course, it's a very simple

186
00:32:17.610 --> 00:32:39.979
Mario Vega: open question is whether we charge for the extra size during the transaction like entry contract. So just imagine that we we call the transaction calls into directly into large contract. We currently do not charge anything extra. So that's basically just the question of whether we should charge for it or not, and I think we should do

187
00:32:40.353 --> 00:32:49.099
Mario Vega: it just. I just placed this comment into the eap for us to decide at some point that we have to either charge for it or not.

188
00:32:49.490 --> 00:32:53.689
Mario Vega: Yeah, I don't know if if anybody else has thought about this

189
00:32:54.200 --> 00:32:58.229
Mario Vega: or not, but I think we should. We should definitely decide on something.

190
00:33:00.410 --> 00:33:06.700
jochem-brouwer: Just to comment on that. If we do this, then we have to analyze well mainnet contracts which could actually break.

191
00:33:06.820 --> 00:33:23.179
jochem-brouwer: Because this means that if you currently call into a well and about existing contracts, that means that you now need more gas than, or you need more upfront gas than you have now, and that could, of course, mean that something breaks. So that is something we should definitely analyze. First, st yeah.

192
00:33:27.320 --> 00:33:30.280
Roman: Sorry. Can you explain it? How?

193
00:33:30.710 --> 00:33:35.840
Roman: How does it break? Because it will be only charging for the extra?

194
00:33:37.190 --> 00:33:40.270
Roman: And we don't have such contracts today.

195
00:33:41.700 --> 00:33:44.280
Roman: Such a big contract today.

196
00:33:50.110 --> 00:33:55.870
jochem-brouwer: Okay, I guess I don't know if I understand the solution. Sorry. Yeah, I will reread this this way. Yeah.

197
00:33:56.790 --> 00:33:59.780
Mario Vega: Yeah, basically, basically just charge. If

198
00:33:59.960 --> 00:34:02.640
Mario Vega: the entry point of the transaction is a large contract.

199
00:34:02.860 --> 00:34:07.759
Mario Vega: since there are no large contracts right now in Mainnet. I don't think there should be anything breaking.

200
00:34:08.110 --> 00:34:26.750
Mario Vega: but I think this should not affect the intrinsic gas cost of the transaction. It should only affect once you enter the execution. If you don't have enough gas to pay for the last contract just out of gas immediately. That's my suggestion, at least. But I don't think it should break any existing behavior. In my opinion.

201
00:34:36.290 --> 00:34:45.560
jochem-brouwer: Right? Okay, I see. But I'm not really seeing how this solves the problem, because you still you still have to load the code in order to figure out if this is a large contract. So

202
00:34:46.310 --> 00:34:49.509
jochem-brouwer: yeah. But but maybe we should. We should discuss this Async. I'm not sure of it.

203
00:34:51.090 --> 00:35:05.219
Mario Vega: It's basically, I think it's the same problem with without the index. If you have the index, the code size in the in the in the state tree is basically the same. The same issue for an inter

204
00:35:05.350 --> 00:35:06.930
Mario Vega: intercontract call.

205
00:35:08.940 --> 00:35:11.779
Mario Vega: Yeah, I don't think there's any any

206
00:35:13.070 --> 00:35:19.889
Mario Vega: any extra problems to this. But I'm sure yeah, we should definitely analyze it.

207
00:35:20.050 --> 00:35:20.800
Mario Vega: Yep.

208
00:35:26.910 --> 00:35:34.560
Parithosh Jayanthi: Okay. So our deadline for Thursday is gonna be getting all the open questions for 7, 9 0 7 taken care of

209
00:35:35.234 --> 00:35:45.070
Parithosh Jayanthi: and to make sure that we're happy with the cost set for modex. Right? And if that's done we should be ready to discuss 3 on Thursday.

210
00:35:51.550 --> 00:36:06.490
Parithosh Jayanthi: Okay, there was one other question from the Eric on team, I think Andrew had asked this. Our blocks supposed to be Ilp serialized as header transactions almost withdrawals

211
00:36:07.095 --> 00:36:17.400
Parithosh Jayanthi: the questions on the interrupt chat. I'm not sure. Does someone already have an answer for them? Or do we want to engage on the interrupt chat about this.

212
00:36:25.330 --> 00:36:31.600
Parithosh Jayanthi: Okay, let's take it to the interrupt chat. Then andrew asked the question. About see? 4 h ago?

213
00:36:35.250 --> 00:36:42.150
Parithosh Jayanthi: Great. Then there is the one sec. Let me get the link up again.

214
00:36:51.900 --> 00:37:02.129
Parithosh Jayanthi: So there's a open topic that Marco pointed out about engine get blobs v. 2 from last week, and to not prohibit partial responses.

215
00:37:02.350 --> 00:37:05.190
Parithosh Jayanthi: Are you on the call, Marco?

216
00:37:05.190 --> 00:37:08.160
marco: Yeah, about those. Yeah, do you wanna introduce it?

217
00:37:08.410 --> 00:37:13.230
marco: Yeah, sure. So a bit of context here is that

218
00:37:13.370 --> 00:37:26.899
marco: for the Peerdas stuff, we use the get blobs. V. 2 Api to ask the El side if there's any work that we can reuse, and in the case that we have a full column. We can just reuse all the work from the El side. And we're golden.

219
00:37:27.140 --> 00:37:38.689
marco: The problem is that in 40% of cases, if there's a private blog in that block. That means we're missing one of the cells in the column. And with the current text.

220
00:37:39.010 --> 00:37:44.730
marco: that means that the El side returns null, and there's no work that we can reuse.

221
00:37:46.780 --> 00:37:53.149
marco: We're pretty sure, on the networking side that we can make some like relatively low, level changes to gossip, sub.

222
00:37:53.470 --> 00:37:59.219
marco: with little changes required on the clients to

223
00:37:59.360 --> 00:38:02.089
marco: allow us to reuse all the

224
00:38:02.290 --> 00:38:08.430
marco: partial responses, all these, like everything except the missing cell.

225
00:38:09.210 --> 00:38:13.130
marco: and then for some context on data like around 40% of

226
00:38:13.370 --> 00:38:23.270
marco: blocks with blobs, have it have one private blob. And so it's like, in these cases, we're really just missing that one cell.

227
00:38:23.470 --> 00:38:28.460
marco: And currently, we'd have to fall back to transmitting the whole column.

228
00:38:29.120 --> 00:38:37.660
marco: If we don't prohibit partial responses, we can reuse all that work, and then just propagate that one missing cell.

229
00:38:41.010 --> 00:38:50.659
marco: And so the change here is just to make the text not prohibit partial responses. Kind of goes back to what the well it does go back to what the old.

230
00:38:50.940 --> 00:38:52.480
marco: older texts were saying.

231
00:38:52.680 --> 00:39:03.640
marco: And then my understanding of the pushback here is that we do not have this optimization. Currently, this is true. And we are paying extra for serializing

232
00:39:03.940 --> 00:39:10.129
marco: this data. That is currently not useful, which which is also true.

233
00:39:10.640 --> 00:39:11.870
marco: Yeah.

234
00:39:12.370 --> 00:39:17.789
marco: And so I just kind of want to talk synchronously through this and and try to

235
00:39:19.700 --> 00:39:22.869
marco: and end up with some some general agreements.

236
00:39:26.300 --> 00:39:41.260
Parithosh Jayanthi: Yeah. Maybe to clarify 1 point that was also in the in the comment, section, so partial responses are still useful. Info, because, my assumption was also that they weren't useful, and that's why we removed them.

237
00:39:42.470 --> 00:39:45.670
marco: So currently, right now, they're not useful.

238
00:39:45.890 --> 00:39:52.440
marco: But we think that we like pretty sure that we can make them useful without a hard fork.

239
00:39:55.910 --> 00:40:01.399
Parithosh Jayanthi: Got it. So we want to lay the groundwork for a future change that might make it more useful.

240
00:40:01.760 --> 00:40:02.960
marco: Exactly. There's

241
00:40:04.120 --> 00:40:11.470
marco: There's like a gossip sub change we can make without a hard fork that would make us that would make partial responses useful.

242
00:40:12.030 --> 00:40:17.910
marco: And so with, if we don't prohibit the partial responses.

243
00:40:18.460 --> 00:40:30.229
marco: it's likely that we could ship this gossip sub change without a hard fork and get these benefits, as we scale the blot parameter like with the Bpo, only changes.

244
00:40:35.240 --> 00:40:45.089
Parithosh Jayanthi: Got it? At least, in the comment. I see that pawan had some hesitation towards merging the change. Do you maybe want to voice hesitation or.

245
00:40:47.180 --> 00:40:50.220
pawan: Yeah. But I think, like the main point was that

246
00:40:50.940 --> 00:40:57.510
pawan: we initially did did not have partial responses. And then I initially

247
00:40:58.109 --> 00:41:21.449
pawan: did have partial responses, and then we didn't have. So I was just a little hesitant to merge this change without actually having the optimization, because, like, if El starts returning partial responses, then it is a serialization and deserialization load on both ends as the number of blobs increases. And I also felt that we could

248
00:41:21.630 --> 00:41:26.300
pawan: potentially. Just add, like another

249
00:41:26.480 --> 00:41:38.079
pawan: version of get blobs later on. If this optimization works out and it would like that also wouldn't sort of require hard folk per se, but

250
00:41:38.720 --> 00:41:48.259
pawan: it is a little more coordination effort. But yeah, I just like the main objection was to validate the optimization before actually

251
00:41:48.550 --> 00:41:53.710
pawan: changing the the behavior.

252
00:41:57.800 --> 00:42:18.039
Parithosh Jayanthi: I guess the main questions gonna be if we want to include this change incrementally for, and then just ship the change proactively. But I guess mirroring Pawan's point. Do we already know enough that we know that this change is going to be useful, such that

253
00:42:18.614 --> 00:42:25.510
Parithosh Jayanthi: we can proactively add it? Or do we want to do this later with a post for Safa, for example.

254
00:42:28.109 --> 00:42:35.799
marco: Yeah, I I'm you know. If if we think that we could like make this kind of change

255
00:42:36.580 --> 00:42:37.645
marco: after

256
00:42:39.330 --> 00:42:44.699
marco: we we launched Osaka like that. That's also fine by me. I think I just don't want to

257
00:42:44.860 --> 00:42:48.170
marco: be in a position where we have like this

258
00:42:49.080 --> 00:42:54.730
marco: pretty obvious optimization that we can't use until Glams again.

259
00:42:55.990 --> 00:43:10.574
Parithosh Jayanthi: Yeah, I think if we do it post Susaka. We'd likely just use engine get blobs. V, 3, and then that would be a engine capabilities check, and if v. 3 exists, then the Cl. Would use v. 3, and if not, it would fall back to v. 2.

260
00:43:11.000 --> 00:43:22.780
Parithosh Jayanthi: So I. I don't think there's a blocker with this needing to be Infosaka. But yeah, I I think if all Cls agree that they want to put this in then it's great. But right now it at least seems like

261
00:43:23.080 --> 00:43:27.909
Parithosh Jayanthi: prism and lighthouse mostly want to learn more about the optimization before agreeing.

262
00:43:32.210 --> 00:43:43.390
marco: Yeah, yeah, I I don't. I don't have a strong preference here. And I'll just add what a couple more things, which is I think we can make the

263
00:43:43.590 --> 00:43:56.810
marco: the El side technically doesn't have to change like, if it keeps its current behavior, it would still be spec compliant, the Cl side would have to change, and it might be able to do some optimizations where it doesn't

264
00:43:57.260 --> 00:43:58.670
marco: it? It

265
00:43:59.150 --> 00:44:15.349
marco: doesn't have to pay so much for deserialization. If it notices any of the values are null, so it can just like skip the blob deserialization of any of the values are null. But again. Like, yeah, I get that. This is some extra extra work.

266
00:44:16.880 --> 00:44:20.050
marco: But yeah, like I no.

267
00:44:20.430 --> 00:44:29.049
marco: my, my strong preference here is we can do something for this without before Glamsterdam. The specifics I leave up to you all.

268
00:44:33.050 --> 00:44:40.150
Parithosh Jayanthi: Okay. Do we have any other Cl teams who wanna speak either in favor or against the change?

269
00:44:43.620 --> 00:44:52.160
Parithosh Jayanthi: I think in general, it seems like the main downside is that we're spending a few more cycles doing serialization and deserialization for a potential future optimization.

270
00:44:52.682 --> 00:44:54.740
Parithosh Jayanthi: I guess that's the crux right?

271
00:45:00.735 --> 00:45:01.210
Parithosh Jayanthi: Done.

272
00:45:01.210 --> 00:45:02.050
marco: That's my understanding.

273
00:45:02.940 --> 00:45:10.579
Parithosh Jayanthi: Casey also mentioned that he's in support of Marco's proposal. But most of prism hasn't reviewed it yet.

274
00:45:11.416 --> 00:45:24.330
Parithosh Jayanthi: Perhaps we can create a thread on Acd and put a deadline for tomorrow to agree. If client teams agree, then we can schedule this change, for if that works.

275
00:45:34.590 --> 00:45:37.580
marco: Yeah, I guess another comment is that

276
00:45:38.610 --> 00:45:44.080
marco: if we are already doing a lot of testing, now, does

277
00:45:44.920 --> 00:45:59.260
marco: does it make sense to like introduce a v. 3. Version mid Fusaka. Will that also necessary? But like, require a similar level of testing that that we want to do? And would we be hesitant on rolling out that v. 3 version.

278
00:45:59.450 --> 00:46:01.760
marco: do, I guess, is there prior art? There.

279
00:46:05.680 --> 00:46:27.820
Parithosh Jayanthi: Yeah, I I think I'd also agree with you. I think if we're doing this change after Fusa, it might not actually get the same level of testing as we do with Fusaka. If we do it after Fusaka it'll likely be like engineer one where a client team rolls it out and then presents their results, and other client teams decide to implement it or not.

280
00:46:32.130 --> 00:46:55.760
Parithosh Jayanthi: But I'd say the play here would be to create a thread on all core devs and then collect Feedback Async over the next day, and then have a deadline for merging this in tomorrow. I. It seems like tending to. Yes, makes sense over here. So unless the strong objection by tomorrow, we should put this change in for separate.

281
00:46:57.340 --> 00:46:59.150
Parithosh Jayanthi: does that sound okay to everyone?

282
00:47:00.470 --> 00:47:01.449
marco: Sounds good to me.

283
00:47:06.390 --> 00:47:09.374
Parithosh Jayanthi: Okay, thank you.

284
00:47:10.260 --> 00:47:17.140
Parithosh Jayanthi: Sunnyside lab team. Do you guys want to give a brief update on what you've been testing on Fusaka and what the next steps are.

285
00:47:18.360 --> 00:47:25.705
J Sunnyside Labs: Hi, yeah, we've just started running devnets with devnet 2 spec

286
00:47:26.700 --> 00:47:35.180
J Sunnyside Labs: and yeah, as we discussed, we will 1st do benchmarking of the network bandwidth.

287
00:47:35.290 --> 00:47:43.910
J Sunnyside Labs: and then we will do bandwidth constraining test after. So there will be 2 parts in the test.

288
00:47:44.740 --> 00:47:46.160
J Sunnyside Labs: And

289
00:47:46.970 --> 00:47:56.650
J Sunnyside Labs: yeah, we've started with 50 present guest news over the weekend, and it seems quite good so far.

290
00:48:01.940 --> 00:48:08.560
Parithosh Jayanthi: Awesome and I guess you guys will share a write up on the interrupt chat and then reach out to client teams.

291
00:48:09.570 --> 00:48:10.690
J Sunnyside Labs: Yes, we will.

292
00:48:13.020 --> 00:48:36.689
Parithosh Jayanthi: Perfect and I guess that leads well into the next topic. We should slowly be planning more offensive networks on Fusaka. So split networks trying to do deeper reorgs. I think one that would be interesting is with a proposal. Look ahead to have reorgs over one or 2 epochs. See what happens there?

293
00:48:37.439 --> 00:48:47.990
Parithosh Jayanthi: Do we want to start doing these with Fussaka Devnet? 2 specs, or do we want to block on Fussaka Devnet 3, and then do it afterwards. What does the timeline look there?

294
00:48:54.836 --> 00:48:58.369
Parithosh Jayanthi: Barnabas mentioned Stemnet 3. And

295
00:48:58.520 --> 00:49:01.109
Parithosh Jayanthi: he has at least a few pluses.

296
00:49:05.400 --> 00:49:07.810
Parithosh Jayanthi: Okay, then let's

297
00:49:08.100 --> 00:49:16.979
Parithosh Jayanthi: set that as the plan so we'd focus on getting devnet 3 specs frozen asap and then focus more on breaking Devnet 3.

298
00:49:21.280 --> 00:49:23.869
Parithosh Jayanthi: Cool anything else on Fusaka.

299
00:49:29.440 --> 00:49:39.009
FLCL: I I probably it might be relevant to bring the topic about below Pertex. Limitation.

300
00:49:40.600 --> 00:49:49.020
FLCL: Yeah, there is slight opposition of having it as part of follow up schedule

301
00:49:51.590 --> 00:49:59.783
FLCL: and probably for the next devnet. We need to agree what we will do with that because it's right now implemented this

302
00:50:01.160 --> 00:50:03.600
FLCL: via blob schedule. Right?

303
00:50:06.250 --> 00:50:11.483
FLCL: So my proposal is still to to do this. and

304
00:50:12.370 --> 00:50:18.333
FLCL: or maybe just tries bloop limit. Consensus bloop limit to 9. And

305
00:50:19.726 --> 00:50:29.333
FLCL: simplifies the blob schedule. If it work for you guys. Why, it may be important. Is that? Because it seems like

306
00:50:30.734 --> 00:50:41.975
FLCL: the expo is not scaled. It's so, for example, some clients decline transaction. Decline OP

307
00:50:42.740 --> 00:50:45.269
FLCL: transactions. Propagation. If it has.

308
00:50:45.720 --> 00:50:58.319
FLCL: if a transaction has more than 7 tops, it means that local block building will not include big transactions in the future, and

309
00:50:58.640 --> 00:51:04.640
FLCL: I guess it's done to not overload the pool with heavy transactions.

310
00:51:05.407 --> 00:51:11.499
FLCL: But maybe we need to do some steps towards its scaling.

311
00:51:12.765 --> 00:51:13.540
FLCL: Yeah.

312
00:51:13.970 --> 00:51:19.220
Parithosh Jayanthi: Yeah, there was one, maybe clarification. Anskar asked. The

313
00:51:20.190 --> 00:51:28.299
Parithosh Jayanthi: yeah was the was the decision to move the per Tx blob limit to the prdos eip? Or was it to leave it in the Vpo.

314
00:51:36.400 --> 00:51:40.849
Barnabas: I mean, that doesn't matter where the where it lives.

315
00:51:41.460 --> 00:51:58.259
Barnabas: The the question is whether we want to actually just hard code this value? Or do we want to be making configurable? Because right now what we do is if it's not configured by the client, then we default Max, which is not right, and there was a push back for doing that.

316
00:51:58.440 --> 00:52:04.900
Barnabas: So the next question is, if we shouldn't be defaulting to Max, should we be defaulting to 6,

317
00:52:05.460 --> 00:52:10.379
Barnabas: and if it just default to 6, then we probably don't want to make it configurable.

318
00:52:12.020 --> 00:52:17.579
Barnabas: or if you make it configurable, then we need to just default to 6 instead of defaulting to Max.

319
00:52:17.690 --> 00:52:20.099
Barnabas: and we can still keep it in the Ppo.

320
00:52:20.250 --> 00:52:21.430
Barnabas: Yeah, I be.

321
00:52:24.238 --> 00:52:34.140
FLCL: With Craig. It's it's 9 consensus there. Mean, we

322
00:52:34.750 --> 00:52:37.120
FLCL: have it already. More than 6.

323
00:52:39.109 --> 00:52:42.699
FLCL: should we add this limit now and check it.

324
00:52:43.620 --> 00:52:54.140
Parithosh Jayanthi: This is kind of retroactively saying, the Max, the explore, the expo blob we have today, which could be 9, is basically going to be the Max we have for the future right.

325
00:52:55.930 --> 00:52:58.769
FLCL: And yeah, I guess.

326
00:53:04.098 --> 00:53:13.029
Parithosh Jayanthi: Is there that in itself makes sense to me? I think we're also doing a similar change with transactions per gas.

327
00:53:13.280 --> 00:53:19.229
Parithosh Jayanthi: So is it. Has there been any opposition towards this change?

328
00:53:19.640 --> 00:53:23.220
Parithosh Jayanthi: Is there a discussion somewhere that we can follow this on.

329
00:53:38.830 --> 00:53:42.819
Barnabas: Any discussion in the execution for

330
00:53:42.950 --> 00:53:46.500
Barnabas: regarding this, but not not how many people participated.

331
00:53:46.760 --> 00:53:50.999
Barnabas: I think we just need to open a new Pr. And discuss it over there.

332
00:53:52.120 --> 00:53:58.460
Parithosh Jayanthi: Yeah. Also, I think Marius says. He thought they wanted to. Max at 6.

333
00:54:00.527 --> 00:54:03.689
Parithosh Jayanthi: Francesco, you had your hand up. Do you want to go?

334
00:54:04.100 --> 00:54:13.509
Francesco: Yeah, I mean same thing you said. I don't remember exactly when this happened. I don't know if it was on an old core dev, or on another testing call, but I'm pretty sure that

335
00:54:13.910 --> 00:54:25.419
Francesco: there was like a general agreement for for 6 at some point as the the value then I mean, besides that, I don't. Personally, I don't really care if it's configurable or not like, if

336
00:54:25.790 --> 00:54:36.719
Francesco: people want it to be config configurable, and it doesn't cause too much work to to change it back to configurable. That's fine. But I I really don't think we should. We should be defaulting to

337
00:54:36.900 --> 00:54:44.370
Francesco: the Max, if if it's not, there isn't like a specifically configured value. And yeah, and specifically, we had

338
00:54:44.820 --> 00:54:47.859
Francesco: the number 6 as something that a lot of people agreed on.

339
00:54:49.332 --> 00:54:58.187
FLCL: That was very quick discussion, and I just trying to bring such an argument to that because I felt to

340
00:54:59.856 --> 00:55:06.410
FLCL: to bring bring it before so if we set this to 6

341
00:55:07.079 --> 00:55:14.429
FLCL: we will need to validate that new transactions on the fork border when a circuit happens

342
00:55:14.730 --> 00:55:17.910
FLCL: before we allowed 9 transactions.

343
00:55:18.400 --> 00:55:23.049
FLCL: If we allow just 6, we will need to validate on forks. That

344
00:55:23.957 --> 00:55:26.142
FLCL: transaction pool does not contain

345
00:55:27.150 --> 00:55:35.597
FLCL: big transactions now, and it will be a little bit more complex, and seems to me that 9 is better.

346
00:55:36.930 --> 00:55:44.920
FLCL: number as it is the current number, and we will not need to check for a decrease

347
00:55:45.320 --> 00:55:46.270
FLCL: in the future.

348
00:55:49.660 --> 00:55:51.799
Parithosh Jayanthi: Ben, do you want to continue.

349
00:55:53.718 --> 00:55:56.590
Ben Adams: I I just say, yeah.

350
00:55:56.980 --> 00:56:12.340
Ben Adams: I'm keen to have it low. But if if we've already done the work to have it configurable. It's worth keeping that because when we hit 72, maybe 6 isn't the right number, maybe one get a little bit higher.

351
00:56:12.848 --> 00:56:18.710
Ben Adams: So it'd be if we've. If we've already done that work, then we might as well keep it in.

352
00:56:19.920 --> 00:56:27.440
Ben Adams: That makes sense, because as we go ahead, that that number might increase as the number of blobs increases.

353
00:56:27.940 --> 00:56:30.219
Barnabas: Right. But then the argument is that

354
00:56:30.370 --> 00:56:38.559
Barnabas: we still need to change the IP to specify that the Mac. That the default value, if it's not defined should be 6,

355
00:56:38.700 --> 00:56:40.279
Barnabas: and not Max.

356
00:56:41.645 --> 00:56:46.669
Ben Adams: Yeah, I mean, I I just mean if we if we have it in the Bpo

357
00:56:47.200 --> 00:56:52.129
Ben Adams: then already, then we might as well just keep it in the vpo. And set it 6.

358
00:56:57.695 --> 00:57:09.180
FLCL: They want to clarify Marius mentions 6 is a constraint for text pool but you can build a block with 9 blocks right now, right?

359
00:57:13.130 --> 00:57:15.559
FLCL: It's not constrained by consensus.

360
00:57:16.620 --> 00:57:25.859
Marius: We can. We can build a block with with 9, with 9 blocks, but we only allow 6 block transactions in our transaction pool.

361
00:57:26.730 --> 00:57:27.290
FLCL: Yep.

362
00:57:30.387 --> 00:57:37.542
FLCL: so this number that we are discussing right now. It's a constraint for like

363
00:57:38.440 --> 00:57:45.640
FLCL: block building, too. I mean you will not be able to include big transactions in the future.

364
00:57:46.300 --> 00:57:50.690
FLCL: Oh, is this difference considerate.

365
00:57:52.990 --> 00:57:57.700
Barnabas: I think the idea was to limit the gossip limit on the outside.

366
00:57:58.210 --> 00:58:00.360
Barnabas: That's why we wanted to limit it to 6.

367
00:58:00.490 --> 00:58:02.769
Barnabas: So we have a predictable value. There.

368
00:58:03.480 --> 00:58:03.920
FLCL: Okay.

369
00:58:03.920 --> 00:58:07.240
Ben Adams: Yeah. Yeah. And also also, if we're including

370
00:58:09.150 --> 00:58:14.859
Ben Adams: larger transactions that are in the transaction pool that we lose the benefit of, get blobs.

371
00:58:21.080 --> 00:58:39.579
Parithosh Jayanthi: Just mimicking something that Anskar put in the chat. We apparently have already made the decision to move Max out of the Bpo and set it to 6. So if we do want to revisit this, then I think the best approach is to have a thread on either all core devs or execution dev.

372
00:58:39.780 --> 00:58:44.320
Parithosh Jayanthi: and to bring it as a change to Ecde on Thursday.

373
00:58:44.680 --> 00:58:51.470
Parithosh Jayanthi: But that being said, I think right now, it does make sense to leave it at 6, and for

374
00:58:52.060 --> 00:58:56.490
Parithosh Jayanthi: and Barnabas does mention, we don't have the modification to the eip, so we should have that.

375
00:58:58.880 --> 00:59:01.650
Parithosh Jayanthi: Yeah. But other than that, I think that would be the

376
00:59:01.790 --> 00:59:05.940
Parithosh Jayanthi: central plan forward for the topic, does that sound? Okay.

377
00:59:14.440 --> 00:59:20.410
Parithosh Jayanthi: okay, so we would still need an update to the eip, if that has not been made already.

378
00:59:23.858 --> 00:59:31.991
Parithosh Jayanthi: Moving on to the next topic since we are kind of close to the end. Gas limit changes

379
00:59:32.890 --> 00:59:38.105
Parithosh Jayanthi: quite a few plan teams, I think. Never mind. Gets best. And

380
00:59:39.190 --> 00:59:45.169
Parithosh Jayanthi: Erica have all released releases with 45 million as the default gas limit

381
00:59:46.037 --> 00:59:58.752
Parithosh Jayanthi: the expand Ops team has also released a blog post with how we arrived at the 45 million gas limit number, and I think Bezoo team is working on a release this week to update that default as well.

382
00:59:59.200 --> 01:00:10.520
Parithosh Jayanthi: So I think this is also a good time to start asking sales to update their gas limit knowing that the performance related fixes are now put into the Els.

383
01:00:11.129 --> 01:00:18.360
Parithosh Jayanthi: So yeah, I just wanted to flag that for Cr teams. I know that. Prism already has a branch with the change ready. And

384
01:00:18.610 --> 01:00:22.400
Parithosh Jayanthi: yeah, I think other Cls will follow shortly after.

385
01:00:28.630 --> 01:00:38.810
Parithosh Jayanthi: and relating to the gas limit topic in general. Felix, from the guest team has been looking more into Modex optimizations on gas.

386
01:00:39.443 --> 01:00:45.080
Parithosh Jayanthi: There's an active chat in the Guest limit channel along with some tests and looking into it.

387
01:00:45.480 --> 01:00:48.530
Parithosh Jayanthi: And yeah, the bezel team

388
01:00:48.680 --> 01:00:55.839
Parithosh Jayanthi: says that they're working on testing the new release sync performance regressions, and so on, so that should be there soon.

389
01:00:56.460 --> 01:01:03.869
Parithosh Jayanthi: Besides that, I think Pk. Had a question on the gas limit. Do you want to talk about it. Pk.

390
01:01:05.640 --> 01:01:11.729
pk910: Yeah, just a general question on Perth Def, net one, we currently have a gas limit of one

391
01:01:11.920 --> 01:01:23.050
pk910: 1 million and usual spamming scenarios. Basically break chain right now. I think that was in preparation to get contracts deployed, just wanted to ask if

392
01:01:23.240 --> 01:01:26.110
pk910: is still needed, or we can lower it again.

393
01:01:29.940 --> 01:01:34.180
Parithosh Jayanthi: I think Joachim was the one doing the deployments. Do you wanna

394
01:01:34.810 --> 01:01:39.920
Parithosh Jayanthi: talk about it, Yokom? Is it? Can we lower the gas limit again, or do you still need it to be very high?

395
01:01:44.460 --> 01:01:49.099
Parithosh Jayanthi: He might have dropped off. So we might have to talk to him about this later.

396
01:01:55.810 --> 01:02:00.780
Parithosh Jayanthi: Okay, is there anything else people want to talk about regarding the gas limit?

397
01:02:07.500 --> 01:02:13.589
Parithosh Jayanthi: Okay, any other topics anyone wanted to bring up for for the call today.

398
01:02:14.310 --> 01:02:25.879
Parithosh Jayanthi: Otherwise I think we have a plan for at least a couple of the topics for Acde, and we should be on target for freezing the scope for and then planning definitely. 3.

399
01:02:27.970 --> 01:02:31.599
Parithosh Jayanthi: Thank you. Everyone for joining then and have a nice day.

400
01:02:33.630 --> 01:02:34.410
pawan: Thank you.

401
01:02:34.760 --> 01:02:35.639
Ameziane Hamlat: Thanks, bye.

402
01:02:35.640 --> 01:02:36.869
Marius: Yeah, thank, you.

403
01:02:36.870 --> 01:02:37.630
jochem-brouwer: Thank you.

404
01:02:37.630 --> 01:02:38.109
Mario Vega: Thank you.

