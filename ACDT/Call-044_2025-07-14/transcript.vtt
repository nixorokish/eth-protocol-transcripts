WEBVTT

1
00:00:18.190 --> 00:00:19.570
Pooja Ranjan: Hello! Akash!

2
00:00:22.020 --> 00:00:23.630
Akash | ECH: Okay. Hello.

3
00:01:07.350 --> 00:01:19.809
Pooja Ranjan: Hello, Takash, I am going to start streaming for Pre stream. Video. Can you please confirm if it is going well on Youtube and Twitter as well.

4
00:01:20.410 --> 00:01:21.140
Akash | ECH: Okay.

5
00:01:26.620 --> 00:01:28.320
Pooja Ranjan: It has started. There.

6
00:01:51.660 --> 00:01:54.559
Akash | ECH: Yeah, we are live on both the platforms.

7
00:01:55.800 --> 00:01:59.790
Pooja Ranjan: And the audio is also good, like the music is coming up right.

8
00:02:00.000 --> 00:02:00.690
Akash | ECH: Yeah.

9
00:02:01.100 --> 00:02:04.820
Pooja Ranjan: Okay, perfect. Then I hope it would work out this time. Thank you.

10
00:04:05.990 --> 00:04:08.099
Justin Florentine (Besu): Good morning, testers.

11
00:04:10.250 --> 00:04:11.760
Parithosh Jayanthi: Good morning.

12
00:04:12.890 --> 00:04:14.809
Parithosh Jayanthi: Hope you had a nice weekend.

13
00:04:24.460 --> 00:04:28.450
Pooja Ranjan: Good morning, all Hello, Pari and Mario!

14
00:04:29.240 --> 00:04:31.900
Pooja Ranjan: Do let us know whenever we are ready for streaming.

15
00:04:32.160 --> 00:04:37.560
Parithosh Jayanthi: Yeah, thank you. Let's give it another minute for people to join. And then we can start off.

16
00:06:32.570 --> 00:06:38.149
Parithosh Jayanthi: Okay, let's start off. Then could we start the stream? Please.

17
00:06:38.920 --> 00:06:40.010
Pooja Ranjan: We are, live.

18
00:06:40.560 --> 00:06:41.470
Parithosh Jayanthi: Thank you.

19
00:06:42.437 --> 00:06:51.980
Parithosh Jayanthi: Okay. So the 1st topic on the agenda today is, an update on Fusaka. Do we have Barnabas on the call to give the update.

20
00:06:53.220 --> 00:07:08.221
Barnabas: Yes, we have a pretty nice participation now, at about 95%. We have seen a few extra deposits made from the team. They are testing their coupling validator or their coupling. Cl,

21
00:07:09.790 --> 00:07:12.250
Barnabas: we had a few

22
00:07:12.870 --> 00:07:30.619
Barnabas: issues, and I have reached out to every single client team about those specific issues. If you are noticing that your editor is not up to head, or are having some issues in staying up to head or missing some doc proposals. Then please take a look.

23
00:07:30.990 --> 00:07:34.170
Barnabas: But other than that, I think we should be pretty good.

24
00:07:36.110 --> 00:07:42.069
Parithosh Jayanthi: Awesome. Were there any notable bugs that were fixed in the last week that we should talk about? Bring up.

25
00:07:46.600 --> 00:07:55.570
Barnabas: Nothing really like right now we are investigating some metadata box, that tech with the

26
00:07:56.250 --> 00:08:09.880
Barnabas: that. So we have a new tool called if does guardian. And this tool is helping us, the metadata field and status messages of a specific client.

27
00:08:10.040 --> 00:08:13.830
Barnabas: And this is going to really help us Debug

28
00:08:14.060 --> 00:08:22.150
Barnabas: smaller problems and figuring out if specific notice costing the columns that they say they would

29
00:08:25.230 --> 00:08:27.985
Barnabas: still a bit work in progress. But hopefully,

30
00:08:28.690 --> 00:08:31.980
Barnabas: hopefully, it will be more ironed out by the ministry.

31
00:08:33.140 --> 00:08:47.680
Parithosh Jayanthi: Yeah. And I think the tools also aim to give us a 3rd point of data set whenever there's a dependency between 2 clients, and it'll be integrated into Dora so that it's easier for client devs to also figure out what's going on on network.

32
00:08:52.060 --> 00:08:59.436
Parithosh Jayanthi: Yeah. And Justin says there was a small nimbus issue that was fixed and new consensus specs.

33
00:09:00.260 --> 00:09:05.789
Parithosh Jayanthi: yeah. And the result of verifies that Kcg proof patch wasn't being checked properly.

34
00:09:06.030 --> 00:09:07.930
Parithosh Jayanthi: Thank you for the update

35
00:09:09.018 --> 00:09:16.971
Parithosh Jayanthi: and on the topic of consensus specs. I also see this as one Pr from Leo that adds,

36
00:09:18.110 --> 00:09:29.380
Parithosh Jayanthi: adds a few new test types Justin. Maybe you could have a look and the Cl teams as well if this testing approach makes sense and we can merge it in. Perhaps.

37
00:09:30.482 --> 00:09:34.210
Justin Traglia: Yep, we'll review. I'm not sure how I feel about

38
00:09:35.206 --> 00:09:40.759
Justin Traglia: test for a test, though. The test template test we'll discuss that internally.

39
00:09:42.060 --> 00:09:52.069
Parithosh Jayanthi: Okay, that sounds perfect. And Barnabas. There was also a round of sync test. Right? Were there any findings from that? Are we mostly good. What's going on.

40
00:09:52.612 --> 00:10:06.249
Barnabas: Sync test generally looked pretty. Okay. We cannot make bigger conclusions right now, because we are limited in a different aspect, but hopefully. By the end of this week we're gonna be able to do very stable sync test.

41
00:10:09.600 --> 00:10:29.330
Parithosh Jayanthi: Okay, perfect and we can just post the sync test repository in case anyone wants to also play around with what's going on you should be able to check the Github actions here they are triggered once a day, and you should be able to see if your client is passing or failing the sync test for the latest, for Safa Devnet.

42
00:10:29.950 --> 00:10:45.409
Barnabas: Yeah. But for now, please ignore this, because, we are currently I Ops limited on our Github runners. So those invalid test they basically just time out after 2Â h, and those are most likely caused by the same bug

43
00:10:45.760 --> 00:10:48.050
Barnabas: that the machine doesn't have enough.

44
00:10:48.050 --> 00:10:56.969
Parithosh Jayanthi: Yeah, right now, we can't draw any assumptions on the actual speed. Once we change the infrastructure, then we should be able to also compare speeds of the sectors.

45
00:11:00.370 --> 00:11:07.589
Parithosh Jayanthi: Is Bharat. On the call I saw he had posted a message with an update on med testing.

46
00:11:08.020 --> 00:11:14.187
Bharath: Yeah. So I'm on the call. Yeah. So in terms of the update to the workflows

47
00:11:15.100 --> 00:11:32.969
Bharath: the 1st the code is there, I think, Justin, thanks for the review. Justin was able to review, and seems good. The code there. So I think Map boost, and Melay generally seem, can get it on a devnet. Our builder, I was able to hack it around and get it to work locally.

48
00:11:33.471 --> 00:11:45.139
Bharath: So this is like local, and kurtos is local, but it's not like broad ready, like. There are a lot of breaking changes across, like the red and alloy stuff. So I ended up. There are some hacks, but

49
00:11:45.280 --> 00:11:49.399
Bharath: it's working. I was able to see like blobs being produced locally and stuff.

50
00:11:49.560 --> 00:11:53.266
Bharath: So yeah. So that's that's the update

51
00:11:54.100 --> 00:11:57.702
Bharath: would love to get out on Devnet, too. But one of the problems

52
00:11:58.583 --> 00:12:02.219
Bharath: you know, in having in the Tg chat with Roman is like.

53
00:12:02.680 --> 00:12:22.239
Bharath: I think the definite Fusaka devnet. 2 branch of rep is this is breaking with Eip 7, 9 0 7 that. I'm I'm trying to like work on that to. I'm like Roman gave some suggestions. I've tried to like work across that, and I'll put any up an update on the Tg chat. But yeah, that's the current state of like

54
00:12:22.470 --> 00:12:30.510
Bharath: email workflows some dependency issue with like that. I'm trying to like, I'll try to resolve that.

55
00:12:31.150 --> 00:12:35.260
Parithosh Jayanthi: Okay, that's perfect. Charles, did you want to say something.

56
00:12:37.040 --> 00:12:38.790
Charles: No. Hello! I just joined.

57
00:12:41.170 --> 00:12:59.519
Parithosh Jayanthi: yeah, okay, that's perfect. In that case, then, if the dependency issues are fixed while Devnet 2 is still live, then I do think it's fine to deploy like a fork of something that's unmerged purely to catch bugs earlier, so that we have more time to fix them. But if not, it sounds like it would be ready in time for Devnet 3.

58
00:12:59.700 --> 00:13:01.300
Bharath: Yeah, yeah, that's that's the point.

59
00:13:01.700 --> 00:13:03.860
Parithosh Jayanthi: Okay, perfect. Thank you for that.

60
00:13:04.813 --> 00:13:20.160
Parithosh Jayanthi: Continuing on the Devnet topic. We do have a state a state bloat network that's been working over the weekend. I think there was some minor things found in. Never mind that. They're still investigating.

61
00:13:20.330 --> 00:13:24.137
Parithosh Jayanthi: but we are aiming to have 2 times the

62
00:13:24.790 --> 00:13:40.060
Parithosh Jayanthi: state size of Mainnet. Soon we. There is a a telegram group where we're trying to coordinate metrics. So in case there's any El that it hasn't already been added to the group. Then please reach out. There's a list of metrics and

63
00:13:40.200 --> 00:13:47.109
Parithosh Jayanthi: type of data that we want to gather, and that's very client specific. So we're gonna need your help to to get the metrics.

64
00:13:49.865 --> 00:14:00.740
Parithosh Jayanthi: The next topic is, 45 million gas limit lighthouse made a release last week, and I wanted to know what the status is of the other cls.

65
00:14:01.890 --> 00:14:03.370
Parithosh Jayanthi: in terms of releases.

66
00:14:12.120 --> 00:14:19.970
Parithosh Jayanthi: Okay? Then I guess we take that offline? At least the good thing is over the last week.

67
00:14:20.370 --> 00:14:42.449
Parithosh Jayanthi: Nimbus also has done this release as well, so we already have numbers as well as lighthouse with their release and according to the relay Apis that we've been tracking, we have roughly 40 ish, 41% indicating 45 million gas we have around half indicating 36 million gas and a few which?

68
00:14:43.110 --> 00:14:45.990
Parithosh Jayanthi: yeah, we're still figuring out that indicate 30 million. Yes.

69
00:14:46.160 --> 00:14:57.386
Parithosh Jayanthi: so at least over the next days. I think that should sort itself out, and we should be fine and just reading from the chat. I think prism lodestar as well as kind of have releases

70
00:14:57.860 --> 00:15:00.460
Parithosh Jayanthi: either tomorrow or later this week.

71
00:15:01.920 --> 00:15:04.259
Parithosh Jayanthi: Okay, thank you for that.

72
00:15:05.143 --> 00:15:16.729
Parithosh Jayanthi: There was one following topic for fusaka.net. 3. There's this open pr blob transaction limit that hasn't been merged yet.

73
00:15:17.642 --> 00:15:23.739
Parithosh Jayanthi: Does someone want to give context here and figure out what's missing.

74
00:15:27.120 --> 00:15:37.220
Barnabas: I think they are approved are missing. They've discussed this topic many times already on Acd. E. And as well

75
00:15:37.972 --> 00:15:50.279
Barnabas: just for a quick recap. We are to say that we're gonna be removing the Max Blobs per transaction from the blob schedule configuration, and we're going to have it hard coded for

76
00:15:50.490 --> 00:15:51.450
Barnabas: perfork.

77
00:15:53.570 --> 00:15:58.640
Barnabas: so no more no longer gonna be part of the Bpo. But it's gonna be part of the work.

78
00:15:59.270 --> 00:16:10.509
Parithosh Jayanthi: Okay, I think at the very least we need either Mark or Raul to approve it as eip authors. But it would be great if other El teams can also leave their comments down.

79
00:16:20.770 --> 00:16:27.320
Parithosh Jayanthi: Okay, does anyone have anything else to add for the topic? If not, we can move on.

80
00:16:31.180 --> 00:16:40.499
Parithosh Jayanthi: Okay. Joacham had a presentation prepared for Eip 7, 9 0, 7. Do you wanna go, Jokom.

81
00:16:42.160 --> 00:16:44.689
jochem-brouwer: Yes, let me share my screen.

82
00:16:49.590 --> 00:16:52.779
jochem-brouwer: Yeah. Can you see my screen and also my mouse?

83
00:16:53.780 --> 00:16:54.480
Parithosh Jayanthi: Yes.

84
00:16:54.970 --> 00:16:56.050
jochem-brouwer: Okay, great.

85
00:16:56.280 --> 00:17:03.930
jochem-brouwer: All right. I wanted to bring up the well. The the big problem is, we want to raise the coder size limit.

86
00:17:04.170 --> 00:17:06.200
jochem-brouwer: This seems like a trivial problem.

87
00:17:06.560 --> 00:17:10.210
jochem-brouwer: But from my side this is not trivial to solve at all.

88
00:17:11.104 --> 00:17:17.400
jochem-brouwer: We are currently introducing eap 7,907, and this is currently scheduled for inclusion for Fusaka.

89
00:17:17.760 --> 00:17:29.159
jochem-brouwer: And in this presentation I'm looking at the version of 8 July 2,025. So that's from last week I just saw that there was a commit merge. But that didn't change a lot was just a clarification.

90
00:17:29.910 --> 00:17:38.220
jochem-brouwer: And what it does is, it raises the Coder size limits from from 24Â kB to 48Â kB, so it doubles it.

91
00:17:38.870 --> 00:17:40.609
jochem-brouwer: and it also introduces

92
00:17:40.790 --> 00:17:48.380
jochem-brouwer: this this metering formula for large code sizes. So you pay more for large code, so that that all looks very logical.

93
00:17:48.830 --> 00:17:55.369
jochem-brouwer: And and this so if we would raise the code size limit. Again.

94
00:17:55.580 --> 00:18:00.399
jochem-brouwer: then we would also use this formula again, if we if we raise the this limit.

95
00:18:00.910 --> 00:18:07.300
jochem-brouwer: and how I'm thinking about this eap currently is also that we are basically using this as a framework

96
00:18:07.550 --> 00:18:12.710
jochem-brouwer: for the future to handle or price in these even bigger contracts.

97
00:18:12.990 --> 00:18:19.420
jochem-brouwer: And that's maybe also to think about how accurately present this this. Yeah in this presentation.

98
00:18:20.030 --> 00:18:22.690
jochem-brouwer: And and

99
00:18:23.100 --> 00:18:30.430
jochem-brouwer: I want to mainly to to raise that point. To think about this is because we currently want to introduce this mechanism.

100
00:18:30.600 --> 00:18:39.819
jochem-brouwer: and if we change it later, that would not be nice. Because then we have this historical code steps. So it would be nice to just do it right on the 1st try? Basically.

101
00:18:40.770 --> 00:18:44.190
jochem-brouwer: So this pricing formula, how does it work?

102
00:18:44.500 --> 00:18:52.370
jochem-brouwer: And the 1st thing what it does is it introduces a new, warm, and cold state. So what we currently have is that we have a warm and cold state for every account.

103
00:18:52.750 --> 00:18:58.099
jochem-brouwer: Each time that you read a new account which you have not touched into the current transaction.

104
00:18:58.370 --> 00:19:03.380
jochem-brouwer: and that's when you move it from the cold state to a warm state.

105
00:19:03.610 --> 00:19:09.940
jochem-brouwer: And yeah, so we have a warm and cold account. But we also have warm and cold code now. So if you read cold.

106
00:19:10.260 --> 00:19:15.750
jochem-brouwer: and this would move the codes from cold to warm, and the accounts would already be warmed up.

107
00:19:16.660 --> 00:19:17.540
jochem-brouwer: So what's

108
00:19:17.660 --> 00:19:23.259
jochem-brouwer: it's currently what you do is you have to pay 2,100 guests from cold code to make it bar.

109
00:19:23.660 --> 00:19:34.629
jochem-brouwer: And for the big contracts we use this, we introduce this dynamic formula, this only kicks in. If you read bigger contracts than the current limit of 24Â kB.

110
00:19:34.830 --> 00:19:37.570
jochem-brouwer: And if you do that.

111
00:19:37.690 --> 00:19:52.079
jochem-brouwer: then you have this formula, and what you essentially essentially do is that for every 32 Byte words which you which the code is over the original 24Â kB limit is, you pay 4 extra guests.

112
00:19:53.490 --> 00:20:02.139
jochem-brouwer: and this coder size feeding. This is actually a problem, because this coder size is something which you cannot directly read from the merkel particia tree.

113
00:20:02.530 --> 00:20:08.779
jochem-brouwer: And to actually read this from the data structure is what you do. Is you open the account from the Mpt.

114
00:20:09.120 --> 00:20:19.739
jochem-brouwer: Then you read the code, hash. This points to the the entire code. And from that you can actually read the code size. So this code size is not part of the account.

115
00:20:21.070 --> 00:20:22.080
jochem-brouwer: And

116
00:20:22.270 --> 00:20:31.129
jochem-brouwer: and if we will use that. So we are not going to do any optimizations in our well, in our clients data structure, we have a dose factor.

117
00:20:31.470 --> 00:20:37.980
jochem-brouwer: And this dose factor is that we can read N. Times, Z. Bytes of data per transaction.

118
00:20:38.370 --> 00:20:47.240
jochem-brouwer: This nest amount of context which we can, that we can read per day transaction. And this is currently, if we will take the 30 million guest limit.

119
00:20:47.510 --> 00:20:50.399
jochem-brouwer: This is about 11,000 contracts.

120
00:20:50.560 --> 00:20:53.100
jochem-brouwer: and that is this maximum code size.

121
00:20:53.530 --> 00:20:55.779
jochem-brouwer: And just as an illustration. How would you do this?

122
00:20:56.320 --> 00:20:59.109
jochem-brouwer: What you do is you have a proxy contract

123
00:20:59.450 --> 00:21:17.749
jochem-brouwer: you call into this contact from? Well, I can call it a tech contract. We give us the exact amount of guess which we would have to use to read this contract, but only to read the the 24Â kB contract. So not the bigger contract.

124
00:21:18.150 --> 00:21:22.629
jochem-brouwer: And if we do this for bigger contracts, then we can actually pay the static cost.

125
00:21:23.000 --> 00:21:37.890
jochem-brouwer: But we cannot pay for the dynamic cost. And the problem here is that if we have to calculate what the dynamic cost is, we need to know the code size. And because we need to know the Coder size. This means that we have to read. If we do not have this optimization, we have to read

126
00:21:38.590 --> 00:21:41.619
jochem-brouwer: entire codes from the merkel partition tree.

127
00:21:42.650 --> 00:21:45.420
jochem-brouwer: And of course, we can get around this

128
00:21:45.730 --> 00:21:54.719
jochem-brouwer: by this optimization. But yeah, this is then so yeah, this is basically an implicit optimization which every client then has to use.

129
00:21:54.960 --> 00:22:04.250
jochem-brouwer: and there is also a new row here. I will share the presentation after this, by the way, in the execution spec test repository. So you can also see in practice how this would look.

130
00:22:05.240 --> 00:22:13.259
jochem-brouwer: So, as I said, the solution for this problem is that, well, we have this code hash, decoder sites and implicit or mandatory lookup cache.

131
00:22:13.980 --> 00:22:18.849
jochem-brouwer: or what would maybe be nicer, is to add this coda size to the account rop.

132
00:22:19.930 --> 00:22:29.289
jochem-brouwer: And what we'll do then is we could either introduce a new account in the account rop, or we could do something else like encode in an already existing field like in the nuance.

133
00:22:29.460 --> 00:22:33.119
jochem-brouwer: There are, of course, many variations for this to do this.

134
00:22:33.840 --> 00:22:51.660
jochem-brouwer: There are also some other possible problems which I might see is that if you bump the Coder size, we also have this bigger witness size. Because currently, in the Coder witness, we have to add the entire code to the witness.

135
00:22:53.130 --> 00:22:54.070
jochem-brouwer: And

136
00:22:55.540 --> 00:23:02.659
jochem-brouwer: another problem which I can see that's more from an economical perspective, is that we have to wait for we have to pay for all the codes.

137
00:23:02.990 --> 00:23:09.780
jochem-brouwer: So if you are calling a contract which is big, then you have to pay this dynamic cost for all the codes.

138
00:23:10.020 --> 00:23:23.219
jochem-brouwer: and my main concern is that we would end up well in the end, that people will still split up the contracts into multiple contracts to avoid that, people are paying for for these big contracts if they are not using this.

139
00:23:23.950 --> 00:23:46.780
jochem-brouwer: So you are actually paying for what you are using. And as an example, here we have this big contract here, and if you use all the code in this big contract in your transaction, then it's fine. We just pay this extra gas. But what if this is, for instance, like an esc, 20 contract, we have this transfer method, which is a very small method itself. Then at some point

140
00:23:47.210 --> 00:23:56.339
jochem-brouwer: as an contract offer, we might realize, okay, I don't want that. All my users are going to pay this extra fee for reading all this code. So what I can then do

141
00:23:56.700 --> 00:24:17.269
jochem-brouwer: is I can just split up my big contract into smaller contracts. And okay, I've only put one here, but I will put my popular methods in the root contracts, and then I will put the unpopular methods into all the contracts, such as I am only paying for calling these methods when I actually need those.

142
00:24:17.440 --> 00:24:33.500
jochem-brouwer: And this 3,000 cost is only for the 48Â kB. But what if we would raise this code even further, for instance, to the 256Â kB. This would actually cost 30,000 extra gas per call. And yeah.

143
00:24:34.090 --> 00:24:42.819
jochem-brouwer: I could imagine that we don't want our users to actually pay this impacted. And that will mean that we will end up splitting up our contacts again.

144
00:24:43.200 --> 00:24:49.179
jochem-brouwer: But yes, if we would do that in practice. That's essentially some kind of code imagalization.

145
00:24:49.380 --> 00:24:55.060
jochem-brouwer: because in the end we want to pay for what we use, and not that we are paying for everything in which we are loading.

146
00:24:56.690 --> 00:25:00.800
jochem-brouwer: So just to quickly go over these concerns again.

147
00:25:00.980 --> 00:25:06.909
jochem-brouwer: The main concern which I have is it's implicit code hash to the code size lookup, cache.

148
00:25:07.090 --> 00:25:19.980
jochem-brouwer: I don't think we have ever done this before, but I might might have missed something, but I don't think we've ever done this before in a network upgrade that we have this implicit well, new data structure.

149
00:25:20.160 --> 00:25:25.309
jochem-brouwer: And yeah, which is, yeah, which which we would need.

150
00:25:27.360 --> 00:25:39.009
jochem-brouwer: I'm also not sure what would economically happen with this? Yeah, with having to pay for these big contracts that you have to pay for all the code which you load. So are we going to see that contacts are actually going to be split up?

151
00:25:40.770 --> 00:25:52.869
jochem-brouwer: The other concern is that? Well, what if we will change, for instance, in Glamsterdam our strategy again. Then we still have this coded depth that we have changed. We have added added this pricing formula, and then we'll change it again.

152
00:25:53.460 --> 00:26:01.900
jochem-brouwer: and also things which we should solve also so much short term like, okay, we now reach 4, 4, guess by 32 Byte words.

153
00:26:02.170 --> 00:26:07.989
jochem-brouwer: Is this too much. Is this too cheap? Well, we don't know. We should solve this.

154
00:26:08.020 --> 00:26:34.330
jochem-brouwer: and these are, of course, like some small things which we can all fix on the fly. But there are also some things to think about like, okay, we have this 2,100 extra gas to pay. If you read the new account. If you read the code and currently, in the specifications, you also have to pay this code, if you want to. For instance, transfer, if you to an Eoa, so we would call an Eoa. Then we also have to pay this 2,100 extra gas, even though we know that this account does not have any code in it.

155
00:26:34.980 --> 00:26:42.620
jochem-brouwer: and also in the terms of testing this, I think that testing the current ep is very big to test.

156
00:26:42.830 --> 00:26:51.789
jochem-brouwer: because we have this extra warm slash, cold category of accounts. So the account is warm and cold, and also the code is warm and cold.

157
00:26:51.990 --> 00:27:01.539
jochem-brouwer: And yeah, my final thoughts is, I want to stress that I really know that this 24Â kB is super small, and we should change it. We should raise it.

158
00:27:01.930 --> 00:27:07.370
jochem-brouwer: But we should also think of the side effects what this might imply and introduce.

159
00:27:08.270 --> 00:27:15.369
jochem-brouwer: And yeah, that was my my talk. I will share the slides afterwards. Yeah, any questions.

160
00:27:22.370 --> 00:27:25.010
jochem-brouwer: or maybe maybe let's read it yet.

161
00:27:27.410 --> 00:27:31.480
jochem-brouwer: Okay, Barnabas is saying, could you not just charge for the worst case scenario?

162
00:27:33.050 --> 00:27:44.910
jochem-brouwer: yeah. The answer was already saying this, this will very likely break existing contracts. And we also have to think about this because this is like basically like an aggressive way to solve this problem.

163
00:27:45.100 --> 00:28:04.579
jochem-brouwer: But this would work in the current context, maybe for 48Â kB, that this might break a very small amount of contracts. But what if we would think of expanding this further to like, for instance, the 256Â kB that would mean that you have to pay upfront the 30,000 gas. And that's, of course, a lot. So

164
00:28:04.920 --> 00:28:10.960
jochem-brouwer: I do not see this this happening and a static cost.

165
00:28:11.700 --> 00:28:14.729
jochem-brouwer: Yeah, the the problem is still that.

166
00:28:16.320 --> 00:28:19.669
jochem-brouwer: Yeah, that this will very likely break a lot of contracts.

167
00:28:20.760 --> 00:28:22.130
jochem-brouwer: So yes.

168
00:28:22.130 --> 00:28:23.859
Parithosh Jayanthi: Rather than.

169
00:28:25.210 --> 00:28:30.830
draganrakita: Joshua. I think we had this discussion already in the discord.

170
00:28:31.790 --> 00:28:40.330
draganrakita: So I don't see those responses that you basically see from both Charles and Ben addressed here.

171
00:28:40.700 --> 00:28:47.240
draganrakita: So maybe we can from the previous slide. Maybe we could go through the list that you made.

172
00:28:47.360 --> 00:28:49.470
draganrakita: and you try to address them

173
00:28:50.690 --> 00:28:58.120
draganrakita: concerns basically all of them. Why, I think most of them are already addressed in the discord. So.

174
00:28:58.560 --> 00:29:02.069
draganrakita: for the sake of discussion, you should be good to address them here.

175
00:29:04.200 --> 00:29:08.559
jochem-brouwer: Okay, could you? Maybe because I know we discussed this. But I think.

176
00:29:08.970 --> 00:29:09.850
Parithosh Jayanthi: Yeah, I was not.

177
00:29:09.900 --> 00:29:13.419
Parithosh Jayanthi: Come on. Maybe give us a summary of what was discussed on this call.

178
00:29:13.420 --> 00:29:14.190
jochem-brouwer: Least, yeah.

179
00:29:14.190 --> 00:29:16.270
Parithosh Jayanthi: To these concerns.

180
00:29:21.020 --> 00:29:28.249
draganrakita: For example, implicit code, hash, code, size, lookup, cache. Do you remember what was discussed there?

181
00:29:28.960 --> 00:29:32.189
draganrakita: I think clients I can.

182
00:29:33.320 --> 00:29:35.389
draganrakita: It's hard to speak for all of them.

183
00:29:35.660 --> 00:29:37.999
draganrakita: but I think they're fine even to.

184
00:29:38.860 --> 00:29:43.260
draganrakita: We had discussed this in Berlin to make this implementation detail.

185
00:29:43.570 --> 00:29:49.470
draganrakita: Some clients are going to add this field inside accounts. Some of them are going to add this

186
00:29:49.590 --> 00:29:53.940
draganrakita: inside the bytecode. They're going to read from.

187
00:29:54.250 --> 00:29:58.750
draganrakita: Some of them are need. They're in need of this additional table.

188
00:29:59.320 --> 00:30:01.019
draganrakita: But even that lookup

189
00:30:01.330 --> 00:30:07.770
draganrakita: on that new table is a lot easier than traversing the tree or anything like that. It's a lot faster.

190
00:30:07.940 --> 00:30:13.519
draganrakita: Ben is even proposing to drop that static gas cost that we currently have.

191
00:30:13.920 --> 00:30:15.979
draganrakita: And he seems reasonable.

192
00:30:16.940 --> 00:30:19.839
draganrakita: Unclear. What economically happens?

193
00:30:19.980 --> 00:30:22.840
draganrakita: Split contract up, I think, Charles.

194
00:30:23.110 --> 00:30:26.220
draganrakita: and we we bend, and Ben

195
00:30:26.590 --> 00:30:34.830
draganrakita: said that there is big incentive to extend, even pay higher gas, because the split of the contract is very hard.

196
00:30:35.915 --> 00:30:36.250
Charles: Yeah.

197
00:30:36.250 --> 00:30:36.630
draganrakita: So.

198
00:30:36.630 --> 00:31:05.099
Charles: I can add a little bit more to that, basically. Yes, you pay for loading the whole contract. But the developer knows this. And so it's a trade-off whether they want to like split some cold paths into like another auxiliary contract. This is actually what I imagined when I drafted Eip 7,903, which doesn't touch the runtime code size at all.

199
00:31:05.140 --> 00:31:16.819
Charles: But it just increases the init code limit. So that in theory you can have a really really big creation code and

200
00:31:16.940 --> 00:31:32.502
Charles: create, I guess, like a a single logical contract which has a a lot of physical auxiliary contracts which hold all the code. But this isn't so easy to implement. And because

201
00:31:33.170 --> 00:31:40.480
Charles: code might be shared between different parts of the contract. So if you imagine, like in the Rc. 20, transfer and transfer from

202
00:31:41.000 --> 00:31:51.990
Charles: functions, they might share some code internally, and if they're in the same contract, then everything is fine, because they just jump to the same internal function.

203
00:31:52.210 --> 00:32:20.059
Charles: But if the developer or the compiler has to split them across contracts, then the code has to be duplicated. So you don't necessarily get a benefit of like if you split some contract into N different smaller contracts that the size of each auxiliary contract is one over N. There may be a lot of overhead for sharing, and in some pathological cases like there may be very little benefit to splitting the contract.

204
00:32:24.490 --> 00:32:29.720
draganrakita: So last codeept.

205
00:32:29.960 --> 00:32:35.939
draganrakita: I'm not sure how exactly the end goal of the byte code loading is going to be.

206
00:32:38.060 --> 00:32:41.910
draganrakita: Maybe it's going to be chunking. Maybe it's going to be something else.

207
00:32:43.536 --> 00:32:49.960
draganrakita: That's basically there wasn't any discussion in.

208
00:32:50.200 --> 00:32:57.750
draganrakita: When that's going to happen. It will probably going to be depending on the Zk vm, or Zk Vm. World.

209
00:32:57.900 --> 00:33:02.529
draganrakita: or how we are going to facilitate that a little bit easier.

210
00:33:04.300 --> 00:33:05.259
draganrakita: You learn more.

211
00:33:06.690 --> 00:33:32.680
Guillaume: Yeah. So the way you solve it in Zkvms is precisely to introduce code chunking. Because if you don't, then you have all those prover killers. You can just call xcode size very, or xcode hash, or whatever actually, code hash doesn't matter. But you can. You can call all those functions that load the entirety of the code, and it will make the provers. Om. So

212
00:33:32.760 --> 00:33:39.400
Guillaume: I don't think you can go around chunking, so there's no way you cannot do code chunking.

213
00:33:44.280 --> 00:33:48.640
draganrakita: I would agree with that to be honest, but at this point of time it's

214
00:33:50.170 --> 00:33:52.650
draganrakita: maybe some new novelty will come.

215
00:33:52.700 --> 00:34:01.160
Charles: Yeah, how feasible is it to introduce code chunking in the near future, like, let's say, the 6 month, one year timeframe.

216
00:34:01.160 --> 00:34:22.970
Guillaume: Well, 6 months. It depends on Glamsterdam, the scheduling of Glamsterdam. So if you believe Glamsterdam can come. Q. 1, 2026. Yeah, I would say, it's probably doable. But yeah, like, I said, it depends on the on the timeline. How easy is it to do? Well, there's an eip that just got resurrected 2926

217
00:34:23.239 --> 00:34:37.500
Guillaume: of which I happen to be the co-author, and trying to introduce this without all the frails of changing a tree, the tree structure just doing what we learned from Verco and from binary trees, and do it in the Mpt.

218
00:34:38.016 --> 00:34:41.270
Guillaume: So how is it? How realistic, is it?

219
00:34:41.480 --> 00:34:45.509
Guillaume: I'm not promising 6 months. But yeah, it's still quite realistic.

220
00:34:48.909 --> 00:34:55.289
draganrakita: In general code chunking requires some kind of tree changes while this doesn't.

221
00:34:55.559 --> 00:35:05.199
draganrakita: So I think code tracking is a better solution. But I think the Glam Glam standarm is going to be ball or some other Aips.

222
00:35:05.529 --> 00:35:09.079
draganrakita: so I'm not sure if we have the space for the trunking.

223
00:35:09.750 --> 00:35:25.409
Guillaume: If if I may disagree changes has been pretty simple has been demonstrated, and it's only unlike the big tree change. It's only 10Â GB that need to be copied so that can be done in

224
00:35:25.650 --> 00:35:27.589
Guillaume: a day, if not an hour.

225
00:35:28.375 --> 00:35:32.729
Guillaume: I think I think it's pretty it's pretty realistic.

226
00:35:33.560 --> 00:35:42.700
Guillaume: And I would contend that writing like creating code that is going to be obsolete. Because once again, code shunking is.

227
00:35:43.290 --> 00:35:58.349
Guillaume: I mean, okay, pending a huge discovery that no one has made so far. It's the only way you're going to allow for Zkvms. So yeah, like, you will need to do it eventually, I would say, might as well do it right. The 1st time.

228
00:36:00.006 --> 00:36:03.179
draganrakita: You will still need to code load, and

229
00:36:03.710 --> 00:36:07.230
draganrakita: that notion of the warm and cold loading.

230
00:36:07.430 --> 00:36:09.660
Guillaume: Yeah. So it's not going to be.

231
00:36:10.750 --> 00:36:19.629
draganrakita: This aip. It's going to change how the gas is calculated. But the structure is still going to be there some way or form.

232
00:36:20.350 --> 00:36:35.849
Guillaume: Absolutely, the gas computation has to match basically what we do in vertical or binary trees, like 4,762, you will need to charge per load per code load. That's not a big

233
00:36:35.850 --> 00:37:00.150
Guillaume: problem. It's just basically the same idea as is present in 7,907. I find the numbers in 7,507 really low, but I'm happy to change them if it makes sense. I'm happy to lower the number from 4,762. But once again, this is something that we have understood for over 4 years now. So it's pretty easy to do.

234
00:37:04.470 --> 00:37:04.940
Parithosh Jayanthi: Okay.

235
00:37:05.640 --> 00:37:29.220
Parithosh Jayanthi: Couple of conversations from chat, perhaps for the 1st one. We're talking about code size data structure being an implementation detail. And one of the asks was, a, which clients do need to have it, and B. If they do need to have it, could we agree to have it at Fusaka. Devnet. 3. And if so, what would the timeline be there?

236
00:37:29.439 --> 00:37:37.339
Parithosh Jayanthi: Because if this is going to be a part of the critical part. Then we have to get that. It will be a delay, and we have to figure out what sort of delay we're accepting.

237
00:37:39.600 --> 00:38:08.109
Guillaume: Yeah, it might be an implementation detail. But you will still need to go and build that index somehow. If you put it in the byte code. If you put it in the account wherever you put it, you will need to do exactly the same thing that a tree transition does. You will need to go over every code and go and put it there, or you will need to build that index. So I would say, from what I can see every client will actually need to build that index.

238
00:38:08.110 --> 00:38:13.260
Guillaume: because if they don't want to do some kind of process exactly like the tree transition.

239
00:38:14.900 --> 00:38:37.940
Parithosh Jayanthi: Okay, that makes sense. And just surfacing maybe 2 more related points one from Marius saying that it's this. Yeah, he still feels under, explored or specified, and he doesn't think we should ship a half big solution, and Anskar already has his hand up, so I would let him speak, and probably also include his message from Chat.

240
00:38:38.750 --> 00:38:48.750
Ansgar Dietrichs: Yeah, actually, I wanted to briefly. Just say, I think where I mostly agreed with Guillaume. I think actually, one thing, he said, is not quite right, because I don't think there would be the need to

241
00:38:49.080 --> 00:39:17.460
Ansgar Dietrichs: populate the code size index with for existing contracts. I mean again, that also would be an implementation detail for clients that for some reason would want to do that. That's fine. But you wouldn't have to do it right, because you know that up to the Fork boundary. All contracts are below the 24Â kB limit, and that's the only information you need for them. You don't need the exact size. You just need that. It's below the 24Â kB. So basically, if you just don't find it in the index, you know, it's below 24. And so that's

242
00:39:17.460 --> 00:39:23.239
Ansgar Dietrichs: all you need. So you don't need to go and rotate through the existing contract. So just a small

243
00:39:23.300 --> 00:39:25.982
Ansgar Dietrichs: thing that makes it actually simpler.

244
00:39:26.820 --> 00:39:40.259
Ansgar Dietrichs: yeah. My comment in chat was specifically like, I would argue that we should make it a hard requirement that before we actually like make the very final call for having 7, 9, 0 7 in Fusaka, that we have

245
00:39:40.750 --> 00:39:52.639
Ansgar Dietrichs: high quality benchmarks that show that all clients can handle these kind of worst case load patterns at a hundred 1 million throughput.

246
00:39:55.300 --> 00:39:58.950
Ansgar Dietrichs: A post post 7, 9 or 7 live.

247
00:39:59.150 --> 00:40:18.600
Ansgar Dietrichs: and that probably means all of them need to have the index implemented. Of course, if some clients, for some reason just, are performing enough, even without the index to do that, all the better. But basically, I would argue that we should officially say, Look, we need to be 100% certain that this will not introduce a new performance bottleneck here. Otherwise we'll pull it out.

248
00:40:22.780 --> 00:40:30.020
Parithosh Jayanthi: That's fair, but that sounds like it will still take some time before we 1st have the index implemented, and do the benchmarks right.

249
00:40:31.830 --> 00:40:58.619
Ansgar Dietrichs: Well, yeah, basically, the argument is implicitly, if we feel like we can't do that in time. Or basically, we will only have that. Those numbers say 2 months from now, because it takes time to implement the index, and 2 months from now it's too late to pull it back out then that I would argue that should mean we should just pull it out immediately, because we don't have that databases. If it is realistic. If all the clients say that is realistic to get those benchmark numbers in time to make the final go. No, go decision, then. I'm personally happy to keep it in, for now.

250
00:40:59.940 --> 00:41:29.029
Parithosh Jayanthi: Okay, I do. Wanna maybe mention one thing. This discussion topic is also slated for Acde. The idea was that Joachim presents all of the information. Here we have a 1st discussion. If there was any information required to be collected over the course of this week, then that, and then present to get an acde. And that's where we would potentially make a decision of how we move forward with the eip. That being said, I think Drakman wanted to say something, and then Ben.

251
00:41:29.520 --> 00:41:42.460
draganrakita: Yeah, I would like to wait the client's opinion on this, because we're talking about if the clients can handle this kind of like new Ddos attacks that could potentially happen.

252
00:41:43.230 --> 00:41:49.829
draganrakita: I didn't hear anybody concerned about that other than we should test it.

253
00:41:50.950 --> 00:41:55.010
draganrakita: So I would take that opinion in discussion.

254
00:41:57.370 --> 00:42:01.619
Parithosh Jayanthi: Could you repeat that point, please? What ddos attack? Do you mean.

255
00:42:03.610 --> 00:42:12.579
draganrakita: I was gonna do the metric, because if we have 100 million, if all clients can handle Aip 7, 9, 0 7 or 100 million.

256
00:42:13.050 --> 00:42:19.890
draganrakita: it should be okay. But yeah, Marius, what's your concern?

257
00:42:22.820 --> 00:42:23.700
Marius van der Wijden: I,

258
00:42:24.500 --> 00:42:34.189
Marius van der Wijden: and like, we still don't really have good reliable numbers on this, you know, like we, we have some tests for it. But the problem with the tests is that they

259
00:42:34.600 --> 00:42:38.509
Marius van der Wijden: like potentially, potentially, even with 24 k.

260
00:42:38.620 --> 00:42:45.630
Marius van der Wijden: you can pull up something like one and a half gigabytes or or something of of of contracts

261
00:42:45.930 --> 00:42:55.300
Marius van der Wijden: with with at a hundred 1 million you can a hundred 1 million like 128

262
00:42:55.710 --> 00:43:01.369
Marius van der Wijden: pay contracts. You can pull out like something like 10 or 11Â GB.

263
00:43:02.990 --> 00:43:09.530
Marius van der Wijden: So that is like, it's just a huge amount of data that you need to load from disk

264
00:43:09.680 --> 00:43:12.239
Marius van der Wijden: in a very short amount of time.

265
00:43:12.390 --> 00:43:22.169
Marius van der Wijden: And the the thing is the tests that we have, I think, for, like

266
00:43:22.730 --> 00:43:26.979
Marius van der Wijden: 45 million gas, we're not wrong with a hundred 1 million gas.

267
00:43:27.180 --> 00:43:29.963
Marius van der Wijden: and only for like

268
00:43:30.710 --> 00:43:34.510
Marius van der Wijden: for small like, not the full amount of contracts.

269
00:43:36.200 --> 00:43:47.649
Marius van der Wijden: And they yeah, like, if the if the con like, it's kind of hard to

270
00:43:48.040 --> 00:43:50.650
Marius van der Wijden: like you can, you can. You can create a bunch of

271
00:43:50.950 --> 00:43:58.640
Marius van der Wijden: interesting edge cases, contracts, calling contracts, calling contracts, doing a bunch of jump test analysis.

272
00:43:58.760 --> 00:44:01.879
Marius van der Wijden: And I just don't see this.

273
00:44:02.520 --> 00:44:08.750
Marius van der Wijden: All of this being as easy as people think.

274
00:44:09.420 --> 00:44:17.580
draganrakita: My question is, Does this is still concerned. Without adding this aip, even with 24 k.

275
00:44:18.190 --> 00:44:23.410
draganrakita: You will, if you have, conserve with 48, you will have conserve with 24.

276
00:44:23.810 --> 00:44:28.030
draganrakita: It's not. We are tripling the size in this

277
00:44:28.260 --> 00:44:30.770
draganrakita: aip. That's why we're just doubling it.

278
00:44:31.340 --> 00:44:37.180
Marius van der Wijden: Yeah, I I do. I do have similar concerns with 24 k.

279
00:44:37.850 --> 00:44:39.609
Marius van der Wijden: Add a hundred 1 million guests.

280
00:44:41.410 --> 00:44:48.169
draganrakita: So it's not exactly the problem with IP with, but with different issues that we need to address.

281
00:44:49.690 --> 00:44:59.770
Charles: The effective rate is at 2,600 gas for 24Â kB is 3.3 8 gas per word.

282
00:45:00.388 --> 00:45:07.571
Charles: A recent change was to forecast per word for the marginal cost, which I personally think is excessive. But

283
00:45:08.590 --> 00:45:15.416
Charles: even if so, with the cip, it's actually more expensive to load.

284
00:45:16.440 --> 00:45:19.780
Charles: a very large contract and multiple small countries.

285
00:45:21.556 --> 00:45:24.650
Parithosh Jayanthi: Ben, do you wanna go? And then Julio.

286
00:45:25.460 --> 00:45:28.229
Ben Adams: Yeah, are we 100%

287
00:45:29.265 --> 00:45:33.279
Ben Adams: certain that there are no contracts above 24Â kB

288
00:45:33.750 --> 00:45:36.680
Ben Adams: that were created before the limits were put in.

289
00:45:40.270 --> 00:45:42.609
Parithosh Jayanthi: Joachim says yes, a hundred percent.

290
00:45:47.470 --> 00:45:48.560
Parithosh Jayanthi: Julio.

291
00:45:52.177 --> 00:46:04.679
Giulio: Yeah, I just wanted to say whether it is we are still in time to maybe just just to bump simply the limit without 7 9 0. 7 at this point. But if it's too late.

292
00:46:14.030 --> 00:46:19.564
Parithosh Jayanthi: Yeah, I think that would have to be something we have to print as an option on acde

293
00:46:20.600 --> 00:46:23.290
Parithosh Jayanthi: But it is probably a realistic option.

294
00:46:23.530 --> 00:46:24.940
Giulio: Yeah, okay.

295
00:46:25.170 --> 00:46:40.010
Parithosh Jayanthi: Also this timeline perspective wise we are in mid July, and I think if we want to have any hope of having Fusaka done before that connect this year. We do need to already start talking about hardening our

296
00:46:40.558 --> 00:46:45.440
Parithosh Jayanthi: our fork and shipping it, instead of figuring out the constraints of the fork.

297
00:46:49.035 --> 00:47:13.090
Parithosh Jayanthi: What would be asked from this discussion. Then what are data points that we can still collect? It seems like one could be that we benchmark, how things look at a hundred 1 million. There is still no index, but it could still help us at least get some initial data points as to how clients perform at 100 million. Are there any other asks from this discussion before Thursday?

298
00:47:15.210 --> 00:47:16.480
Parithosh Jayanthi: Yeah. Milan.

299
00:47:16.960 --> 00:47:20.698
milen | Erigon: Yeah, Hi, it's not an ask, but more of a question.

300
00:47:21.140 --> 00:47:30.149
milen | Erigon: so I was thinking a few days ago that there's currently 2 Aips about limiting the transaction gas limit.

301
00:47:30.360 --> 00:47:39.659
milen | Erigon: and the 1st one is 30 million, which I think is going into Osaka. But then there's another one that I saw that further lowers this down to 16 million.

302
00:47:40.030 --> 00:47:49.720
milen | Erigon: And if you have a 16 million gas transact gas transaction limit, you're actually have an upper bound on like what is the largest contract codes that you can

303
00:47:49.830 --> 00:47:55.230
milen | Erigon: deploy, which I don't know. Haven't done the maths, but like it's

304
00:47:55.360 --> 00:47:59.540
milen | Erigon: quite low, like it's I don't know. 80, let's say, 80Â kB.

305
00:47:59.930 --> 00:48:08.199
milen | Erigon: So the in in my head there, there's 2 things that are competing here, and if we're gonna introduce

306
00:48:08.370 --> 00:48:11.399
milen | Erigon: such aps in the future with 16 million

307
00:48:11.690 --> 00:48:21.060
milen | Erigon: transaction. That's limit size. Then we shouldn't really be discussing like 256Â kB quote size, because I'm not sure how we're gonna deploy these

308
00:48:22.190 --> 00:48:29.029
milen | Erigon: so kinda I feel like all these worries are kind of being a bit exaggerated because

309
00:48:29.910 --> 00:48:35.789
milen | Erigon: I don't see how we would deploy such like large contracts if we have such a low transaction gas limit.

310
00:48:42.520 --> 00:48:53.870
Parithosh Jayanthi: Yeah, I'd imagine that in the future we, if we do have higher contract limits, we also increase the transaction gas limit. But, I don't think we've thought that approach fully through yet.

311
00:49:07.511 --> 00:49:15.699
Parithosh Jayanthi: Sorry. Just trying to quickly catch up on the chat. Is there any specific message people want to bring back to the call.

312
00:49:18.840 --> 00:49:19.499
Parithosh Jayanthi: Well, I just.

313
00:49:19.500 --> 00:49:29.249
Ben Adams: Slide to follow up on Melan's Point that 16 million is in Devnet 3 it got reduced.

314
00:49:30.610 --> 00:49:33.000
Ben Adams: So you might want to implement that if you haven't.

315
00:49:37.470 --> 00:49:44.184
milen | Erigon: Okay, yeah. So I mean, that means that we're even for definitely 3, we're sort of limited, quite a lot

316
00:49:44.630 --> 00:49:49.179
milen | Erigon: in terms of like, what is the theoretical Max code size that you can deploy?

317
00:49:54.830 --> 00:50:00.229
milen | Erigon: See? I'm I'm not sure why, like it's a concern. Why, we're discussing 256Â kB when

318
00:50:00.460 --> 00:50:02.700
milen | Erigon: we actually can't really reach that.

319
00:50:06.600 --> 00:50:09.500
Marius van der Wijden: Because in the future you might be able to awesome.

320
00:50:11.700 --> 00:50:16.489
milen | Erigon: Even with with low transaction gas limit and 60 million.

321
00:50:20.633 --> 00:50:30.450
Marius van der Wijden: No, but maybe in the in the future, deploying a contract will be cheaper. Maybe in the future we will remove the transaction gas cost limit like

322
00:50:31.250 --> 00:50:37.739
Marius van der Wijden: there's no point in specifying that we want to have a hundred, 28Â kB contracts.

323
00:50:37.910 --> 00:50:43.090
Marius van der Wijden: If we will not be able to deploy 128Â kB contracts.

324
00:50:45.670 --> 00:50:49.440
Marius van der Wijden: So at some point either the the

325
00:50:49.590 --> 00:50:56.680
Marius van der Wijden: camp will go or we will have some other mechanism of deploying big contracts, or like.

326
00:50:58.510 --> 00:51:06.340
Marius van der Wijden: maybe maybe even just L twos will will remove the contract the the transaction cap.

327
00:51:06.610 --> 00:51:18.530
Marius van der Wijden: But even then, we should be making these these test cases and these benchmarks to see. Is it actually safe even for you to to have this? These large contracts.

328
00:51:22.520 --> 00:51:26.610
draganrakita: In general, I would say that this a lot depends on client implementations.

329
00:51:27.330 --> 00:51:32.299
draganrakita: so I would like to hear from clients on few days on acde

330
00:51:32.990 --> 00:51:39.480
draganrakita: if they think that this is going to be problematic or not even.

331
00:51:39.760 --> 00:51:40.890
Parithosh Jayanthi: Yeah, I think.

332
00:51:40.890 --> 00:51:41.420
draganrakita: Okay.

333
00:51:41.700 --> 00:52:11.480
Parithosh Jayanthi: That can be concrete? Asks so clients would need to come to acde with a opinion on how difficult it would be to implement the index. The second one would be if they would imagine that it's problematic for larger contract contact sizes. And the 3rd one is we would need to get benchmarks at a hundred 1 million to make sure that we're not bottlenecking on a new front before we even get to 100 million.

334
00:52:12.720 --> 00:52:14.000
Parithosh Jayanthi: Yeah, you have them.

335
00:52:14.000 --> 00:52:24.359
jochem-brouwer: Yeah, one question is because we need these benchmarks. But what benchmarks do we need? Specifically because I did not get that? Is it, Jim test? Is it code reading? Is it? What is it.

336
00:52:30.840 --> 00:52:35.279
Parithosh Jayanthi: Well, which of the parts mainly stresses the client the most?

337
00:52:35.590 --> 00:52:39.150
Parithosh Jayanthi: Yeah, maybe Tony has an answer, Tony.

338
00:52:40.880 --> 00:52:42.229
Parithosh Jayanthi: or is it a different topic.

339
00:52:42.542 --> 00:52:44.730
Toni Wahrstaetter: No, I have a different one.

340
00:52:44.960 --> 00:52:54.429
Parithosh Jayanthi: Okay, then let's finish this 1 first.st does any client team have, like concrete assumptions of what the Ddos attack would be

341
00:52:55.130 --> 00:52:57.429
Parithosh Jayanthi: or what the attack would be.

342
00:52:59.990 --> 00:53:01.900
draganrakita: Marius, do you have example?

343
00:53:02.920 --> 00:53:03.710
Marius van der Wijden: Yes.

344
00:53:04.160 --> 00:53:10.810
Marius van der Wijden: So, what I would like to see is.

345
00:53:10.950 --> 00:53:13.527
Marius van der Wijden: and I think you already implemented. This is

346
00:53:14.270 --> 00:53:23.380
Marius van der Wijden: just touching contract. I don't know where you get the 11 K number from, because when I computed it, it's like 36 K contracts that you can touch

347
00:53:23.560 --> 00:53:24.119
Marius van der Wijden: at a hundred.

348
00:53:24.120 --> 00:53:29.380
jochem-brouwer: Yeah, sorry. That's that's per per transaction. What I'm talking about, not per block. But yeah.

349
00:53:29.778 --> 00:53:31.370
Marius van der Wijden: Per transaction. Oh, yeah.

350
00:53:31.600 --> 00:53:37.195
Marius van der Wijden: So I'm yeah. I was when when I did this test, it was

351
00:53:38.260 --> 00:53:41.560
Marius van der Wijden: it was per 100 million transaction or per block

352
00:53:41.950 --> 00:53:46.820
Marius van der Wijden: and so I could touch 36 k. Contracts.

353
00:53:47.140 --> 00:53:50.063
Marius van der Wijden: Hmm, and then

354
00:53:51.210 --> 00:53:54.149
Marius van der Wijden: Every contract contains a bunch of junk dust

355
00:53:54.677 --> 00:53:57.710
Marius van der Wijden: and then jumps to the end of the contract

356
00:53:57.960 --> 00:54:07.969
Marius van der Wijden: so that it also triggers the jump desk analysis, or contains randomness, whatever you want to do, and then the other one that I would like to see is

357
00:54:08.320 --> 00:54:13.990
Marius van der Wijden: hmm contracts that call other contracts.

358
00:54:14.340 --> 00:54:20.860
Marius van der Wijden: 1024 layers deep, and all of them

359
00:54:21.230 --> 00:54:25.010
Marius van der Wijden: will will have to be will have to stay in memory.

360
00:54:25.270 --> 00:54:32.110
Marius van der Wijden: And then and then it goes basically goes back up one step, and then it calls into a second.

361
00:54:33.010 --> 00:54:38.029
Marius van der Wijden: another 10 like another contract, and then goes back up a step and

362
00:54:38.220 --> 00:54:42.910
Marius van der Wijden: bought into another contract. So you have this chain of

363
00:54:43.840 --> 00:54:45.859
Marius van der Wijden: big contracts that call each other.

364
00:54:47.583 --> 00:54:55.410
Marius van der Wijden: The other stuff is like X code size at a hundred 1 million without the indices.

365
00:54:55.630 --> 00:54:59.029
Marius van der Wijden: And then X code size at a hundred 1 million with an index.

366
00:55:02.690 --> 00:55:07.979
Marius van der Wijden: And yeah, I think those those are the main ones that I would like to see.

367
00:55:09.310 --> 00:55:10.929
jochem-brouwer: Yep. Cool. Thank you.

368
00:55:10.930 --> 00:55:17.810
draganrakita: General, I'll code code size. A code analysis is going to be

369
00:55:18.720 --> 00:55:20.610
draganrakita: because we are spending more gas

370
00:55:21.030 --> 00:55:27.480
draganrakita: with the big code loading. It would be better with this IP,

371
00:55:28.290 --> 00:55:39.840
draganrakita: so the attack is mostly concerned about older current present bytecode, and even

372
00:55:40.000 --> 00:55:43.590
draganrakita: it's Aip 7, 9 0 7.

373
00:55:43.860 --> 00:55:48.640
draganrakita: We have additional cost static cost for loading the code.

374
00:55:49.030 --> 00:55:56.969
draganrakita: So we will reduce the attack vector with the cip. If this cost is here.

375
00:56:02.270 --> 00:56:04.739
Marius van der Wijden: Oh, 1 1 other thing is like

376
00:56:04.970 --> 00:56:11.729
Marius van der Wijden: calling a contract and then reverting because you don't at the

377
00:56:12.830 --> 00:56:15.910
Marius van der Wijden: the required gas to do the

378
00:56:17.444 --> 00:56:19.450
Marius van der Wijden: to pay for loading the contracts.

379
00:56:21.700 --> 00:56:28.550
Marius van der Wijden: That would that would trigger this edge case where you also need the the index for it right.

380
00:56:34.080 --> 00:56:42.369
Parithosh Jayanthi: Okay, I'd like to stop the 7, 9 0, 7 discussion here, and then maybe to 20.

381
00:56:44.910 --> 00:56:54.310
Toni Wahrstaetter: Yeah, just regarding the transaction gas limit. 7, 8, 25. I put it on to the. So last week after the testing call after we.

382
00:56:54.490 --> 00:57:03.919
Toni Wahrstaetter: and loaded from 30 million to 16,000,060.7 million. I put it on onto the Ecde agenda this week. So I think we

383
00:57:04.150 --> 00:57:05.899
Toni Wahrstaetter: we should discuss it there again.

384
00:57:08.650 --> 00:57:10.457
Parithosh Jayanthi: Yeah, perfect. Thank you.

385
00:57:11.929 --> 00:57:21.899
Parithosh Jayanthi: And Barnabas, do you have some update on Devnet? 3. Planning, what else is left over before we launch Devnet 3. And what's the timeline there.

386
00:57:23.450 --> 00:57:27.862
Barnabas: So this is probably one of the main blockers for devnetary, and

387
00:57:28.390 --> 00:57:45.759
Barnabas: not sure how clients are with the implementing. All the different repricing vips especially it should be up updated, and I think we only have 3 more open prs that needs to be merged before we can launch.

388
00:57:48.270 --> 00:57:53.340
Parithosh Jayanthi: Okay, and I think one of them was the pr, I will merge during the call right.

389
00:57:54.010 --> 00:57:55.650
Barnabas: Oh, that has been there still.

390
00:57:55.790 --> 00:58:05.929
Barnabas: The yeah. Yeah. So the blob per transaction limit has been merged. So then there's 1 more for the execution. Api and

391
00:58:06.630 --> 00:58:12.379
Barnabas: the builder spec would also probably want like I I would like to get that all submersion.

392
00:58:14.200 --> 00:58:24.879
Parithosh Jayanthi: Okay, that sounds good. Then I guess the after we have a decision on 7, 9 0, 7 on Ecd. On Thursday we should be have a we should have a timeline for definitely 3 as well.

393
00:58:30.020 --> 00:58:32.970
Parithosh Jayanthi: Yeah, we can discuss the

394
00:58:33.980 --> 00:58:41.349
Parithosh Jayanthi: yeah, we can discuss the execution. Api eip it's the one from rule about partial responses.

395
00:58:41.999 --> 00:58:45.290
Parithosh Jayanthi: Does someone have a status update on how this is going.

396
00:58:46.770 --> 00:59:13.699
RaÃºl Kripalani: Yeah. So this was discussed in Acdc last week. There was a bunch of considerations there. But overall the sentiment was we should just push into it now, and there's been one approval, and we're just waiting to for more El and Cl. Devs to to chime in and just approve if they still see a fit before we go ahead and merge, and I think the idea is to freeze the the execution. Api spec. Soon.

397
00:59:14.660 --> 00:59:17.379
RaÃºl Kripalani: So this would be stopping, stopping it from that.

398
00:59:17.380 --> 00:59:27.980
Parithosh Jayanthi: Okay, perfect. So let's try and get this eip as well emerged in before Thursday, and I think we should be very close to. Then figuring out a timeline for definitely 3

399
00:59:30.770 --> 00:59:35.810
Parithosh Jayanthi: the Sunnyside Labs team wanted to give an update on their latest testing. Do you want to go.

400
00:59:37.210 --> 00:59:43.416
J Sunnyside Labs: Yeah, sure. Thank you. Let me just post the link to the chat.

401
00:59:45.240 --> 00:59:51.030
J Sunnyside Labs: yeah. So briefly, just summarizing what we have done. So we've ran

402
00:59:51.790 --> 00:59:58.720
J Sunnyside Labs: every single cl devnets and er devnets, except for Nimbo CEO

403
01:00:00.054 --> 01:00:04.899
J Sunnyside Labs: with 8 validators for full nodes this time, and then

404
01:00:05.570 --> 01:00:13.970
J Sunnyside Labs: every single cl that nets were able to reach up to more than up to more than 60 blocks per block

405
01:00:14.370 --> 01:00:21.210
J Sunnyside Labs: and nimbus, which previous pre previously was at 9 blobs during Berlin

406
01:00:21.540 --> 01:00:25.080
J Sunnyside Labs: was able to reach up to 40 or more.

407
01:00:26.825 --> 01:00:34.180
J Sunnyside Labs: Yeah. We also could confirm that. All the tested el clients supported

408
01:00:35.033 --> 01:00:38.279
J Sunnyside Labs: more than 72 blocks per block

409
01:00:39.130 --> 01:00:43.080
J Sunnyside Labs: and we also then tested

410
01:00:43.420 --> 01:00:48.850
J Sunnyside Labs: whether clients can sustain high blobs.

411
01:00:49.560 --> 01:00:58.510
J Sunnyside Labs: high blood droplets, and we found with a hundred, 28 node mixed combinations.

412
01:00:59.674 --> 01:01:08.370
J Sunnyside Labs: At 60 blocks per block for every block. On average we could maintain stable.net for 48Â h.

413
01:01:09.800 --> 01:01:16.550
J Sunnyside Labs: We then limited network bandwidth at 30 megabits per second

414
01:01:21.980 --> 01:01:27.370
J Sunnyside Labs: which we found on single Cl devnets we were able to achieve

415
01:01:27.640 --> 01:01:37.230
J Sunnyside Labs: around 60 blobs per block, and with the 128 node devnet we were able to achieve around 45 blobs.

416
01:01:37.780 --> 01:01:45.949
J Sunnyside Labs: say. And then we looked at like what kind of things that limited the

417
01:01:46.070 --> 01:01:50.960
J Sunnyside Labs: block throughput on such bandwidth caps, and we found

418
01:01:52.091 --> 01:01:59.388
J Sunnyside Labs: should both in track network traffics. Kind of bounded the network usage.

419
01:02:00.150 --> 01:02:10.039
J Sunnyside Labs: the block, drop it limit, and other than that there were minor findings in the networking resource usage.

420
01:02:10.450 --> 01:02:15.530
J Sunnyside Labs: We've also done Genesis sync test which we

421
01:02:16.553 --> 01:02:22.849
J Sunnyside Labs: were able to confirm that all the Cls and Els passed except for Gath. But

422
01:02:23.140 --> 01:02:32.000
J Sunnyside Labs: the fix for death is up in the review, so. I guess, like we are at

423
01:02:32.240 --> 01:02:45.019
J Sunnyside Labs: pretty good stage at the moment, and, as Parish said, hardening the cls and Els for Fussaka will be quite important next steps

424
01:02:45.470 --> 01:02:53.079
J Sunnyside Labs: by testing out edge cases and continue doing stress testing and interrupt testing.

425
01:02:54.030 --> 01:03:19.210
Parithosh Jayanthi: Yeah, I think one So Barnabas had a couple of test scenarios that he wanted to see done. I think he sent you guys a list as well as including transactions in the devnets. Right? we spammer should have a bunch of scenarios, and I think we'd like to see a version of this benchmark result also with the default spammer transactions going in.

426
01:03:20.840 --> 01:03:28.740
J Sunnyside Labs: Yeah, I I think Marius and Raoul also commented about that. So we should definitely add that to the next.

427
01:03:29.510 --> 01:03:30.370
Parithosh Jayanthi: Perfect.

428
01:03:31.370 --> 01:03:45.380
RaÃºl Kripalani: Yeah. So just to chime in here, there's there's a there's a bunch of things that this is great testing, and it's great that we have you to do it. Just to kind of like make it more realistic. There's a bunch of things here that I think we'll we'll need to do, we'll need to

429
01:03:45.729 --> 01:04:08.119
RaÃºl Kripalani: constrain the bandwidth, the upside, and the downside of the bandwidth. And differently, we'll need to have different types of nodes that follow the I think it's cip 7,870 specifications. So we'll need to have different, which which mandate different bandwidth requirements depending on the node profile. So we'll need to. We'll need to add that I think we'd benefit as well from backfill

430
01:04:08.120 --> 01:04:22.919
RaÃºl Kripalani: tests that we do here. We do want to create blocks, for example, that are competing with blobs during propagation, and specifically blocks that are saturating the available blocks like that are saturating gas and

431
01:04:22.920 --> 01:04:26.810
RaÃºl Kripalani: creating pathologically large blocks to disseminate

432
01:04:26.810 --> 01:04:55.380
RaÃºl Kripalani: after compressed right? Because this is the object of dissemination. So things like that are things that I think will continue giving us way more signal. And yeah, and I think we also want to apply different latency distributions here. And we want to definitely capture the latency distributions that we've applied for each of these devnets. Another thing that we'll want to do, I think, is we'll want to constrain artificially, constrain the gossip parameters because these are small testnets. These are 50 nodes.

433
01:04:55.380 --> 01:05:14.350
RaÃºl Kripalani: which means that there are very few hops if we're using the the gossip sub parameters of Mainnet. So we'll wanna artificially constrain those so that we're replicating the number of hops and kind of like the travel time that messages will have to do in Mainnet to get better signal. So so yeah, I'm I'm writing all of these things up. I'll I'll send you some feedback.

434
01:05:14.380 --> 01:05:21.319
RaÃºl Kripalani: And and yeah, Barnabas, happy to to integrate any any other tests you you want down here as feedback for sunny Satellite Stream.

435
01:05:24.000 --> 01:05:30.049
Parithosh Jayanthi: Perfect. Thank you. Guys so much. Is there any other topic we want to talk about?

436
01:05:32.914 --> 01:05:44.980
Parithosh Jayanthi: There's a point from Francesco about skewing bandwidth findings. Maybe we take that one to discord, since what happened. And thank you. Everyone for joining.

437
01:05:46.240 --> 01:05:47.589
Parithosh Jayanthi: Okay, have a nice day.

438
01:05:47.820 --> 01:05:48.380
Anders Kristiansen: So.

439
01:05:50.130 --> 01:05:51.110
Toni Wahrstaetter: Thank you. Bye-bye.

440
01:05:51.110 --> 01:05:51.630
jochem-brouwer: Thank you.

441
01:05:51.630 --> 01:05:52.360
Antoine James: Thank you. Bye-bye.

442
01:05:52.360 --> 01:05:54.030
Justin Traglia: Bye, thanks, everyone.

